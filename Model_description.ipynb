{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu/s6zedoGkTH1MAQT5Ij/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ylkim1947/Car_color_classfication/blob/main/Model_description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVEnzxH9-eeI",
        "outputId": "c3cb0a0b-e88b-4930-f56f-6d9e5aadb891"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qfPsJyql8wSt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import glob as glob\n",
        "import os\n",
        "import time\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "from torch import topk\n",
        "\n",
        "# from model import build_model\n",
        "# from class_names import class_names\n",
        "class_names = ['black','red', 'white', 'blue','grey']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/cp2/codestates_cp2_cars/094/outputs/cam_results/', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Q8wt93-38yjN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def build_model(pretrained=True, fine_tune=True, num_classes=5):\n",
        "    if pretrained:\n",
        "        print('[INFO]: Loading pre-trained weights')\n",
        "    else:\n",
        "        print('[INFO]: Not loading pre-trained weights')\n",
        "    #model = models.efficientnet_b1(pretrained=pretrained)\n",
        "    model = models.efficientnet_v2_m(pretrained=pretrained)\n",
        "\n",
        "    if fine_tune:\n",
        "        print('[INFO]: Fine-tuning all layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = True\n",
        "    elif not fine_tune:\n",
        "        print('[INFO]: Freezing hidden layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    # Change the final classification head.\n",
        "    model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "f3sXYP9h-tg8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define computation device.\n",
        "device = 'cpu'\n",
        "# Class names.\n",
        "# Initialize model, switch to eval model, load trained weights.\n",
        "model = build_model(\n",
        "    pretrained=False,\n",
        "    fine_tune=False, \n",
        "    num_classes=5\n",
        ").to(device)\n",
        "model = model.eval()\n",
        "#print(model)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/cp2/codestates_cp2_cars/094/outputs/model.pth',map_location=torch.device('cpu'))['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIe5b319881v",
        "outputId": "733c0f58-797f-4943-fe60-1d92cbf7d723"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Not loading pre-trained weights\n",
            "[INFO]: Freezing hidden layers...\n",
            "EfficientNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "      )\n",
            "      (1): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0035087719298245615, mode=row)\n",
            "      )\n",
            "      (2): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.007017543859649123, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.010526315789473686, mode=row)\n",
            "      )\n",
            "      (1): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.014035087719298246, mode=row)\n",
            "      )\n",
            "      (2): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.017543859649122806, mode=row)\n",
            "      )\n",
            "      (3): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.02105263157894737, mode=row)\n",
            "      )\n",
            "      (4): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.024561403508771933, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.028070175438596492, mode=row)\n",
            "      )\n",
            "      (1): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.031578947368421054, mode=row)\n",
            "      )\n",
            "      (2): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.03508771929824561, mode=row)\n",
            "      )\n",
            "      (3): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.03859649122807018, mode=row)\n",
            "      )\n",
            "      (4): FusedMBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.04210526315789474, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
            "            (1): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(320, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(20, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0456140350877193, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.04912280701754387, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05263157894736842, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.056140350877192984, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05964912280701755, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06315789473684211, mode=row)\n",
            "      )\n",
            "      (6): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
            "            (1): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.07017543859649122, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0736842105263158, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.07719298245614035, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08070175438596493, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08421052631578949, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08771929824561403, mode=row)\n",
            "      )\n",
            "      (6): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0912280701754386, mode=row)\n",
            "      )\n",
            "      (7): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09473684210526316, mode=row)\n",
            "      )\n",
            "      (8): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09824561403508773, mode=row)\n",
            "      )\n",
            "      (9): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10175438596491229, mode=row)\n",
            "      )\n",
            "      (10): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10526315789473684, mode=row)\n",
            "      )\n",
            "      (11): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10877192982456141, mode=row)\n",
            "      )\n",
            "      (12): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.11228070175438597, mode=row)\n",
            "      )\n",
            "      (13): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.11578947368421054, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1056, bias=False)\n",
            "            (1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1192982456140351, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.12280701754385964, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.12631578947368421, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1298245614035088, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1368421052631579, mode=row)\n",
            "      )\n",
            "      (6): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14035087719298245, mode=row)\n",
            "      )\n",
            "      (7): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14385964912280705, mode=row)\n",
            "      )\n",
            "      (8): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1473684210526316, mode=row)\n",
            "      )\n",
            "      (9): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.15087719298245614, mode=row)\n",
            "      )\n",
            "      (10): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1543859649122807, mode=row)\n",
            "      )\n",
            "      (11): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.15789473684210525, mode=row)\n",
            "      )\n",
            "      (12): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16140350877192985, mode=row)\n",
            "      )\n",
            "      (13): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1649122807017544, mode=row)\n",
            "      )\n",
            "      (14): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16842105263157897, mode=row)\n",
            "      )\n",
            "      (15): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17192982456140352, mode=row)\n",
            "      )\n",
            "      (16): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17543859649122806, mode=row)\n",
            "      )\n",
            "      (17): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17894736842105266, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
            "            (1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1824561403508772, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.18596491228070178, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.18947368421052632, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.19298245614035087, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
            "            (1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.19649122807017547, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (8): Conv2dNormActivation(\n",
            "      (0): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.3, inplace=True)\n",
            "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
        "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
        "    # Generate the class activation maps upsample to 256x256.\n",
        "    size_upsample = (256, 256)\n",
        "    bz, nc, h, w = feature_conv.shape\n",
        "    output_cam = []\n",
        "    for idx in class_idx:\n",
        "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
        "        cam = cam.reshape(h, w)\n",
        "        cam = cam - np.min(cam)\n",
        "        cam_img = cam / np.max(cam)\n",
        "        cam_img = np.uint8(255 * cam_img)\n",
        "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
        "    return output_cam\n",
        "\n",
        "def show_cam(CAMs, width, height, orig_image, class_idx, save_name, gt_class):\n",
        "    for i, cam in enumerate(CAMs):\n",
        "        heatmap = cv2.applyColorMap(cv2.resize(cam,(width, height)), cv2.COLORMAP_JET)\n",
        "        result = heatmap * 0.5 + orig_image * 0.5\n",
        "        # put class label text on the result\n",
        "        cv2.putText(result, gt_class, (20, 40), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2,\n",
        "                    cv2.LINE_AA)\n",
        "        pred_class_name = str(class_names[int(class_idx[i])])\n",
        "        if pred_class_name == gt_class:\n",
        "            cv2.putText(result, pred_class_name, (20, 65), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2,\n",
        "                        cv2.LINE_AA)\n",
        "        else:\n",
        "            cv2.putText(result, pred_class_name, (20, 65), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n",
        "                        cv2.LINE_AA)\n",
        "        \n",
        "        # cv2.imshow('CAM', result/255.)\n",
        "        cv2.waitKey(1)\n",
        "        cv2.imwrite(f\"/content/drive/MyDrive/cp2/codestates_cp2_cars/094/outputs/cam_results/CAM_{save_name}.jpg\", result)\n",
        "\n",
        "# Hook the feature extractor.\n",
        "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
        "features_blobs = []\n",
        "def hook_feature(module, input, output):\n",
        "    features_blobs.append(output.data.cpu().numpy())\n",
        "model._modules.get('features').register_forward_hook(hook_feature)\n",
        "# Get the softmax weight\n",
        "params = list(model.parameters())\n",
        "weight_softmax = np.squeeze(params[-2].data.cpu().numpy())"
      ],
      "metadata": {
        "id": "O5KXJaKN9ANS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transforms, resize => tensor => normalize.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "eKEhy5q09DSv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "correct_count = 0\n",
        "frame_count = 0 # To count total frames.\n",
        "total_fps = 0 # To get the final frames per second. \n",
        "# Run for all the test images.\n",
        "all_images = glob.glob('/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/*.jpg', recursive=True)\n",
        "print(all_images[:5])\n",
        "for image_path in all_images:\n",
        "    # Read the image.\n",
        "    image = cv2.imread(image_path)\n",
        "    gt_class = image_path.split(os.path.sep)[-2]\n",
        "    orig_image = image.copy()\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = orig_image.shape\n",
        "    # Apply the image transforms.\n",
        "    image_tensor = transform(image)\n",
        "    # Add batch dimension.\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    # Forward pass through model.\n",
        "    start_time = time.time()\n",
        "    outputs = model(image_tensor.to(device))\n",
        "    end_time = time.time()\n",
        "    # Get the softmax probabilities.\n",
        "    probs = F.softmax(outputs).data.squeeze()\n",
        "    # Get the class indices of top k probabilities.\n",
        "    class_idx = topk(probs, 1)[1].int()\n",
        "    pred_class_name = str(class_names[int(class_idx)])\n",
        "    if gt_class == pred_class_name:\n",
        "        correct_count += 1\n",
        "    \n",
        "    # Generate class activation mapping for the top1 prediction.\n",
        "    CAMs = returnCAM(features_blobs[0], weight_softmax, class_idx)\n",
        "    # File name to save the resulting CAM image with.\n",
        "    save_name = f\"{image_path.split('/')[-1].split('.')[0]}\"\n",
        "    # Show and save the results.\n",
        "    show_cam(CAMs, width, height, orig_image, class_idx, save_name, gt_class)\n",
        "    counter += 1\n",
        "    print(f\"Image: {counter}\")\n",
        "    # Get the current fps.\n",
        "    fps = 1 / (end_time - start_time)\n",
        "    # Add `fps` to `total_fps`.\n",
        "    total_fps += fps\n",
        "    # Increment frame count.\n",
        "    frame_count += 1\n",
        "\n",
        "print(f\"Total number of test images: {len(all_images)}\")\n",
        "print(f\"Total correct predictions: {correct_count}\")\n",
        "print(f\"Accuracy: {correct_count/len(all_images)*100:.3f}\")\n",
        "\n",
        "# Close all frames and video windows.\n",
        "cv2.destroyAllWindows()\n",
        "# calculate and print the average FPS\n",
        "avg_fps = total_fps / frame_count\n",
        "print(f\"Average FPS: {avg_fps:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUT5Idwt9GX_",
        "outputId": "967c35cb-c4ae-4a0d-dadf-5cc55725ebb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/C_210820_KI_052_19_BK_A_T_02_003.jpg', '/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/C_210807_GE_019_18_BK_A_P_01_055.jpg', '/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/C_210820_SS_017_18_BK_C_T_03_019.jpg', '/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/C_210807_GE_019_18_BK_A_P_01_038.jpg', '/content/drive/MyDrive/cp2/codestates_cp2_cars/094/test/C_210807_GE_019_18_BK_A_P_01_003.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 1\n",
            "Image: 2\n",
            "Image: 3\n",
            "Image: 4\n",
            "Image: 5\n",
            "Image: 6\n",
            "Image: 7\n",
            "Image: 8\n",
            "Image: 9\n",
            "Image: 10\n",
            "Image: 11\n",
            "Image: 12\n",
            "Image: 13\n",
            "Image: 14\n",
            "Image: 15\n",
            "Image: 16\n",
            "Image: 17\n",
            "Image: 18\n",
            "Image: 19\n",
            "Total number of test images: 19\n",
            "Total correct predictions: 0\n",
            "Accuracy: 0.000\n",
            "Average FPS: 2.340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchsummary"
      ],
      "metadata": {
        "id": "0zhLBLfnJ5Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wHCe91LEz4H",
        "outputId": "d7ce6cee-aa4a-4ff9-c8db-6a5219ea8670"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary \n",
        "torchsummary.summary(model,(3,480,480),batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OU9nwKNE6oj",
        "outputId": "74db8069-eb17-45be-d309-72dd3689d58c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 24, 240, 240]             648\n",
            "       BatchNorm2d-2         [32, 24, 240, 240]              48\n",
            "              SiLU-3         [32, 24, 240, 240]               0\n",
            "            Conv2d-4         [32, 24, 240, 240]           5,184\n",
            "       BatchNorm2d-5         [32, 24, 240, 240]              48\n",
            "              SiLU-6         [32, 24, 240, 240]               0\n",
            "   StochasticDepth-7         [32, 24, 240, 240]               0\n",
            "       FusedMBConv-8         [32, 24, 240, 240]               0\n",
            "            Conv2d-9         [32, 24, 240, 240]           5,184\n",
            "      BatchNorm2d-10         [32, 24, 240, 240]              48\n",
            "             SiLU-11         [32, 24, 240, 240]               0\n",
            "  StochasticDepth-12         [32, 24, 240, 240]               0\n",
            "      FusedMBConv-13         [32, 24, 240, 240]               0\n",
            "           Conv2d-14         [32, 24, 240, 240]           5,184\n",
            "      BatchNorm2d-15         [32, 24, 240, 240]              48\n",
            "             SiLU-16         [32, 24, 240, 240]               0\n",
            "  StochasticDepth-17         [32, 24, 240, 240]               0\n",
            "      FusedMBConv-18         [32, 24, 240, 240]               0\n",
            "           Conv2d-19         [32, 96, 120, 120]          20,736\n",
            "      BatchNorm2d-20         [32, 96, 120, 120]             192\n",
            "             SiLU-21         [32, 96, 120, 120]               0\n",
            "           Conv2d-22         [32, 48, 120, 120]           4,608\n",
            "      BatchNorm2d-23         [32, 48, 120, 120]              96\n",
            "      FusedMBConv-24         [32, 48, 120, 120]               0\n",
            "           Conv2d-25        [32, 192, 120, 120]          82,944\n",
            "      BatchNorm2d-26        [32, 192, 120, 120]             384\n",
            "             SiLU-27        [32, 192, 120, 120]               0\n",
            "           Conv2d-28         [32, 48, 120, 120]           9,216\n",
            "      BatchNorm2d-29         [32, 48, 120, 120]              96\n",
            "  StochasticDepth-30         [32, 48, 120, 120]               0\n",
            "      FusedMBConv-31         [32, 48, 120, 120]               0\n",
            "           Conv2d-32        [32, 192, 120, 120]          82,944\n",
            "      BatchNorm2d-33        [32, 192, 120, 120]             384\n",
            "             SiLU-34        [32, 192, 120, 120]               0\n",
            "           Conv2d-35         [32, 48, 120, 120]           9,216\n",
            "      BatchNorm2d-36         [32, 48, 120, 120]              96\n",
            "  StochasticDepth-37         [32, 48, 120, 120]               0\n",
            "      FusedMBConv-38         [32, 48, 120, 120]               0\n",
            "           Conv2d-39        [32, 192, 120, 120]          82,944\n",
            "      BatchNorm2d-40        [32, 192, 120, 120]             384\n",
            "             SiLU-41        [32, 192, 120, 120]               0\n",
            "           Conv2d-42         [32, 48, 120, 120]           9,216\n",
            "      BatchNorm2d-43         [32, 48, 120, 120]              96\n",
            "  StochasticDepth-44         [32, 48, 120, 120]               0\n",
            "      FusedMBConv-45         [32, 48, 120, 120]               0\n",
            "           Conv2d-46        [32, 192, 120, 120]          82,944\n",
            "      BatchNorm2d-47        [32, 192, 120, 120]             384\n",
            "             SiLU-48        [32, 192, 120, 120]               0\n",
            "           Conv2d-49         [32, 48, 120, 120]           9,216\n",
            "      BatchNorm2d-50         [32, 48, 120, 120]              96\n",
            "  StochasticDepth-51         [32, 48, 120, 120]               0\n",
            "      FusedMBConv-52         [32, 48, 120, 120]               0\n",
            "           Conv2d-53          [32, 192, 60, 60]          82,944\n",
            "      BatchNorm2d-54          [32, 192, 60, 60]             384\n",
            "             SiLU-55          [32, 192, 60, 60]               0\n",
            "           Conv2d-56           [32, 80, 60, 60]          15,360\n",
            "      BatchNorm2d-57           [32, 80, 60, 60]             160\n",
            "      FusedMBConv-58           [32, 80, 60, 60]               0\n",
            "           Conv2d-59          [32, 320, 60, 60]         230,400\n",
            "      BatchNorm2d-60          [32, 320, 60, 60]             640\n",
            "             SiLU-61          [32, 320, 60, 60]               0\n",
            "           Conv2d-62           [32, 80, 60, 60]          25,600\n",
            "      BatchNorm2d-63           [32, 80, 60, 60]             160\n",
            "  StochasticDepth-64           [32, 80, 60, 60]               0\n",
            "      FusedMBConv-65           [32, 80, 60, 60]               0\n",
            "           Conv2d-66          [32, 320, 60, 60]         230,400\n",
            "      BatchNorm2d-67          [32, 320, 60, 60]             640\n",
            "             SiLU-68          [32, 320, 60, 60]               0\n",
            "           Conv2d-69           [32, 80, 60, 60]          25,600\n",
            "      BatchNorm2d-70           [32, 80, 60, 60]             160\n",
            "  StochasticDepth-71           [32, 80, 60, 60]               0\n",
            "      FusedMBConv-72           [32, 80, 60, 60]               0\n",
            "           Conv2d-73          [32, 320, 60, 60]         230,400\n",
            "      BatchNorm2d-74          [32, 320, 60, 60]             640\n",
            "             SiLU-75          [32, 320, 60, 60]               0\n",
            "           Conv2d-76           [32, 80, 60, 60]          25,600\n",
            "      BatchNorm2d-77           [32, 80, 60, 60]             160\n",
            "  StochasticDepth-78           [32, 80, 60, 60]               0\n",
            "      FusedMBConv-79           [32, 80, 60, 60]               0\n",
            "           Conv2d-80          [32, 320, 60, 60]         230,400\n",
            "      BatchNorm2d-81          [32, 320, 60, 60]             640\n",
            "             SiLU-82          [32, 320, 60, 60]               0\n",
            "           Conv2d-83           [32, 80, 60, 60]          25,600\n",
            "      BatchNorm2d-84           [32, 80, 60, 60]             160\n",
            "  StochasticDepth-85           [32, 80, 60, 60]               0\n",
            "      FusedMBConv-86           [32, 80, 60, 60]               0\n",
            "           Conv2d-87          [32, 320, 60, 60]          25,600\n",
            "      BatchNorm2d-88          [32, 320, 60, 60]             640\n",
            "             SiLU-89          [32, 320, 60, 60]               0\n",
            "           Conv2d-90          [32, 320, 30, 30]           2,880\n",
            "      BatchNorm2d-91          [32, 320, 30, 30]             640\n",
            "             SiLU-92          [32, 320, 30, 30]               0\n",
            "AdaptiveAvgPool2d-93            [32, 320, 1, 1]               0\n",
            "           Conv2d-94             [32, 20, 1, 1]           6,420\n",
            "             SiLU-95             [32, 20, 1, 1]               0\n",
            "           Conv2d-96            [32, 320, 1, 1]           6,720\n",
            "          Sigmoid-97            [32, 320, 1, 1]               0\n",
            "SqueezeExcitation-98          [32, 320, 30, 30]               0\n",
            "           Conv2d-99          [32, 160, 30, 30]          51,200\n",
            "     BatchNorm2d-100          [32, 160, 30, 30]             320\n",
            "          MBConv-101          [32, 160, 30, 30]               0\n",
            "          Conv2d-102          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-103          [32, 640, 30, 30]           1,280\n",
            "            SiLU-104          [32, 640, 30, 30]               0\n",
            "          Conv2d-105          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-106          [32, 640, 30, 30]           1,280\n",
            "            SiLU-107          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-108            [32, 640, 1, 1]               0\n",
            "          Conv2d-109             [32, 40, 1, 1]          25,640\n",
            "            SiLU-110             [32, 40, 1, 1]               0\n",
            "          Conv2d-111            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-112            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-113          [32, 640, 30, 30]               0\n",
            "          Conv2d-114          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-115          [32, 160, 30, 30]             320\n",
            " StochasticDepth-116          [32, 160, 30, 30]               0\n",
            "          MBConv-117          [32, 160, 30, 30]               0\n",
            "          Conv2d-118          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-119          [32, 640, 30, 30]           1,280\n",
            "            SiLU-120          [32, 640, 30, 30]               0\n",
            "          Conv2d-121          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-122          [32, 640, 30, 30]           1,280\n",
            "            SiLU-123          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-124            [32, 640, 1, 1]               0\n",
            "          Conv2d-125             [32, 40, 1, 1]          25,640\n",
            "            SiLU-126             [32, 40, 1, 1]               0\n",
            "          Conv2d-127            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-128            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-129          [32, 640, 30, 30]               0\n",
            "          Conv2d-130          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-131          [32, 160, 30, 30]             320\n",
            " StochasticDepth-132          [32, 160, 30, 30]               0\n",
            "          MBConv-133          [32, 160, 30, 30]               0\n",
            "          Conv2d-134          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-135          [32, 640, 30, 30]           1,280\n",
            "            SiLU-136          [32, 640, 30, 30]               0\n",
            "          Conv2d-137          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-138          [32, 640, 30, 30]           1,280\n",
            "            SiLU-139          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-140            [32, 640, 1, 1]               0\n",
            "          Conv2d-141             [32, 40, 1, 1]          25,640\n",
            "            SiLU-142             [32, 40, 1, 1]               0\n",
            "          Conv2d-143            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-144            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-145          [32, 640, 30, 30]               0\n",
            "          Conv2d-146          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-147          [32, 160, 30, 30]             320\n",
            " StochasticDepth-148          [32, 160, 30, 30]               0\n",
            "          MBConv-149          [32, 160, 30, 30]               0\n",
            "          Conv2d-150          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-151          [32, 640, 30, 30]           1,280\n",
            "            SiLU-152          [32, 640, 30, 30]               0\n",
            "          Conv2d-153          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-154          [32, 640, 30, 30]           1,280\n",
            "            SiLU-155          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-156            [32, 640, 1, 1]               0\n",
            "          Conv2d-157             [32, 40, 1, 1]          25,640\n",
            "            SiLU-158             [32, 40, 1, 1]               0\n",
            "          Conv2d-159            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-160            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-161          [32, 640, 30, 30]               0\n",
            "          Conv2d-162          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-163          [32, 160, 30, 30]             320\n",
            " StochasticDepth-164          [32, 160, 30, 30]               0\n",
            "          MBConv-165          [32, 160, 30, 30]               0\n",
            "          Conv2d-166          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-167          [32, 640, 30, 30]           1,280\n",
            "            SiLU-168          [32, 640, 30, 30]               0\n",
            "          Conv2d-169          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-170          [32, 640, 30, 30]           1,280\n",
            "            SiLU-171          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-172            [32, 640, 1, 1]               0\n",
            "          Conv2d-173             [32, 40, 1, 1]          25,640\n",
            "            SiLU-174             [32, 40, 1, 1]               0\n",
            "          Conv2d-175            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-176            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-177          [32, 640, 30, 30]               0\n",
            "          Conv2d-178          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-179          [32, 160, 30, 30]             320\n",
            " StochasticDepth-180          [32, 160, 30, 30]               0\n",
            "          MBConv-181          [32, 160, 30, 30]               0\n",
            "          Conv2d-182          [32, 640, 30, 30]         102,400\n",
            "     BatchNorm2d-183          [32, 640, 30, 30]           1,280\n",
            "            SiLU-184          [32, 640, 30, 30]               0\n",
            "          Conv2d-185          [32, 640, 30, 30]           5,760\n",
            "     BatchNorm2d-186          [32, 640, 30, 30]           1,280\n",
            "            SiLU-187          [32, 640, 30, 30]               0\n",
            "AdaptiveAvgPool2d-188            [32, 640, 1, 1]               0\n",
            "          Conv2d-189             [32, 40, 1, 1]          25,640\n",
            "            SiLU-190             [32, 40, 1, 1]               0\n",
            "          Conv2d-191            [32, 640, 1, 1]          26,240\n",
            "         Sigmoid-192            [32, 640, 1, 1]               0\n",
            "SqueezeExcitation-193          [32, 640, 30, 30]               0\n",
            "          Conv2d-194          [32, 160, 30, 30]         102,400\n",
            "     BatchNorm2d-195          [32, 160, 30, 30]             320\n",
            " StochasticDepth-196          [32, 160, 30, 30]               0\n",
            "          MBConv-197          [32, 160, 30, 30]               0\n",
            "          Conv2d-198          [32, 960, 30, 30]         153,600\n",
            "     BatchNorm2d-199          [32, 960, 30, 30]           1,920\n",
            "            SiLU-200          [32, 960, 30, 30]               0\n",
            "          Conv2d-201          [32, 960, 30, 30]           8,640\n",
            "     BatchNorm2d-202          [32, 960, 30, 30]           1,920\n",
            "            SiLU-203          [32, 960, 30, 30]               0\n",
            "AdaptiveAvgPool2d-204            [32, 960, 1, 1]               0\n",
            "          Conv2d-205             [32, 40, 1, 1]          38,440\n",
            "            SiLU-206             [32, 40, 1, 1]               0\n",
            "          Conv2d-207            [32, 960, 1, 1]          39,360\n",
            "         Sigmoid-208            [32, 960, 1, 1]               0\n",
            "SqueezeExcitation-209          [32, 960, 30, 30]               0\n",
            "          Conv2d-210          [32, 176, 30, 30]         168,960\n",
            "     BatchNorm2d-211          [32, 176, 30, 30]             352\n",
            "          MBConv-212          [32, 176, 30, 30]               0\n",
            "          Conv2d-213         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-214         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-215         [32, 1056, 30, 30]               0\n",
            "          Conv2d-216         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-217         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-218         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-219           [32, 1056, 1, 1]               0\n",
            "          Conv2d-220             [32, 44, 1, 1]          46,508\n",
            "            SiLU-221             [32, 44, 1, 1]               0\n",
            "          Conv2d-222           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-223           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-224         [32, 1056, 30, 30]               0\n",
            "          Conv2d-225          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-226          [32, 176, 30, 30]             352\n",
            " StochasticDepth-227          [32, 176, 30, 30]               0\n",
            "          MBConv-228          [32, 176, 30, 30]               0\n",
            "          Conv2d-229         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-230         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-231         [32, 1056, 30, 30]               0\n",
            "          Conv2d-232         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-233         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-234         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-235           [32, 1056, 1, 1]               0\n",
            "          Conv2d-236             [32, 44, 1, 1]          46,508\n",
            "            SiLU-237             [32, 44, 1, 1]               0\n",
            "          Conv2d-238           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-239           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-240         [32, 1056, 30, 30]               0\n",
            "          Conv2d-241          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-242          [32, 176, 30, 30]             352\n",
            " StochasticDepth-243          [32, 176, 30, 30]               0\n",
            "          MBConv-244          [32, 176, 30, 30]               0\n",
            "          Conv2d-245         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-246         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-247         [32, 1056, 30, 30]               0\n",
            "          Conv2d-248         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-249         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-250         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-251           [32, 1056, 1, 1]               0\n",
            "          Conv2d-252             [32, 44, 1, 1]          46,508\n",
            "            SiLU-253             [32, 44, 1, 1]               0\n",
            "          Conv2d-254           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-255           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-256         [32, 1056, 30, 30]               0\n",
            "          Conv2d-257          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-258          [32, 176, 30, 30]             352\n",
            " StochasticDepth-259          [32, 176, 30, 30]               0\n",
            "          MBConv-260          [32, 176, 30, 30]               0\n",
            "          Conv2d-261         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-262         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-263         [32, 1056, 30, 30]               0\n",
            "          Conv2d-264         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-265         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-266         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-267           [32, 1056, 1, 1]               0\n",
            "          Conv2d-268             [32, 44, 1, 1]          46,508\n",
            "            SiLU-269             [32, 44, 1, 1]               0\n",
            "          Conv2d-270           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-271           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-272         [32, 1056, 30, 30]               0\n",
            "          Conv2d-273          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-274          [32, 176, 30, 30]             352\n",
            " StochasticDepth-275          [32, 176, 30, 30]               0\n",
            "          MBConv-276          [32, 176, 30, 30]               0\n",
            "          Conv2d-277         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-278         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-279         [32, 1056, 30, 30]               0\n",
            "          Conv2d-280         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-281         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-282         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-283           [32, 1056, 1, 1]               0\n",
            "          Conv2d-284             [32, 44, 1, 1]          46,508\n",
            "            SiLU-285             [32, 44, 1, 1]               0\n",
            "          Conv2d-286           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-287           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-288         [32, 1056, 30, 30]               0\n",
            "          Conv2d-289          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-290          [32, 176, 30, 30]             352\n",
            " StochasticDepth-291          [32, 176, 30, 30]               0\n",
            "          MBConv-292          [32, 176, 30, 30]               0\n",
            "          Conv2d-293         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-294         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-295         [32, 1056, 30, 30]               0\n",
            "          Conv2d-296         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-297         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-298         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-299           [32, 1056, 1, 1]               0\n",
            "          Conv2d-300             [32, 44, 1, 1]          46,508\n",
            "            SiLU-301             [32, 44, 1, 1]               0\n",
            "          Conv2d-302           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-303           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-304         [32, 1056, 30, 30]               0\n",
            "          Conv2d-305          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-306          [32, 176, 30, 30]             352\n",
            " StochasticDepth-307          [32, 176, 30, 30]               0\n",
            "          MBConv-308          [32, 176, 30, 30]               0\n",
            "          Conv2d-309         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-310         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-311         [32, 1056, 30, 30]               0\n",
            "          Conv2d-312         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-313         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-314         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-315           [32, 1056, 1, 1]               0\n",
            "          Conv2d-316             [32, 44, 1, 1]          46,508\n",
            "            SiLU-317             [32, 44, 1, 1]               0\n",
            "          Conv2d-318           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-319           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-320         [32, 1056, 30, 30]               0\n",
            "          Conv2d-321          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-322          [32, 176, 30, 30]             352\n",
            " StochasticDepth-323          [32, 176, 30, 30]               0\n",
            "          MBConv-324          [32, 176, 30, 30]               0\n",
            "          Conv2d-325         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-326         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-327         [32, 1056, 30, 30]               0\n",
            "          Conv2d-328         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-329         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-330         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-331           [32, 1056, 1, 1]               0\n",
            "          Conv2d-332             [32, 44, 1, 1]          46,508\n",
            "            SiLU-333             [32, 44, 1, 1]               0\n",
            "          Conv2d-334           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-335           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-336         [32, 1056, 30, 30]               0\n",
            "          Conv2d-337          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-338          [32, 176, 30, 30]             352\n",
            " StochasticDepth-339          [32, 176, 30, 30]               0\n",
            "          MBConv-340          [32, 176, 30, 30]               0\n",
            "          Conv2d-341         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-342         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-343         [32, 1056, 30, 30]               0\n",
            "          Conv2d-344         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-345         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-346         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-347           [32, 1056, 1, 1]               0\n",
            "          Conv2d-348             [32, 44, 1, 1]          46,508\n",
            "            SiLU-349             [32, 44, 1, 1]               0\n",
            "          Conv2d-350           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-351           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-352         [32, 1056, 30, 30]               0\n",
            "          Conv2d-353          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-354          [32, 176, 30, 30]             352\n",
            " StochasticDepth-355          [32, 176, 30, 30]               0\n",
            "          MBConv-356          [32, 176, 30, 30]               0\n",
            "          Conv2d-357         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-358         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-359         [32, 1056, 30, 30]               0\n",
            "          Conv2d-360         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-361         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-362         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-363           [32, 1056, 1, 1]               0\n",
            "          Conv2d-364             [32, 44, 1, 1]          46,508\n",
            "            SiLU-365             [32, 44, 1, 1]               0\n",
            "          Conv2d-366           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-367           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-368         [32, 1056, 30, 30]               0\n",
            "          Conv2d-369          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-370          [32, 176, 30, 30]             352\n",
            " StochasticDepth-371          [32, 176, 30, 30]               0\n",
            "          MBConv-372          [32, 176, 30, 30]               0\n",
            "          Conv2d-373         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-374         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-375         [32, 1056, 30, 30]               0\n",
            "          Conv2d-376         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-377         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-378         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-379           [32, 1056, 1, 1]               0\n",
            "          Conv2d-380             [32, 44, 1, 1]          46,508\n",
            "            SiLU-381             [32, 44, 1, 1]               0\n",
            "          Conv2d-382           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-383           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-384         [32, 1056, 30, 30]               0\n",
            "          Conv2d-385          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-386          [32, 176, 30, 30]             352\n",
            " StochasticDepth-387          [32, 176, 30, 30]               0\n",
            "          MBConv-388          [32, 176, 30, 30]               0\n",
            "          Conv2d-389         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-390         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-391         [32, 1056, 30, 30]               0\n",
            "          Conv2d-392         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-393         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-394         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-395           [32, 1056, 1, 1]               0\n",
            "          Conv2d-396             [32, 44, 1, 1]          46,508\n",
            "            SiLU-397             [32, 44, 1, 1]               0\n",
            "          Conv2d-398           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-399           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-400         [32, 1056, 30, 30]               0\n",
            "          Conv2d-401          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-402          [32, 176, 30, 30]             352\n",
            " StochasticDepth-403          [32, 176, 30, 30]               0\n",
            "          MBConv-404          [32, 176, 30, 30]               0\n",
            "          Conv2d-405         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-406         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-407         [32, 1056, 30, 30]               0\n",
            "          Conv2d-408         [32, 1056, 30, 30]           9,504\n",
            "     BatchNorm2d-409         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-410         [32, 1056, 30, 30]               0\n",
            "AdaptiveAvgPool2d-411           [32, 1056, 1, 1]               0\n",
            "          Conv2d-412             [32, 44, 1, 1]          46,508\n",
            "            SiLU-413             [32, 44, 1, 1]               0\n",
            "          Conv2d-414           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-415           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-416         [32, 1056, 30, 30]               0\n",
            "          Conv2d-417          [32, 176, 30, 30]         185,856\n",
            "     BatchNorm2d-418          [32, 176, 30, 30]             352\n",
            " StochasticDepth-419          [32, 176, 30, 30]               0\n",
            "          MBConv-420          [32, 176, 30, 30]               0\n",
            "          Conv2d-421         [32, 1056, 30, 30]         185,856\n",
            "     BatchNorm2d-422         [32, 1056, 30, 30]           2,112\n",
            "            SiLU-423         [32, 1056, 30, 30]               0\n",
            "          Conv2d-424         [32, 1056, 15, 15]           9,504\n",
            "     BatchNorm2d-425         [32, 1056, 15, 15]           2,112\n",
            "            SiLU-426         [32, 1056, 15, 15]               0\n",
            "AdaptiveAvgPool2d-427           [32, 1056, 1, 1]               0\n",
            "          Conv2d-428             [32, 44, 1, 1]          46,508\n",
            "            SiLU-429             [32, 44, 1, 1]               0\n",
            "          Conv2d-430           [32, 1056, 1, 1]          47,520\n",
            "         Sigmoid-431           [32, 1056, 1, 1]               0\n",
            "SqueezeExcitation-432         [32, 1056, 15, 15]               0\n",
            "          Conv2d-433          [32, 304, 15, 15]         321,024\n",
            "     BatchNorm2d-434          [32, 304, 15, 15]             608\n",
            "          MBConv-435          [32, 304, 15, 15]               0\n",
            "          Conv2d-436         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-437         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-438         [32, 1824, 15, 15]               0\n",
            "          Conv2d-439         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-440         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-441         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-442           [32, 1824, 1, 1]               0\n",
            "          Conv2d-443             [32, 76, 1, 1]         138,700\n",
            "            SiLU-444             [32, 76, 1, 1]               0\n",
            "          Conv2d-445           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-446           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-447         [32, 1824, 15, 15]               0\n",
            "          Conv2d-448          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-449          [32, 304, 15, 15]             608\n",
            " StochasticDepth-450          [32, 304, 15, 15]               0\n",
            "          MBConv-451          [32, 304, 15, 15]               0\n",
            "          Conv2d-452         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-453         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-454         [32, 1824, 15, 15]               0\n",
            "          Conv2d-455         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-456         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-457         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-458           [32, 1824, 1, 1]               0\n",
            "          Conv2d-459             [32, 76, 1, 1]         138,700\n",
            "            SiLU-460             [32, 76, 1, 1]               0\n",
            "          Conv2d-461           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-462           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-463         [32, 1824, 15, 15]               0\n",
            "          Conv2d-464          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-465          [32, 304, 15, 15]             608\n",
            " StochasticDepth-466          [32, 304, 15, 15]               0\n",
            "          MBConv-467          [32, 304, 15, 15]               0\n",
            "          Conv2d-468         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-469         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-470         [32, 1824, 15, 15]               0\n",
            "          Conv2d-471         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-472         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-473         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-474           [32, 1824, 1, 1]               0\n",
            "          Conv2d-475             [32, 76, 1, 1]         138,700\n",
            "            SiLU-476             [32, 76, 1, 1]               0\n",
            "          Conv2d-477           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-478           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-479         [32, 1824, 15, 15]               0\n",
            "          Conv2d-480          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-481          [32, 304, 15, 15]             608\n",
            " StochasticDepth-482          [32, 304, 15, 15]               0\n",
            "          MBConv-483          [32, 304, 15, 15]               0\n",
            "          Conv2d-484         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-485         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-486         [32, 1824, 15, 15]               0\n",
            "          Conv2d-487         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-488         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-489         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-490           [32, 1824, 1, 1]               0\n",
            "          Conv2d-491             [32, 76, 1, 1]         138,700\n",
            "            SiLU-492             [32, 76, 1, 1]               0\n",
            "          Conv2d-493           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-494           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-495         [32, 1824, 15, 15]               0\n",
            "          Conv2d-496          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-497          [32, 304, 15, 15]             608\n",
            " StochasticDepth-498          [32, 304, 15, 15]               0\n",
            "          MBConv-499          [32, 304, 15, 15]               0\n",
            "          Conv2d-500         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-501         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-502         [32, 1824, 15, 15]               0\n",
            "          Conv2d-503         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-504         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-505         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-506           [32, 1824, 1, 1]               0\n",
            "          Conv2d-507             [32, 76, 1, 1]         138,700\n",
            "            SiLU-508             [32, 76, 1, 1]               0\n",
            "          Conv2d-509           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-510           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-511         [32, 1824, 15, 15]               0\n",
            "          Conv2d-512          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-513          [32, 304, 15, 15]             608\n",
            " StochasticDepth-514          [32, 304, 15, 15]               0\n",
            "          MBConv-515          [32, 304, 15, 15]               0\n",
            "          Conv2d-516         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-517         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-518         [32, 1824, 15, 15]               0\n",
            "          Conv2d-519         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-520         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-521         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-522           [32, 1824, 1, 1]               0\n",
            "          Conv2d-523             [32, 76, 1, 1]         138,700\n",
            "            SiLU-524             [32, 76, 1, 1]               0\n",
            "          Conv2d-525           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-526           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-527         [32, 1824, 15, 15]               0\n",
            "          Conv2d-528          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-529          [32, 304, 15, 15]             608\n",
            " StochasticDepth-530          [32, 304, 15, 15]               0\n",
            "          MBConv-531          [32, 304, 15, 15]               0\n",
            "          Conv2d-532         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-533         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-534         [32, 1824, 15, 15]               0\n",
            "          Conv2d-535         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-536         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-537         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-538           [32, 1824, 1, 1]               0\n",
            "          Conv2d-539             [32, 76, 1, 1]         138,700\n",
            "            SiLU-540             [32, 76, 1, 1]               0\n",
            "          Conv2d-541           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-542           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-543         [32, 1824, 15, 15]               0\n",
            "          Conv2d-544          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-545          [32, 304, 15, 15]             608\n",
            " StochasticDepth-546          [32, 304, 15, 15]               0\n",
            "          MBConv-547          [32, 304, 15, 15]               0\n",
            "          Conv2d-548         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-549         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-550         [32, 1824, 15, 15]               0\n",
            "          Conv2d-551         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-552         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-553         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-554           [32, 1824, 1, 1]               0\n",
            "          Conv2d-555             [32, 76, 1, 1]         138,700\n",
            "            SiLU-556             [32, 76, 1, 1]               0\n",
            "          Conv2d-557           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-558           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-559         [32, 1824, 15, 15]               0\n",
            "          Conv2d-560          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-561          [32, 304, 15, 15]             608\n",
            " StochasticDepth-562          [32, 304, 15, 15]               0\n",
            "          MBConv-563          [32, 304, 15, 15]               0\n",
            "          Conv2d-564         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-565         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-566         [32, 1824, 15, 15]               0\n",
            "          Conv2d-567         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-568         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-569         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-570           [32, 1824, 1, 1]               0\n",
            "          Conv2d-571             [32, 76, 1, 1]         138,700\n",
            "            SiLU-572             [32, 76, 1, 1]               0\n",
            "          Conv2d-573           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-574           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-575         [32, 1824, 15, 15]               0\n",
            "          Conv2d-576          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-577          [32, 304, 15, 15]             608\n",
            " StochasticDepth-578          [32, 304, 15, 15]               0\n",
            "          MBConv-579          [32, 304, 15, 15]               0\n",
            "          Conv2d-580         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-581         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-582         [32, 1824, 15, 15]               0\n",
            "          Conv2d-583         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-584         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-585         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-586           [32, 1824, 1, 1]               0\n",
            "          Conv2d-587             [32, 76, 1, 1]         138,700\n",
            "            SiLU-588             [32, 76, 1, 1]               0\n",
            "          Conv2d-589           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-590           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-591         [32, 1824, 15, 15]               0\n",
            "          Conv2d-592          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-593          [32, 304, 15, 15]             608\n",
            " StochasticDepth-594          [32, 304, 15, 15]               0\n",
            "          MBConv-595          [32, 304, 15, 15]               0\n",
            "          Conv2d-596         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-597         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-598         [32, 1824, 15, 15]               0\n",
            "          Conv2d-599         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-600         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-601         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-602           [32, 1824, 1, 1]               0\n",
            "          Conv2d-603             [32, 76, 1, 1]         138,700\n",
            "            SiLU-604             [32, 76, 1, 1]               0\n",
            "          Conv2d-605           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-606           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-607         [32, 1824, 15, 15]               0\n",
            "          Conv2d-608          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-609          [32, 304, 15, 15]             608\n",
            " StochasticDepth-610          [32, 304, 15, 15]               0\n",
            "          MBConv-611          [32, 304, 15, 15]               0\n",
            "          Conv2d-612         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-613         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-614         [32, 1824, 15, 15]               0\n",
            "          Conv2d-615         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-616         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-617         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-618           [32, 1824, 1, 1]               0\n",
            "          Conv2d-619             [32, 76, 1, 1]         138,700\n",
            "            SiLU-620             [32, 76, 1, 1]               0\n",
            "          Conv2d-621           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-622           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-623         [32, 1824, 15, 15]               0\n",
            "          Conv2d-624          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-625          [32, 304, 15, 15]             608\n",
            " StochasticDepth-626          [32, 304, 15, 15]               0\n",
            "          MBConv-627          [32, 304, 15, 15]               0\n",
            "          Conv2d-628         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-629         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-630         [32, 1824, 15, 15]               0\n",
            "          Conv2d-631         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-632         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-633         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-634           [32, 1824, 1, 1]               0\n",
            "          Conv2d-635             [32, 76, 1, 1]         138,700\n",
            "            SiLU-636             [32, 76, 1, 1]               0\n",
            "          Conv2d-637           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-638           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-639         [32, 1824, 15, 15]               0\n",
            "          Conv2d-640          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-641          [32, 304, 15, 15]             608\n",
            " StochasticDepth-642          [32, 304, 15, 15]               0\n",
            "          MBConv-643          [32, 304, 15, 15]               0\n",
            "          Conv2d-644         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-645         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-646         [32, 1824, 15, 15]               0\n",
            "          Conv2d-647         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-648         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-649         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-650           [32, 1824, 1, 1]               0\n",
            "          Conv2d-651             [32, 76, 1, 1]         138,700\n",
            "            SiLU-652             [32, 76, 1, 1]               0\n",
            "          Conv2d-653           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-654           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-655         [32, 1824, 15, 15]               0\n",
            "          Conv2d-656          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-657          [32, 304, 15, 15]             608\n",
            " StochasticDepth-658          [32, 304, 15, 15]               0\n",
            "          MBConv-659          [32, 304, 15, 15]               0\n",
            "          Conv2d-660         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-661         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-662         [32, 1824, 15, 15]               0\n",
            "          Conv2d-663         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-664         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-665         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-666           [32, 1824, 1, 1]               0\n",
            "          Conv2d-667             [32, 76, 1, 1]         138,700\n",
            "            SiLU-668             [32, 76, 1, 1]               0\n",
            "          Conv2d-669           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-670           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-671         [32, 1824, 15, 15]               0\n",
            "          Conv2d-672          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-673          [32, 304, 15, 15]             608\n",
            " StochasticDepth-674          [32, 304, 15, 15]               0\n",
            "          MBConv-675          [32, 304, 15, 15]               0\n",
            "          Conv2d-676         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-677         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-678         [32, 1824, 15, 15]               0\n",
            "          Conv2d-679         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-680         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-681         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-682           [32, 1824, 1, 1]               0\n",
            "          Conv2d-683             [32, 76, 1, 1]         138,700\n",
            "            SiLU-684             [32, 76, 1, 1]               0\n",
            "          Conv2d-685           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-686           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-687         [32, 1824, 15, 15]               0\n",
            "          Conv2d-688          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-689          [32, 304, 15, 15]             608\n",
            " StochasticDepth-690          [32, 304, 15, 15]               0\n",
            "          MBConv-691          [32, 304, 15, 15]               0\n",
            "          Conv2d-692         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-693         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-694         [32, 1824, 15, 15]               0\n",
            "          Conv2d-695         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-696         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-697         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-698           [32, 1824, 1, 1]               0\n",
            "          Conv2d-699             [32, 76, 1, 1]         138,700\n",
            "            SiLU-700             [32, 76, 1, 1]               0\n",
            "          Conv2d-701           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-702           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-703         [32, 1824, 15, 15]               0\n",
            "          Conv2d-704          [32, 304, 15, 15]         554,496\n",
            "     BatchNorm2d-705          [32, 304, 15, 15]             608\n",
            " StochasticDepth-706          [32, 304, 15, 15]               0\n",
            "          MBConv-707          [32, 304, 15, 15]               0\n",
            "          Conv2d-708         [32, 1824, 15, 15]         554,496\n",
            "     BatchNorm2d-709         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-710         [32, 1824, 15, 15]               0\n",
            "          Conv2d-711         [32, 1824, 15, 15]          16,416\n",
            "     BatchNorm2d-712         [32, 1824, 15, 15]           3,648\n",
            "            SiLU-713         [32, 1824, 15, 15]               0\n",
            "AdaptiveAvgPool2d-714           [32, 1824, 1, 1]               0\n",
            "          Conv2d-715             [32, 76, 1, 1]         138,700\n",
            "            SiLU-716             [32, 76, 1, 1]               0\n",
            "          Conv2d-717           [32, 1824, 1, 1]         140,448\n",
            "         Sigmoid-718           [32, 1824, 1, 1]               0\n",
            "SqueezeExcitation-719         [32, 1824, 15, 15]               0\n",
            "          Conv2d-720          [32, 512, 15, 15]         933,888\n",
            "     BatchNorm2d-721          [32, 512, 15, 15]           1,024\n",
            "          MBConv-722          [32, 512, 15, 15]               0\n",
            "          Conv2d-723         [32, 3072, 15, 15]       1,572,864\n",
            "     BatchNorm2d-724         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-725         [32, 3072, 15, 15]               0\n",
            "          Conv2d-726         [32, 3072, 15, 15]          27,648\n",
            "     BatchNorm2d-727         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-728         [32, 3072, 15, 15]               0\n",
            "AdaptiveAvgPool2d-729           [32, 3072, 1, 1]               0\n",
            "          Conv2d-730            [32, 128, 1, 1]         393,344\n",
            "            SiLU-731            [32, 128, 1, 1]               0\n",
            "          Conv2d-732           [32, 3072, 1, 1]         396,288\n",
            "         Sigmoid-733           [32, 3072, 1, 1]               0\n",
            "SqueezeExcitation-734         [32, 3072, 15, 15]               0\n",
            "          Conv2d-735          [32, 512, 15, 15]       1,572,864\n",
            "     BatchNorm2d-736          [32, 512, 15, 15]           1,024\n",
            " StochasticDepth-737          [32, 512, 15, 15]               0\n",
            "          MBConv-738          [32, 512, 15, 15]               0\n",
            "          Conv2d-739         [32, 3072, 15, 15]       1,572,864\n",
            "     BatchNorm2d-740         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-741         [32, 3072, 15, 15]               0\n",
            "          Conv2d-742         [32, 3072, 15, 15]          27,648\n",
            "     BatchNorm2d-743         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-744         [32, 3072, 15, 15]               0\n",
            "AdaptiveAvgPool2d-745           [32, 3072, 1, 1]               0\n",
            "          Conv2d-746            [32, 128, 1, 1]         393,344\n",
            "            SiLU-747            [32, 128, 1, 1]               0\n",
            "          Conv2d-748           [32, 3072, 1, 1]         396,288\n",
            "         Sigmoid-749           [32, 3072, 1, 1]               0\n",
            "SqueezeExcitation-750         [32, 3072, 15, 15]               0\n",
            "          Conv2d-751          [32, 512, 15, 15]       1,572,864\n",
            "     BatchNorm2d-752          [32, 512, 15, 15]           1,024\n",
            " StochasticDepth-753          [32, 512, 15, 15]               0\n",
            "          MBConv-754          [32, 512, 15, 15]               0\n",
            "          Conv2d-755         [32, 3072, 15, 15]       1,572,864\n",
            "     BatchNorm2d-756         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-757         [32, 3072, 15, 15]               0\n",
            "          Conv2d-758         [32, 3072, 15, 15]          27,648\n",
            "     BatchNorm2d-759         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-760         [32, 3072, 15, 15]               0\n",
            "AdaptiveAvgPool2d-761           [32, 3072, 1, 1]               0\n",
            "          Conv2d-762            [32, 128, 1, 1]         393,344\n",
            "            SiLU-763            [32, 128, 1, 1]               0\n",
            "          Conv2d-764           [32, 3072, 1, 1]         396,288\n",
            "         Sigmoid-765           [32, 3072, 1, 1]               0\n",
            "SqueezeExcitation-766         [32, 3072, 15, 15]               0\n",
            "          Conv2d-767          [32, 512, 15, 15]       1,572,864\n",
            "     BatchNorm2d-768          [32, 512, 15, 15]           1,024\n",
            " StochasticDepth-769          [32, 512, 15, 15]               0\n",
            "          MBConv-770          [32, 512, 15, 15]               0\n",
            "          Conv2d-771         [32, 3072, 15, 15]       1,572,864\n",
            "     BatchNorm2d-772         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-773         [32, 3072, 15, 15]               0\n",
            "          Conv2d-774         [32, 3072, 15, 15]          27,648\n",
            "     BatchNorm2d-775         [32, 3072, 15, 15]           6,144\n",
            "            SiLU-776         [32, 3072, 15, 15]               0\n",
            "AdaptiveAvgPool2d-777           [32, 3072, 1, 1]               0\n",
            "          Conv2d-778            [32, 128, 1, 1]         393,344\n",
            "            SiLU-779            [32, 128, 1, 1]               0\n",
            "          Conv2d-780           [32, 3072, 1, 1]         396,288\n",
            "         Sigmoid-781           [32, 3072, 1, 1]               0\n",
            "SqueezeExcitation-782         [32, 3072, 15, 15]               0\n",
            "          Conv2d-783          [32, 512, 15, 15]       1,572,864\n",
            "     BatchNorm2d-784          [32, 512, 15, 15]           1,024\n",
            " StochasticDepth-785          [32, 512, 15, 15]               0\n",
            "          MBConv-786          [32, 512, 15, 15]               0\n",
            "          Conv2d-787         [32, 1280, 15, 15]         655,360\n",
            "     BatchNorm2d-788         [32, 1280, 15, 15]           2,560\n",
            "            SiLU-789         [32, 1280, 15, 15]               0\n",
            "AdaptiveAvgPool2d-790           [32, 1280, 1, 1]               0\n",
            "         Dropout-791                 [32, 1280]               0\n",
            "          Linear-792                    [32, 5]           6,405\n",
            "================================================================\n",
            "Total params: 52,864,761\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 52,858,356\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 84.38\n",
            "Forward/backward pass size (MB): 76568.07\n",
            "Params size (MB): 201.66\n",
            "Estimated Total Size (MB): 76854.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pytorch-model-summary"
      ],
      "metadata": {
        "id": "ukuzIEnjJYme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-model-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y90gxvtSGabR",
        "outputId": "b606d364-ad93-49e1-8f17-2411ed4ddd01"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-model-summary\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-model-summary) (4.1.1)\n",
            "Installing collected packages: pytorch-model-summary\n",
            "Successfully installed pytorch-model-summary-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_model_summary\n",
        "import torch\n",
        "\n",
        "print(pytorch_model_summary.summary(model, torch.zeros(1,3,480,480),show_input=True,max_depth=0))#,batch_size=32,show_hierarchical=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRHkiBBSGe1I",
        "outputId": "8e9a9491-a345-4526-d166-9647730d9941"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "      Layer (type)          Input Shape         Param #     Tr. Param #\n",
            "========================================================================\n",
            "    EfficientNet-1     [1, 3, 480, 480]      52,864,761           6,405\n",
            "========================================================================\n",
            "Total params: 52,864,761\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 52,858,356\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchsummaryX"
      ],
      "metadata": {
        "id": "BpBk8Px8JWCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvhmOPjUHwV6",
        "outputId": "24ab5514-5593-4ffa-b6d9-b9bbaa9fa3dc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.12.1+cu113)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (4.1.1)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummaryX\n",
        "torchsummaryX.summary(model,torch.zeros((32,3,480,480)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1382
        },
        "id": "ADo4zfqoH7S_",
        "outputId": "52229191-c51f-425a-fe6c-41bd3c3d1372"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================================================\n",
            "                                        Kernel Shape        Output Shape  \\\n",
            "Layer                                                                      \n",
            "0_features.0.Conv2d_0                  [3, 24, 3, 3]  [32, 24, 240, 240]   \n",
            "1_features.0.BatchNorm2d_1                      [24]  [32, 24, 240, 240]   \n",
            "2_features.0.SiLU_2                                -  [32, 24, 240, 240]   \n",
            "3_features.1.0.block.0.Conv2d_0       [24, 24, 3, 3]  [32, 24, 240, 240]   \n",
            "4_features.1.0.block.0.BatchNorm2d_1            [24]  [32, 24, 240, 240]   \n",
            "...                                              ...                 ...   \n",
            "686_features.8.BatchNorm2d_1                  [1280]  [32, 1280, 15, 15]   \n",
            "687_features.8.SiLU_2                              -  [32, 1280, 15, 15]   \n",
            "688_avgpool                                        -    [32, 1280, 1, 1]   \n",
            "689_classifier.Dropout_0                           -          [32, 1280]   \n",
            "690_classifier.Linear_1                    [1280, 5]             [32, 5]   \n",
            "\n",
            "                                      Params Mult-Adds  \n",
            "Layer                                                   \n",
            "0_features.0.Conv2d_0                      -         -  \n",
            "1_features.0.BatchNorm2d_1                 -         -  \n",
            "2_features.0.SiLU_2                        -         -  \n",
            "3_features.1.0.block.0.Conv2d_0            -         -  \n",
            "4_features.1.0.block.0.BatchNorm2d_1       -         -  \n",
            "...                                      ...       ...  \n",
            "686_features.8.BatchNorm2d_1               -         -  \n",
            "687_features.8.SiLU_2                      -         -  \n",
            "688_avgpool                                -         -  \n",
            "689_classifier.Dropout_0                   -         -  \n",
            "690_classifier.Linear_1               6.405k      6.4k  \n",
            "\n",
            "[691 rows x 4 columns]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          52.864761M\n",
            "Trainable params          6.405k\n",
            "Non-trainable params  52.858356M\n",
            "Mult-Adds                   6.4k\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Kernel Shape        Output Shape  \\\n",
              "Layer                                                                      \n",
              "0_features.0.Conv2d_0                  [3, 24, 3, 3]  [32, 24, 240, 240]   \n",
              "1_features.0.BatchNorm2d_1                      [24]  [32, 24, 240, 240]   \n",
              "2_features.0.SiLU_2                                -  [32, 24, 240, 240]   \n",
              "3_features.1.0.block.0.Conv2d_0       [24, 24, 3, 3]  [32, 24, 240, 240]   \n",
              "4_features.1.0.block.0.BatchNorm2d_1            [24]  [32, 24, 240, 240]   \n",
              "...                                              ...                 ...   \n",
              "686_features.8.BatchNorm2d_1                  [1280]  [32, 1280, 15, 15]   \n",
              "687_features.8.SiLU_2                              -  [32, 1280, 15, 15]   \n",
              "688_avgpool                                        -    [32, 1280, 1, 1]   \n",
              "689_classifier.Dropout_0                           -          [32, 1280]   \n",
              "690_classifier.Linear_1                    [1280, 5]             [32, 5]   \n",
              "\n",
              "                                      Params  Mult-Adds  \n",
              "Layer                                                    \n",
              "0_features.0.Conv2d_0                    NaN        NaN  \n",
              "1_features.0.BatchNorm2d_1               NaN        NaN  \n",
              "2_features.0.SiLU_2                      NaN        NaN  \n",
              "3_features.1.0.block.0.Conv2d_0          NaN        NaN  \n",
              "4_features.1.0.block.0.BatchNorm2d_1     NaN        NaN  \n",
              "...                                      ...        ...  \n",
              "686_features.8.BatchNorm2d_1             NaN        NaN  \n",
              "687_features.8.SiLU_2                    NaN        NaN  \n",
              "688_avgpool                              NaN        NaN  \n",
              "689_classifier.Dropout_0                 NaN        NaN  \n",
              "690_classifier.Linear_1               6405.0     6400.0  \n",
              "\n",
              "[691 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-993ed2c2-0e21-412f-9b3c-e6be0f0c24ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_features.0.Conv2d_0</th>\n",
              "      <td>[3, 24, 3, 3]</td>\n",
              "      <td>[32, 24, 240, 240]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_features.0.BatchNorm2d_1</th>\n",
              "      <td>[24]</td>\n",
              "      <td>[32, 24, 240, 240]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_features.0.SiLU_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 24, 240, 240]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_features.1.0.block.0.Conv2d_0</th>\n",
              "      <td>[24, 24, 3, 3]</td>\n",
              "      <td>[32, 24, 240, 240]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_features.1.0.block.0.BatchNorm2d_1</th>\n",
              "      <td>[24]</td>\n",
              "      <td>[32, 24, 240, 240]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686_features.8.BatchNorm2d_1</th>\n",
              "      <td>[1280]</td>\n",
              "      <td>[32, 1280, 15, 15]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687_features.8.SiLU_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 1280, 15, 15]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688_avgpool</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 1280, 1, 1]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689_classifier.Dropout_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 1280]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690_classifier.Linear_1</th>\n",
              "      <td>[1280, 5]</td>\n",
              "      <td>[32, 5]</td>\n",
              "      <td>6405.0</td>\n",
              "      <td>6400.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>691 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-993ed2c2-0e21-412f-9b3c-e6be0f0c24ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-993ed2c2-0e21-412f-9b3c-e6be0f0c24ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-993ed2c2-0e21-412f-9b3c-e6be0f0c24ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchviz"
      ],
      "metadata": {
        "id": "12M90hVhJSQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-Ox6J-GJNfa",
        "outputId": "0fbf436b-629b-4941-fa1c-8473b7301a09"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.12.1+cu113)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4151 sha256=72908a83606a2078cc943145383a1416fde4b6636426f0dbc10777d5d928dc7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "import torch\n",
        "x= torch.zeros(32,3,480,480)\n",
        "y=model(x)\n",
        "\n",
        "make_dot(y.mean(),params=dict(model.named_parameters()),show_attrs=True,show_saved=True).render(\"/content/drive/MyDrive/cp2/codestates_cp2_cars/094/outputs/cam_results/efficientNetV2m.png\",format='png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RzIq9DugJ8k9",
        "outputId": "4ba86540-b182-4f56-8275-d546bd1b7642"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/cp2/codestates_cp2_cars/094/outputs/cam_results/efficientNetV2m.png.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HiddenLayer\n"
      ],
      "metadata": {
        "id": "r31GMa8YMfyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hiddenlayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzvx4YYXMi0i",
        "outputId": "03f061e4-23e4-4d99-e3ce-7fd29f62fcff"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hiddenlayer\n",
            "  Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hiddenlayer as hl \n",
        "\n",
        "transforms = [hl.transforms.Prune('Constant')] # removes constant nodes from graph\n",
        "x= torch.zeros(32,3,480,480)\n",
        "#x= torch.randn(1,8)\n",
        "graph = hl.build_graph(model,x)#,transforms=transforms)\n",
        "graph.theme=hl.graph.THENES['blue'].copy()\n",
        "graph\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "514XEWzbMlLS",
        "outputId": "de7aa1de-87f7-4b63-e1b7-f05335755e0d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-ca3699b8d334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#x= torch.randn(1,8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,transforms=transforms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHENES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hiddenlayer/graph.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Argument args must be provided for Pytorch models.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mimport_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtf_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hiddenlayer/pytorch_builder.py\u001b[0m in \u001b[0;36mimport_graph\u001b[0;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mtorch_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Dump list of nodes (DEBUG only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_optimize_trace\u001b[0;34m(graph, operator_export_type)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     _C._jit_pass_onnx_unpack_quantized_weights(\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_caffe2_aten_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msymbolic_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_caffe2_aten_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%input.1 : Float(32, 3, 480, 480, strides=[691200, 230400, 480, 1], requires_grad=0, device=cpu),\n      %1 : Float(24, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n      %2 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %3 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %4 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %5 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %6 : Long(requires_grad=0, device=cpu),\n      %7 : Float(24, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n      %8 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %9 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %10 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %11 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %12 : Long(requires_grad=0, device=cpu),\n      %13 : Float(24, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n      %14 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %15 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %16 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %17 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %18 : Long(requires_grad=0, device=cpu),\n      %19 : Float(24, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n      %20 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %21 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %22 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %23 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %24 : Long(requires_grad=0, device=cpu),\n      %25 : Float(96, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n      %26 : Float(96, strides=[1], requires_grad=0, device=cpu),\n      %27 : Float(96, strides=[1], requires_grad=0, device=cpu),\n      %28 : Float(96, strides=[1], requires_grad=0, device=cpu),\n      %29 : Float(96, strides=[1], requires_grad=0, device=cpu),\n      %30 : Long(requires_grad=0, device=cpu),\n      %31 : Float(48, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n      %32 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %33 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %34 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %35 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %36 : Long(requires_grad=0, device=cpu),\n      %37 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cpu),\n      %38 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %39 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %40 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %41 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %42 : Long(requires_grad=0, device=cpu),\n      %43 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %44 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %45 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %46 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %47 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %48 : Long(requires_grad=0, device=cpu),\n      %49 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cpu),\n      %50 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %51 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %52 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %53 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %54 : Long(requires_grad=0, device=cpu),\n      %55 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %56 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %57 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %58 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %59 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %60 : Long(requires_grad=0, device=cpu),\n      %61 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cpu),\n      %62 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %63 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %64 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %65 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %66 : Long(requires_grad=0, device=cpu),\n      %67 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %68 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %69 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %70 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %71 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %72 : Long(requires_grad=0, device=cpu),\n      %73 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cpu),\n      %74 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %75 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %76 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %77 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %78 : Long(requires_grad=0, device=cpu),\n      %79 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %80 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %81 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %82 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %83 : Float(48, strides=[1], requires_grad=0, device=cpu),\n      %84 : Long(requires_grad=0, device=cpu),\n      %85 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cpu),\n      %86 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %87 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %88 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %89 : Float(192, strides=[1], requires_grad=0, device=cpu),\n      %90 : Long(requires_grad=0, device=cpu),\n      %91 : Float(80, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %92 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %93 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %94 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %95 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %96 : Long(requires_grad=0, device=cpu),\n      %97 : Float(320, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n      %98 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %99 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %100 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %101 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %102 : Long(requires_grad=0, device=cpu),\n      %103 : Float(80, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %104 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %105 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %106 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %107 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %108 : Long(requires_grad=0, device=cpu),\n      %109 : Float(320, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n      %110 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %111 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %112 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %113 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %114 : Long(requires_grad=0, device=cpu),\n      %115 : Float(80, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %116 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %117 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %118 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %119 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %120 : Long(requires_grad=0, device=cpu),\n      %121 : Float(320, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n      %122 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %123 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %124 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %125 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %126 : Long(requires_grad=0, device=cpu),\n      %127 : Float(80, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %128 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %129 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %130 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %131 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %132 : Long(requires_grad=0, device=cpu),\n      %133 : Float(320, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n      %134 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %135 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %136 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %137 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %138 : Long(requires_grad=0, device=cpu),\n      %139 : Float(80, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %140 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %141 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %142 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %143 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %144 : Long(requires_grad=0, device=cpu),\n      %145 : Float(320, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %146 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %147 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %148 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %149 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %150 : Long(requires_grad=0, device=cpu),\n      %151 : Float(320, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %152 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %153 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %154 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %155 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %156 : Long(requires_grad=0, device=cpu),\n      %157 : Float(20, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %158 : Float(20, strides=[1], requires_grad=0, device=cpu),\n      %159 : Float(320, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n      %160 : Float(320, strides=[1], requires_grad=0, device=cpu),\n      %161 : Float(160, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n      %162 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %163 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %164 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %165 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %166 : Long(requires_grad=0, device=cpu),\n      %167 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %168 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %169 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %170 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %171 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %172 : Long(requires_grad=0, device=cpu),\n      %173 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %174 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %175 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %176 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %177 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %178 : Long(requires_grad=0, device=cpu),\n      %179 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %180 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %181 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %182 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %183 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %184 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %185 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %186 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %187 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %188 : Long(requires_grad=0, device=cpu),\n      %189 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %190 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %191 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %192 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %193 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %194 : Long(requires_grad=0, device=cpu),\n      %195 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %196 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %197 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %198 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %199 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %200 : Long(requires_grad=0, device=cpu),\n      %201 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %202 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %203 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %204 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %205 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %206 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %207 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %208 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %209 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %210 : Long(requires_grad=0, device=cpu),\n      %211 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %212 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %213 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %214 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %215 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %216 : Long(requires_grad=0, device=cpu),\n      %217 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %218 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %219 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %220 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %221 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %222 : Long(requires_grad=0, device=cpu),\n      %223 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %224 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %225 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %226 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %227 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %228 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %229 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %230 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %231 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %232 : Long(requires_grad=0, device=cpu),\n      %233 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %234 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %235 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %236 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %237 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %238 : Long(requires_grad=0, device=cpu),\n      %239 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %240 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %241 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %242 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %243 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %244 : Long(requires_grad=0, device=cpu),\n      %245 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %246 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %247 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %248 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %249 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %250 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %251 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %252 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %253 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %254 : Long(requires_grad=0, device=cpu),\n      %255 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %256 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %257 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %258 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %259 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %260 : Long(requires_grad=0, device=cpu),\n      %261 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %262 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %263 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %264 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %265 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %266 : Long(requires_grad=0, device=cpu),\n      %267 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %268 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %269 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %270 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %271 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %272 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %273 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %274 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %275 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %276 : Long(requires_grad=0, device=cpu),\n      %277 : Float(640, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %278 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %279 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %280 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %281 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %282 : Long(requires_grad=0, device=cpu),\n      %283 : Float(640, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %284 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %285 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %286 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %287 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %288 : Long(requires_grad=0, device=cpu),\n      %289 : Float(40, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %290 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %291 : Float(640, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %292 : Float(640, strides=[1], requires_grad=0, device=cpu),\n      %293 : Float(160, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu),\n      %294 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %295 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %296 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %297 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %298 : Long(requires_grad=0, device=cpu),\n      %299 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %300 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %301 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %302 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %303 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %304 : Long(requires_grad=0, device=cpu),\n      %305 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %306 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %307 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %308 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %309 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %310 : Long(requires_grad=0, device=cpu),\n      %311 : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %312 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %313 : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %314 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %315 : Float(176, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %316 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %317 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %318 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %319 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %320 : Long(requires_grad=0, device=cpu),\n      %321 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %322 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %323 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %324 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %325 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %326 : Long(requires_grad=0, device=cpu),\n      %327 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %328 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %329 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %330 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %331 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %332 : Long(requires_grad=0, device=cpu),\n      %333 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %334 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %335 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %336 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %337 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %338 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %339 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %340 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %341 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %342 : Long(requires_grad=0, device=cpu),\n      %343 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %344 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %345 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %346 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %347 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %348 : Long(requires_grad=0, device=cpu),\n      %349 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %350 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %351 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %352 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %353 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %354 : Long(requires_grad=0, device=cpu),\n      %355 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %356 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %357 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %358 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %359 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %360 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %361 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %362 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %363 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %364 : Long(requires_grad=0, device=cpu),\n      %365 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %366 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %367 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %368 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %369 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %370 : Long(requires_grad=0, device=cpu),\n      %371 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %372 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %373 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %374 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %375 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %376 : Long(requires_grad=0, device=cpu),\n      %377 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %378 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %379 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %380 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %381 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %382 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %383 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %384 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %385 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %386 : Long(requires_grad=0, device=cpu),\n      %387 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %388 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %389 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %390 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %391 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %392 : Long(requires_grad=0, device=cpu),\n      %393 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %394 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %395 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %396 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %397 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %398 : Long(requires_grad=0, device=cpu),\n      %399 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %400 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %401 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %402 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %403 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %404 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %405 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %406 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %407 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %408 : Long(requires_grad=0, device=cpu),\n      %409 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %410 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %411 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %412 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %413 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %414 : Long(requires_grad=0, device=cpu),\n      %415 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %416 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %417 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %418 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %419 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %420 : Long(requires_grad=0, device=cpu),\n      %421 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %422 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %423 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %424 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %425 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %426 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %427 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %428 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %429 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %430 : Long(requires_grad=0, device=cpu),\n      %431 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %432 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %433 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %434 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %435 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %436 : Long(requires_grad=0, device=cpu),\n      %437 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %438 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %439 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %440 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %441 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %442 : Long(requires_grad=0, device=cpu),\n      %443 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %444 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %445 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %446 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %447 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %448 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %449 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %450 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %451 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %452 : Long(requires_grad=0, device=cpu),\n      %453 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %454 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %455 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %456 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %457 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %458 : Long(requires_grad=0, device=cpu),\n      %459 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %460 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %461 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %462 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %463 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %464 : Long(requires_grad=0, device=cpu),\n      %465 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %466 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %467 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %468 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %469 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %470 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %471 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %472 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %473 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %474 : Long(requires_grad=0, device=cpu),\n      %475 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %476 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %477 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %478 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %479 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %480 : Long(requires_grad=0, device=cpu),\n      %481 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %482 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %483 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %484 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %485 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %486 : Long(requires_grad=0, device=cpu),\n      %487 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %488 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %489 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %490 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %491 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %492 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %493 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %494 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %495 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %496 : Long(requires_grad=0, device=cpu),\n      %497 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %498 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %499 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %500 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %501 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %502 : Long(requires_grad=0, device=cpu),\n      %503 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %504 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %505 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %506 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %507 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %508 : Long(requires_grad=0, device=cpu),\n      %509 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %510 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %511 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %512 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %513 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %514 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %515 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %516 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %517 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %518 : Long(requires_grad=0, device=cpu),\n      %519 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %520 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %521 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %522 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %523 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %524 : Long(requires_grad=0, device=cpu),\n      %525 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %526 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %527 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %528 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %529 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %530 : Long(requires_grad=0, device=cpu),\n      %531 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %532 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %533 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %534 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %535 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %536 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %537 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %538 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %539 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %540 : Long(requires_grad=0, device=cpu),\n      %541 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %542 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %543 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %544 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %545 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %546 : Long(requires_grad=0, device=cpu),\n      %547 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %548 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %549 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %550 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %551 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %552 : Long(requires_grad=0, device=cpu),\n      %553 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %554 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %555 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %556 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %557 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %558 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %559 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %560 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %561 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %562 : Long(requires_grad=0, device=cpu),\n      %563 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %564 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %565 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %566 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %567 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %568 : Long(requires_grad=0, device=cpu),\n      %569 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %570 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %571 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %572 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %573 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %574 : Long(requires_grad=0, device=cpu),\n      %575 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %576 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %577 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %578 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %579 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %580 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %581 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %582 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %583 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %584 : Long(requires_grad=0, device=cpu),\n      %585 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %586 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %587 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %588 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %589 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %590 : Long(requires_grad=0, device=cpu),\n      %591 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %592 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %593 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %594 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %595 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %596 : Long(requires_grad=0, device=cpu),\n      %597 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %598 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %599 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %600 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %601 : Float(176, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %602 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %603 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %604 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %605 : Float(176, strides=[1], requires_grad=0, device=cpu),\n      %606 : Long(requires_grad=0, device=cpu),\n      %607 : Float(1056, 176, 1, 1, strides=[176, 1, 1, 1], requires_grad=0, device=cpu),\n      %608 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %609 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %610 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %611 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %612 : Long(requires_grad=0, device=cpu),\n      %613 : Float(1056, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %614 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %615 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %616 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %617 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %618 : Long(requires_grad=0, device=cpu),\n      %619 : Float(44, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %620 : Float(44, strides=[1], requires_grad=0, device=cpu),\n      %621 : Float(1056, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu),\n      %622 : Float(1056, strides=[1], requires_grad=0, device=cpu),\n      %623 : Float(304, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu),\n      %624 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %625 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %626 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %627 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %628 : Long(requires_grad=0, device=cpu),\n      %629 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %630 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %631 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %632 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %633 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %634 : Long(requires_grad=0, device=cpu),\n      %635 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %636 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %637 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %638 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %639 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %640 : Long(requires_grad=0, device=cpu),\n      %641 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %642 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %643 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %644 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %645 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %646 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %647 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %648 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %649 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %650 : Long(requires_grad=0, device=cpu),\n      %651 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %652 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %653 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %654 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %655 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %656 : Long(requires_grad=0, device=cpu),\n      %657 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %658 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %659 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %660 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %661 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %662 : Long(requires_grad=0, device=cpu),\n      %663 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %664 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %665 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %666 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %667 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %668 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %669 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %670 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %671 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %672 : Long(requires_grad=0, device=cpu),\n      %673 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %674 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %675 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %676 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %677 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %678 : Long(requires_grad=0, device=cpu),\n      %679 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %680 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %681 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %682 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %683 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %684 : Long(requires_grad=0, device=cpu),\n      %685 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %686 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %687 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %688 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %689 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %690 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %691 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %692 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %693 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %694 : Long(requires_grad=0, device=cpu),\n      %695 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %696 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %697 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %698 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %699 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %700 : Long(requires_grad=0, device=cpu),\n      %701 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %702 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %703 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %704 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %705 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %706 : Long(requires_grad=0, device=cpu),\n      %707 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %708 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %709 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %710 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %711 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %712 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %713 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %714 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %715 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %716 : Long(requires_grad=0, device=cpu),\n      %717 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %718 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %719 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %720 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %721 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %722 : Long(requires_grad=0, device=cpu),\n      %723 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %724 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %725 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %726 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %727 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %728 : Long(requires_grad=0, device=cpu),\n      %729 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %730 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %731 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %732 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %733 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %734 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %735 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %736 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %737 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %738 : Long(requires_grad=0, device=cpu),\n      %739 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %740 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %741 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %742 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %743 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %744 : Long(requires_grad=0, device=cpu),\n      %745 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %746 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %747 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %748 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %749 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %750 : Long(requires_grad=0, device=cpu),\n      %751 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %752 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %753 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %754 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %755 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %756 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %757 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %758 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %759 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %760 : Long(requires_grad=0, device=cpu),\n      %761 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %762 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %763 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %764 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %765 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %766 : Long(requires_grad=0, device=cpu),\n      %767 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %768 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %769 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %770 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %771 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %772 : Long(requires_grad=0, device=cpu),\n      %773 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %774 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %775 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %776 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %777 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %778 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %779 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %780 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %781 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %782 : Long(requires_grad=0, device=cpu),\n      %783 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %784 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %785 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %786 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %787 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %788 : Long(requires_grad=0, device=cpu),\n      %789 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %790 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %791 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %792 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %793 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %794 : Long(requires_grad=0, device=cpu),\n      %795 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %796 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %797 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %798 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %799 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %800 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %801 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %802 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %803 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %804 : Long(requires_grad=0, device=cpu),\n      %805 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %806 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %807 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %808 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %809 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %810 : Long(requires_grad=0, device=cpu),\n      %811 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %812 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %813 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %814 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %815 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %816 : Long(requires_grad=0, device=cpu),\n      %817 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %818 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %819 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %820 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %821 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %822 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %823 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %824 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %825 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %826 : Long(requires_grad=0, device=cpu),\n      %827 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %828 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %829 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %830 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %831 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %832 : Long(requires_grad=0, device=cpu),\n      %833 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %834 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %835 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %836 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %837 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %838 : Long(requires_grad=0, device=cpu),\n      %839 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %840 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %841 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %842 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %843 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %844 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %845 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %846 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %847 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %848 : Long(requires_grad=0, device=cpu),\n      %849 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %850 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %851 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %852 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %853 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %854 : Long(requires_grad=0, device=cpu),\n      %855 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %856 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %857 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %858 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %859 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %860 : Long(requires_grad=0, device=cpu),\n      %861 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %862 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %863 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %864 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %865 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %866 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %867 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %868 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %869 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %870 : Long(requires_grad=0, device=cpu),\n      %871 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %872 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %873 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %874 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %875 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %876 : Long(requires_grad=0, device=cpu),\n      %877 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %878 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %879 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %880 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %881 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %882 : Long(requires_grad=0, device=cpu),\n      %883 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %884 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %885 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %886 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %887 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %888 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %889 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %890 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %891 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %892 : Long(requires_grad=0, device=cpu),\n      %893 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %894 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %895 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %896 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %897 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %898 : Long(requires_grad=0, device=cpu),\n      %899 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %900 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %901 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %902 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %903 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %904 : Long(requires_grad=0, device=cpu),\n      %905 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %906 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %907 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %908 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %909 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %910 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %911 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %912 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %913 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %914 : Long(requires_grad=0, device=cpu),\n      %915 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %916 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %917 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %918 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %919 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %920 : Long(requires_grad=0, device=cpu),\n      %921 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %922 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %923 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %924 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %925 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %926 : Long(requires_grad=0, device=cpu),\n      %927 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %928 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %929 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %930 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %931 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %932 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %933 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %934 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %935 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %936 : Long(requires_grad=0, device=cpu),\n      %937 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %938 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %939 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %940 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %941 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %942 : Long(requires_grad=0, device=cpu),\n      %943 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %944 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %945 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %946 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %947 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %948 : Long(requires_grad=0, device=cpu),\n      %949 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %950 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %951 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %952 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %953 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %954 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %955 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %956 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %957 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %958 : Long(requires_grad=0, device=cpu),\n      %959 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %960 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %961 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %962 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %963 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %964 : Long(requires_grad=0, device=cpu),\n      %965 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %966 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %967 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %968 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %969 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %970 : Long(requires_grad=0, device=cpu),\n      %971 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %972 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %973 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %974 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %975 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %976 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %977 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %978 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %979 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %980 : Long(requires_grad=0, device=cpu),\n      %981 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %982 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %983 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %984 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %985 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %986 : Long(requires_grad=0, device=cpu),\n      %987 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %988 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %989 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %990 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %991 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %992 : Long(requires_grad=0, device=cpu),\n      %993 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %994 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %995 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %996 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %997 : Float(304, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %998 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %999 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %1000 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %1001 : Float(304, strides=[1], requires_grad=0, device=cpu),\n      %1002 : Long(requires_grad=0, device=cpu),\n      %1003 : Float(1824, 304, 1, 1, strides=[304, 1, 1, 1], requires_grad=0, device=cpu),\n      %1004 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1005 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1006 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1007 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1008 : Long(requires_grad=0, device=cpu),\n      %1009 : Float(1824, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %1010 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1011 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1012 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1013 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1014 : Long(requires_grad=0, device=cpu),\n      %1015 : Float(76, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %1016 : Float(76, strides=[1], requires_grad=0, device=cpu),\n      %1017 : Float(1824, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu),\n      %1018 : Float(1824, strides=[1], requires_grad=0, device=cpu),\n      %1019 : Float(512, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu),\n      %1020 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1021 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1022 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1023 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1024 : Long(requires_grad=0, device=cpu),\n      %1025 : Float(3072, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n      %1026 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1027 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1028 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1029 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1030 : Long(requires_grad=0, device=cpu),\n      %1031 : Float(3072, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %1032 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1033 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1034 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1035 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1036 : Long(requires_grad=0, device=cpu),\n      %1037 : Float(128, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1038 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %1039 : Float(3072, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n      %1040 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1041 : Float(512, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1042 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1043 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1044 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1045 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1046 : Long(requires_grad=0, device=cpu),\n      %1047 : Float(3072, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n      %1048 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1049 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1050 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1051 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1052 : Long(requires_grad=0, device=cpu),\n      %1053 : Float(3072, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %1054 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1055 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1056 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1057 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1058 : Long(requires_grad=0, device=cpu),\n      %1059 : Float(128, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1060 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %1061 : Float(3072, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n      %1062 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1063 : Float(512, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1064 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1065 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1066 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1067 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1068 : Long(requires_grad=0, device=cpu),\n      %1069 : Float(3072, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n      %1070 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1071 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1072 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1073 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1074 : Long(requires_grad=0, device=cpu),\n      %1075 : Float(3072, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %1076 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1077 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1078 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1079 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1080 : Long(requires_grad=0, device=cpu),\n      %1081 : Float(128, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1082 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %1083 : Float(3072, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n      %1084 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1085 : Float(512, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1086 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1087 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1088 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1089 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1090 : Long(requires_grad=0, device=cpu),\n      %1091 : Float(3072, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n      %1092 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1093 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1094 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1095 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1096 : Long(requires_grad=0, device=cpu),\n      %1097 : Float(3072, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %1098 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1099 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1100 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1101 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1102 : Long(requires_grad=0, device=cpu),\n      %1103 : Float(128, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1104 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %1105 : Float(3072, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n      %1106 : Float(3072, strides=[1], requires_grad=0, device=cpu),\n      %1107 : Float(512, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu),\n      %1108 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1109 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1110 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1111 : Float(512, strides=[1], requires_grad=0, device=cpu),\n      %1112 : Long(requires_grad=0, device=cpu),\n      %1113 : Float(1280, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n      %1114 : Float(1280, strides=[1], requires_grad=0, device=cpu),\n      %1115 : Float(1280, strides=[1], requires_grad=0, device=cpu),\n      %1116 : Float(1280, strides=[1], requires_grad=0, device=cpu),\n      %1117 : Float(1280, strides=[1], requires_grad=0, device=cpu),\n      %1118 : Long(requires_grad=0, device=cpu),\n      %1119 : Float(5, 1280, strides=[1280, 1], requires_grad=1, device=cpu),\n      %1120 : Float(5, strides=[1], requires_grad=1, device=cpu)):\n  %3363 : NoneType = prim::Constant()\n  %10033 : int[] = prim::Constant[value=[2, 2]]()\n  %10034 : int[] = prim::Constant[value=[1, 1]]()\n  %10035 : int[] = prim::Constant[value=[1, 1]]()\n  %3373 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10036 : int[] = prim::Constant[value=[0, 0]]()\n  %3377 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3378 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3379 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3380 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3381 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.3 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %1, %3363, %10033, %10034, %10035, %3373, %10036, %3377, %3378, %3379, %3380, %3381) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3383 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3384 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3385 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3386 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.5 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.3, %2, %3, %4, %5, %3383, %3384, %3385, %3386) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11109 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::silu(%input.5) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3389 : NoneType = prim::Constant()\n  %10037 : int[] = prim::Constant[value=[1, 1]]()\n  %10038 : int[] = prim::Constant[value=[1, 1]]()\n  %10039 : int[] = prim::Constant[value=[1, 1]]()\n  %3399 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10040 : int[] = prim::Constant[value=[0, 0]]()\n  %3403 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3404 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3405 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3406 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3407 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.9 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::_convolution(%11109, %7, %3389, %10037, %10038, %10039, %3399, %10040, %3403, %3404, %3405, %3406, %3407) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3409 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3410 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3411 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3412 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.11 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.9, %8, %9, %10, %11, %3409, %3410, %3411, %3412) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11110 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::silu(%input.11) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3415 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11058 : Tensor = aten::type_as(%11109, %11110)\n  %11256 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::add(%11110, %11058, %3415) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3417 : NoneType = prim::Constant()\n  %10041 : int[] = prim::Constant[value=[1, 1]]()\n  %10042 : int[] = prim::Constant[value=[1, 1]]()\n  %10043 : int[] = prim::Constant[value=[1, 1]]()\n  %3427 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10044 : int[] = prim::Constant[value=[0, 0]]()\n  %3431 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3432 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3433 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3434 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3435 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.15 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::_convolution(%11256, %13, %3417, %10041, %10042, %10043, %3427, %10044, %3431, %3432, %3433, %3434, %3435) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3437 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3438 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3439 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3440 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.17 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.15, %14, %15, %16, %17, %3437, %3438, %3439, %3440) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11111 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::silu(%input.17) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3443 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11059 : Tensor = aten::type_as(%11256, %11111)\n  %11257 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::add(%11111, %11059, %3443) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3445 : NoneType = prim::Constant()\n  %10045 : int[] = prim::Constant[value=[1, 1]]()\n  %10046 : int[] = prim::Constant[value=[1, 1]]()\n  %10047 : int[] = prim::Constant[value=[1, 1]]()\n  %3455 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10048 : int[] = prim::Constant[value=[0, 0]]()\n  %3459 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3460 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3461 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3462 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3463 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.21 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::_convolution(%11257, %19, %3445, %10045, %10046, %10047, %3455, %10048, %3459, %3460, %3461, %3462, %3463) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3465 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3466 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3467 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3468 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.23 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.21, %20, %21, %22, %23, %3465, %3466, %3467, %3468) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11112 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::silu(%input.23) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3471 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11060 : Tensor = aten::type_as(%11257, %11112)\n  %11258 : Float(32, 24, 240, 240, strides=[1382400, 57600, 240, 1], requires_grad=0, device=cpu) = aten::add(%11112, %11060, %3471) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3473 : NoneType = prim::Constant()\n  %10049 : int[] = prim::Constant[value=[2, 2]]()\n  %10050 : int[] = prim::Constant[value=[1, 1]]()\n  %10051 : int[] = prim::Constant[value=[1, 1]]()\n  %3483 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10052 : int[] = prim::Constant[value=[0, 0]]()\n  %3487 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3488 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3489 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3490 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3491 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.27 : Float(32, 96, 120, 120, strides=[1382400, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11258, %25, %3473, %10049, %10050, %10051, %3483, %10052, %3487, %3488, %3489, %3490, %3491) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3493 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3494 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3495 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3496 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.29 : Float(32, 96, 120, 120, strides=[1382400, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.27, %26, %27, %28, %29, %3493, %3494, %3495, %3496) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11113 : Float(32, 96, 120, 120, strides=[1382400, 14400, 120, 1], requires_grad=0, device=cpu) = aten::silu(%input.29) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3499 : NoneType = prim::Constant()\n  %10053 : int[] = prim::Constant[value=[1, 1]]()\n  %10054 : int[] = prim::Constant[value=[0, 0]]()\n  %10055 : int[] = prim::Constant[value=[1, 1]]()\n  %3509 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10056 : int[] = prim::Constant[value=[0, 0]]()\n  %3513 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3514 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3515 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3516 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3517 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.33 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11113, %31, %3499, %10053, %10054, %10055, %3509, %10056, %3513, %3514, %3515, %3516, %3517) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3519 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3520 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3521 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3522 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.35 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.33, %32, %33, %34, %35, %3519, %3520, %3521, %3522) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3524 : NoneType = prim::Constant()\n  %10057 : int[] = prim::Constant[value=[1, 1]]()\n  %10058 : int[] = prim::Constant[value=[1, 1]]()\n  %10059 : int[] = prim::Constant[value=[1, 1]]()\n  %3534 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10060 : int[] = prim::Constant[value=[0, 0]]()\n  %3538 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3539 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3540 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3541 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3542 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.37 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.35, %37, %3524, %10057, %10058, %10059, %3534, %10060, %3538, %3539, %3540, %3541, %3542) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3544 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3545 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3546 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3547 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.39 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.37, %38, %39, %40, %41, %3544, %3545, %3546, %3547) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11114 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::silu(%input.39) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3550 : NoneType = prim::Constant()\n  %10061 : int[] = prim::Constant[value=[1, 1]]()\n  %10062 : int[] = prim::Constant[value=[0, 0]]()\n  %10063 : int[] = prim::Constant[value=[1, 1]]()\n  %3560 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10064 : int[] = prim::Constant[value=[0, 0]]()\n  %3564 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3565 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3566 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3567 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3568 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.43 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11114, %43, %3550, %10061, %10062, %10063, %3560, %10064, %3564, %3565, %3566, %3567, %3568) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3570 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3571 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3572 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3573 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3574 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.43, %44, %45, %46, %47, %3570, %3571, %3572, %3573) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3575 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11061 : Tensor = aten::type_as(%input.35, %3574)\n  %11259 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::add(%3574, %11061, %3575) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3577 : NoneType = prim::Constant()\n  %10065 : int[] = prim::Constant[value=[1, 1]]()\n  %10066 : int[] = prim::Constant[value=[1, 1]]()\n  %10067 : int[] = prim::Constant[value=[1, 1]]()\n  %3587 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10068 : int[] = prim::Constant[value=[0, 0]]()\n  %3591 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3592 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3593 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3594 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3595 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.47 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11259, %49, %3577, %10065, %10066, %10067, %3587, %10068, %3591, %3592, %3593, %3594, %3595) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3597 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3598 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3599 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3600 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.49 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.47, %50, %51, %52, %53, %3597, %3598, %3599, %3600) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11115 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::silu(%input.49) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3603 : NoneType = prim::Constant()\n  %10069 : int[] = prim::Constant[value=[1, 1]]()\n  %10070 : int[] = prim::Constant[value=[0, 0]]()\n  %10071 : int[] = prim::Constant[value=[1, 1]]()\n  %3613 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10072 : int[] = prim::Constant[value=[0, 0]]()\n  %3617 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3618 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3619 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3620 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3621 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.53 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11115, %55, %3603, %10069, %10070, %10071, %3613, %10072, %3617, %3618, %3619, %3620, %3621) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3623 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3624 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3625 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3626 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3627 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.53, %56, %57, %58, %59, %3623, %3624, %3625, %3626) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3628 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11062 : Tensor = aten::type_as(%11259, %3627)\n  %11260 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::add(%3627, %11062, %3628) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3630 : NoneType = prim::Constant()\n  %10073 : int[] = prim::Constant[value=[1, 1]]()\n  %10074 : int[] = prim::Constant[value=[1, 1]]()\n  %10075 : int[] = prim::Constant[value=[1, 1]]()\n  %3640 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10076 : int[] = prim::Constant[value=[0, 0]]()\n  %3644 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3645 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3646 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3647 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3648 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.57 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11260, %61, %3630, %10073, %10074, %10075, %3640, %10076, %3644, %3645, %3646, %3647, %3648) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3650 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3651 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3652 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3653 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.59 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.57, %62, %63, %64, %65, %3650, %3651, %3652, %3653) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11116 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::silu(%input.59) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3656 : NoneType = prim::Constant()\n  %10077 : int[] = prim::Constant[value=[1, 1]]()\n  %10078 : int[] = prim::Constant[value=[0, 0]]()\n  %10079 : int[] = prim::Constant[value=[1, 1]]()\n  %3666 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10080 : int[] = prim::Constant[value=[0, 0]]()\n  %3670 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3671 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3672 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3673 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3674 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.63 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11116, %67, %3656, %10077, %10078, %10079, %3666, %10080, %3670, %3671, %3672, %3673, %3674) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3676 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3677 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3678 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3679 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3680 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.63, %68, %69, %70, %71, %3676, %3677, %3678, %3679) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3681 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11063 : Tensor = aten::type_as(%11260, %3680)\n  %11261 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::add(%3680, %11063, %3681) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3683 : NoneType = prim::Constant()\n  %10081 : int[] = prim::Constant[value=[1, 1]]()\n  %10082 : int[] = prim::Constant[value=[1, 1]]()\n  %10083 : int[] = prim::Constant[value=[1, 1]]()\n  %3693 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10084 : int[] = prim::Constant[value=[0, 0]]()\n  %3697 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3698 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3699 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3700 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3701 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.67 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11261, %73, %3683, %10081, %10082, %10083, %3693, %10084, %3697, %3698, %3699, %3700, %3701) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3703 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3704 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3705 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3706 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.69 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.67, %74, %75, %76, %77, %3703, %3704, %3705, %3706) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11117 : Float(32, 192, 120, 120, strides=[2764800, 14400, 120, 1], requires_grad=0, device=cpu) = aten::silu(%input.69) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3709 : NoneType = prim::Constant()\n  %10085 : int[] = prim::Constant[value=[1, 1]]()\n  %10086 : int[] = prim::Constant[value=[0, 0]]()\n  %10087 : int[] = prim::Constant[value=[1, 1]]()\n  %3719 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10088 : int[] = prim::Constant[value=[0, 0]]()\n  %3723 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3724 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3725 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3726 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3727 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.73 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::_convolution(%11117, %79, %3709, %10085, %10086, %10087, %3719, %10088, %3723, %3724, %3725, %3726, %3727) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3729 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3730 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3731 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3732 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3733 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.73, %80, %81, %82, %83, %3729, %3730, %3731, %3732) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3734 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11064 : Tensor = aten::type_as(%11261, %3733)\n  %11262 : Float(32, 48, 120, 120, strides=[691200, 14400, 120, 1], requires_grad=0, device=cpu) = aten::add(%3733, %11064, %3734) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3736 : NoneType = prim::Constant()\n  %10089 : int[] = prim::Constant[value=[2, 2]]()\n  %10090 : int[] = prim::Constant[value=[1, 1]]()\n  %10091 : int[] = prim::Constant[value=[1, 1]]()\n  %3746 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10092 : int[] = prim::Constant[value=[0, 0]]()\n  %3750 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3751 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3752 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3753 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3754 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.77 : Float(32, 192, 60, 60, strides=[691200, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11262, %85, %3736, %10089, %10090, %10091, %3746, %10092, %3750, %3751, %3752, %3753, %3754) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3756 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3757 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3758 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3759 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.79 : Float(32, 192, 60, 60, strides=[691200, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.77, %86, %87, %88, %89, %3756, %3757, %3758, %3759) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11118 : Float(32, 192, 60, 60, strides=[691200, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.79) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3762 : NoneType = prim::Constant()\n  %10093 : int[] = prim::Constant[value=[1, 1]]()\n  %10094 : int[] = prim::Constant[value=[0, 0]]()\n  %10095 : int[] = prim::Constant[value=[1, 1]]()\n  %3772 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10096 : int[] = prim::Constant[value=[0, 0]]()\n  %3776 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3777 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3778 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3779 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3780 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.83 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11118, %91, %3762, %10093, %10094, %10095, %3772, %10096, %3776, %3777, %3778, %3779, %3780) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3782 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3783 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3784 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3785 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.85 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.83, %92, %93, %94, %95, %3782, %3783, %3784, %3785) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3787 : NoneType = prim::Constant()\n  %10097 : int[] = prim::Constant[value=[1, 1]]()\n  %10098 : int[] = prim::Constant[value=[1, 1]]()\n  %10099 : int[] = prim::Constant[value=[1, 1]]()\n  %3797 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10100 : int[] = prim::Constant[value=[0, 0]]()\n  %3801 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3802 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3803 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3804 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3805 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.87 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.85, %97, %3787, %10097, %10098, %10099, %3797, %10100, %3801, %3802, %3803, %3804, %3805) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3807 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3808 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3809 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3810 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.89 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.87, %98, %99, %100, %101, %3807, %3808, %3809, %3810) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11119 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.89) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3813 : NoneType = prim::Constant()\n  %10101 : int[] = prim::Constant[value=[1, 1]]()\n  %10102 : int[] = prim::Constant[value=[0, 0]]()\n  %10103 : int[] = prim::Constant[value=[1, 1]]()\n  %3823 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10104 : int[] = prim::Constant[value=[0, 0]]()\n  %3827 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3828 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3829 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3830 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3831 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.93 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11119, %103, %3813, %10101, %10102, %10103, %3823, %10104, %3827, %3828, %3829, %3830, %3831) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3833 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3834 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3835 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3836 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3837 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.93, %104, %105, %106, %107, %3833, %3834, %3835, %3836) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3838 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11065 : Tensor = aten::type_as(%input.85, %3837)\n  %11263 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::add(%3837, %11065, %3838) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3840 : NoneType = prim::Constant()\n  %10105 : int[] = prim::Constant[value=[1, 1]]()\n  %10106 : int[] = prim::Constant[value=[1, 1]]()\n  %10107 : int[] = prim::Constant[value=[1, 1]]()\n  %3850 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10108 : int[] = prim::Constant[value=[0, 0]]()\n  %3854 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3855 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3856 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3857 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3858 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.97 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11263, %109, %3840, %10105, %10106, %10107, %3850, %10108, %3854, %3855, %3856, %3857, %3858) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3860 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3861 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3862 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3863 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.99 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.97, %110, %111, %112, %113, %3860, %3861, %3862, %3863) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11120 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.99) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3866 : NoneType = prim::Constant()\n  %10109 : int[] = prim::Constant[value=[1, 1]]()\n  %10110 : int[] = prim::Constant[value=[0, 0]]()\n  %10111 : int[] = prim::Constant[value=[1, 1]]()\n  %3876 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10112 : int[] = prim::Constant[value=[0, 0]]()\n  %3880 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3881 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3882 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3883 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3884 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.103 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11120, %115, %3866, %10109, %10110, %10111, %3876, %10112, %3880, %3881, %3882, %3883, %3884) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3886 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3887 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3888 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3889 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3890 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.103, %116, %117, %118, %119, %3886, %3887, %3888, %3889) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3891 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11066 : Tensor = aten::type_as(%11263, %3890)\n  %11264 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::add(%3890, %11066, %3891) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3893 : NoneType = prim::Constant()\n  %10113 : int[] = prim::Constant[value=[1, 1]]()\n  %10114 : int[] = prim::Constant[value=[1, 1]]()\n  %10115 : int[] = prim::Constant[value=[1, 1]]()\n  %3903 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10116 : int[] = prim::Constant[value=[0, 0]]()\n  %3907 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3908 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3909 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3910 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3911 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.107 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11264, %121, %3893, %10113, %10114, %10115, %3903, %10116, %3907, %3908, %3909, %3910, %3911) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3913 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3914 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3915 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3916 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.109 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.107, %122, %123, %124, %125, %3913, %3914, %3915, %3916) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11121 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.109) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3919 : NoneType = prim::Constant()\n  %10117 : int[] = prim::Constant[value=[1, 1]]()\n  %10118 : int[] = prim::Constant[value=[0, 0]]()\n  %10119 : int[] = prim::Constant[value=[1, 1]]()\n  %3929 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10120 : int[] = prim::Constant[value=[0, 0]]()\n  %3933 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3934 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3935 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3936 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3937 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.113 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11121, %127, %3919, %10117, %10118, %10119, %3929, %10120, %3933, %3934, %3935, %3936, %3937) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3939 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3940 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3941 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3942 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3943 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.113, %128, %129, %130, %131, %3939, %3940, %3941, %3942) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3944 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11067 : Tensor = aten::type_as(%11264, %3943)\n  %11265 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::add(%3943, %11067, %3944) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3946 : NoneType = prim::Constant()\n  %10121 : int[] = prim::Constant[value=[1, 1]]()\n  %10122 : int[] = prim::Constant[value=[1, 1]]()\n  %10123 : int[] = prim::Constant[value=[1, 1]]()\n  %3956 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10124 : int[] = prim::Constant[value=[0, 0]]()\n  %3960 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3961 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3962 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3963 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3964 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.117 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11265, %133, %3946, %10121, %10122, %10123, %3956, %10124, %3960, %3961, %3962, %3963, %3964) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3966 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3967 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3968 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3969 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.119 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.117, %134, %135, %136, %137, %3966, %3967, %3968, %3969) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11122 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.119) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %3972 : NoneType = prim::Constant()\n  %10125 : int[] = prim::Constant[value=[1, 1]]()\n  %10126 : int[] = prim::Constant[value=[0, 0]]()\n  %10127 : int[] = prim::Constant[value=[1, 1]]()\n  %3982 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10128 : int[] = prim::Constant[value=[0, 0]]()\n  %3986 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3987 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3988 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3989 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3990 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.123 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11122, %139, %3972, %10125, %10126, %10127, %3982, %10128, %3986, %3987, %3988, %3989, %3990) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %3992 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3993 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3994 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3995 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3996 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.123, %140, %141, %142, %143, %3992, %3993, %3994, %3995) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %3997 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %11068 : Tensor = aten::type_as(%11265, %3996)\n  %11266 : Float(32, 80, 60, 60, strides=[288000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::add(%3996, %11068, %3997) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:229:0\n  %3999 : NoneType = prim::Constant()\n  %10129 : int[] = prim::Constant[value=[1, 1]]()\n  %10130 : int[] = prim::Constant[value=[0, 0]]()\n  %10131 : int[] = prim::Constant[value=[1, 1]]()\n  %4009 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10132 : int[] = prim::Constant[value=[0, 0]]()\n  %4013 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4014 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4015 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4016 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4017 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.127 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::_convolution(%11266, %145, %3999, %10129, %10130, %10131, %4009, %10132, %4013, %4014, %4015, %4016, %4017) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4019 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4020 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4021 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4022 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.129 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.127, %146, %147, %148, %149, %4019, %4020, %4021, %4022) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11123 : Float(32, 320, 60, 60, strides=[1152000, 3600, 60, 1], requires_grad=0, device=cpu) = aten::silu(%input.129) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4025 : NoneType = prim::Constant()\n  %10133 : int[] = prim::Constant[value=[2, 2]]()\n  %10134 : int[] = prim::Constant[value=[1, 1]]()\n  %10135 : int[] = prim::Constant[value=[1, 1]]()\n  %4035 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10136 : int[] = prim::Constant[value=[0, 0]]()\n  %4039 : int = prim::Constant[value=320]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4040 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4041 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4042 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4043 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.133 : Float(32, 320, 30, 30, strides=[288000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11123, %151, %4025, %10133, %10134, %10135, %4035, %10136, %4039, %4040, %4041, %4042, %4043) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4045 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4046 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4047 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4048 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.135 : Float(32, 320, 30, 30, strides=[288000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.133, %152, %153, %154, %155, %4045, %4046, %4047, %4048) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11124 : Float(32, 320, 30, 30, strides=[288000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.135) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10137 : int[] = prim::Constant[value=[1, 1]]()\n  %input.139 : Float(32, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11124, %10137) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10138 : int[] = prim::Constant[value=[1, 1]]()\n  %10139 : int[] = prim::Constant[value=[0, 0]]()\n  %10140 : int[] = prim::Constant[value=[1, 1]]()\n  %4076 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10141 : int[] = prim::Constant[value=[0, 0]]()\n  %4080 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4081 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4082 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4083 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4084 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.141 : Float(32, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.139, %157, %158, %10138, %10139, %10140, %4076, %10141, %4080, %4081, %4082, %4083, %4084) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11125 : Float(32, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.141) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10142 : int[] = prim::Constant[value=[1, 1]]()\n  %10143 : int[] = prim::Constant[value=[0, 0]]()\n  %10144 : int[] = prim::Constant[value=[1, 1]]()\n  %4096 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10145 : int[] = prim::Constant[value=[0, 0]]()\n  %4100 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4101 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4102 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4103 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4104 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4105 : Float(32, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11125, %159, %160, %10142, %10143, %10144, %4096, %10145, %4100, %4101, %4102, %4103, %4104) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4106 : Float(32, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4105) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.145 : Float(32, 320, 30, 30, strides=[288000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4106, %11124) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4108 : NoneType = prim::Constant()\n  %10146 : int[] = prim::Constant[value=[1, 1]]()\n  %10147 : int[] = prim::Constant[value=[0, 0]]()\n  %10148 : int[] = prim::Constant[value=[1, 1]]()\n  %4118 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10149 : int[] = prim::Constant[value=[0, 0]]()\n  %4122 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4123 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4124 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4125 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4126 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.147 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.145, %161, %4108, %10146, %10147, %10148, %4118, %10149, %4122, %4123, %4124, %4125, %4126) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4128 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4129 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4130 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4131 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.149 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.147, %162, %163, %164, %165, %4128, %4129, %4130, %4131) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4133 : NoneType = prim::Constant()\n  %10150 : int[] = prim::Constant[value=[1, 1]]()\n  %10151 : int[] = prim::Constant[value=[0, 0]]()\n  %10152 : int[] = prim::Constant[value=[1, 1]]()\n  %4143 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10153 : int[] = prim::Constant[value=[0, 0]]()\n  %4147 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4148 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4149 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4150 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4151 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.151 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.149, %167, %4133, %10150, %10151, %10152, %4143, %10153, %4147, %4148, %4149, %4150, %4151) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4153 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4154 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4155 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4156 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.153 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.151, %168, %169, %170, %171, %4153, %4154, %4155, %4156) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11126 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.153) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4159 : NoneType = prim::Constant()\n  %10154 : int[] = prim::Constant[value=[1, 1]]()\n  %10155 : int[] = prim::Constant[value=[1, 1]]()\n  %10156 : int[] = prim::Constant[value=[1, 1]]()\n  %4169 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10157 : int[] = prim::Constant[value=[0, 0]]()\n  %4173 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4174 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4175 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4176 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4177 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.157 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11126, %173, %4159, %10154, %10155, %10156, %4169, %10157, %4173, %4174, %4175, %4176, %4177) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4179 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4180 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4181 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4182 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.159 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.157, %174, %175, %176, %177, %4179, %4180, %4181, %4182) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11127 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.159) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10158 : int[] = prim::Constant[value=[1, 1]]()\n  %input.163 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11127, %10158) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10159 : int[] = prim::Constant[value=[1, 1]]()\n  %10160 : int[] = prim::Constant[value=[0, 0]]()\n  %10161 : int[] = prim::Constant[value=[1, 1]]()\n  %4210 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10162 : int[] = prim::Constant[value=[0, 0]]()\n  %4214 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4215 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4216 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4217 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4218 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.165 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.163, %179, %180, %10159, %10160, %10161, %4210, %10162, %4214, %4215, %4216, %4217, %4218) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11128 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.165) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10163 : int[] = prim::Constant[value=[1, 1]]()\n  %10164 : int[] = prim::Constant[value=[0, 0]]()\n  %10165 : int[] = prim::Constant[value=[1, 1]]()\n  %4230 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10166 : int[] = prim::Constant[value=[0, 0]]()\n  %4234 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4235 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4236 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4237 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4238 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4239 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11128, %181, %182, %10163, %10164, %10165, %4230, %10166, %4234, %4235, %4236, %4237, %4238) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4240 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4239) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.169 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4240, %11127) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4242 : NoneType = prim::Constant()\n  %10167 : int[] = prim::Constant[value=[1, 1]]()\n  %10168 : int[] = prim::Constant[value=[0, 0]]()\n  %10169 : int[] = prim::Constant[value=[1, 1]]()\n  %4252 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10170 : int[] = prim::Constant[value=[0, 0]]()\n  %4256 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4257 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4258 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4259 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4260 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.171 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.169, %183, %4242, %10167, %10168, %10169, %4252, %10170, %4256, %4257, %4258, %4259, %4260) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4262 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4263 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4264 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4265 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4266 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.171, %184, %185, %186, %187, %4262, %4263, %4264, %4265) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4267 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11069 : Tensor = aten::type_as(%input.149, %4266)\n  %11267 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4266, %11069, %4267) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4269 : NoneType = prim::Constant()\n  %10171 : int[] = prim::Constant[value=[1, 1]]()\n  %10172 : int[] = prim::Constant[value=[0, 0]]()\n  %10173 : int[] = prim::Constant[value=[1, 1]]()\n  %4279 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10174 : int[] = prim::Constant[value=[0, 0]]()\n  %4283 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4284 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4285 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4286 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4287 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.175 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11267, %189, %4269, %10171, %10172, %10173, %4279, %10174, %4283, %4284, %4285, %4286, %4287) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4289 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4290 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4291 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4292 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.177 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.175, %190, %191, %192, %193, %4289, %4290, %4291, %4292) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11129 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.177) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4295 : NoneType = prim::Constant()\n  %10175 : int[] = prim::Constant[value=[1, 1]]()\n  %10176 : int[] = prim::Constant[value=[1, 1]]()\n  %10177 : int[] = prim::Constant[value=[1, 1]]()\n  %4305 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10178 : int[] = prim::Constant[value=[0, 0]]()\n  %4309 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4310 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4311 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4312 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4313 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.181 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11129, %195, %4295, %10175, %10176, %10177, %4305, %10178, %4309, %4310, %4311, %4312, %4313) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4315 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4316 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4317 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4318 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.183 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.181, %196, %197, %198, %199, %4315, %4316, %4317, %4318) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11130 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.183) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10179 : int[] = prim::Constant[value=[1, 1]]()\n  %input.187 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11130, %10179) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10180 : int[] = prim::Constant[value=[1, 1]]()\n  %10181 : int[] = prim::Constant[value=[0, 0]]()\n  %10182 : int[] = prim::Constant[value=[1, 1]]()\n  %4346 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10183 : int[] = prim::Constant[value=[0, 0]]()\n  %4350 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4351 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4352 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4353 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4354 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.189 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.187, %201, %202, %10180, %10181, %10182, %4346, %10183, %4350, %4351, %4352, %4353, %4354) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11131 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.189) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10184 : int[] = prim::Constant[value=[1, 1]]()\n  %10185 : int[] = prim::Constant[value=[0, 0]]()\n  %10186 : int[] = prim::Constant[value=[1, 1]]()\n  %4366 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10187 : int[] = prim::Constant[value=[0, 0]]()\n  %4370 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4371 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4372 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4373 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4374 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4375 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11131, %203, %204, %10184, %10185, %10186, %4366, %10187, %4370, %4371, %4372, %4373, %4374) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4376 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4375) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.193 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4376, %11130) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4378 : NoneType = prim::Constant()\n  %10188 : int[] = prim::Constant[value=[1, 1]]()\n  %10189 : int[] = prim::Constant[value=[0, 0]]()\n  %10190 : int[] = prim::Constant[value=[1, 1]]()\n  %4388 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10191 : int[] = prim::Constant[value=[0, 0]]()\n  %4392 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4393 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4394 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4395 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4396 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.195 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.193, %205, %4378, %10188, %10189, %10190, %4388, %10191, %4392, %4393, %4394, %4395, %4396) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4398 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4399 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4400 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4401 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4402 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.195, %206, %207, %208, %209, %4398, %4399, %4400, %4401) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4403 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11070 : Tensor = aten::type_as(%11267, %4402)\n  %11268 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4402, %11070, %4403) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4405 : NoneType = prim::Constant()\n  %10192 : int[] = prim::Constant[value=[1, 1]]()\n  %10193 : int[] = prim::Constant[value=[0, 0]]()\n  %10194 : int[] = prim::Constant[value=[1, 1]]()\n  %4415 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10195 : int[] = prim::Constant[value=[0, 0]]()\n  %4419 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4420 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4421 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4422 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4423 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.199 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11268, %211, %4405, %10192, %10193, %10194, %4415, %10195, %4419, %4420, %4421, %4422, %4423) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4425 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4426 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4427 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4428 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.201 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.199, %212, %213, %214, %215, %4425, %4426, %4427, %4428) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11132 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.201) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4431 : NoneType = prim::Constant()\n  %10196 : int[] = prim::Constant[value=[1, 1]]()\n  %10197 : int[] = prim::Constant[value=[1, 1]]()\n  %10198 : int[] = prim::Constant[value=[1, 1]]()\n  %4441 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10199 : int[] = prim::Constant[value=[0, 0]]()\n  %4445 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4446 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4447 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4448 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4449 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.205 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11132, %217, %4431, %10196, %10197, %10198, %4441, %10199, %4445, %4446, %4447, %4448, %4449) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4451 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4452 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4453 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4454 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.207 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.205, %218, %219, %220, %221, %4451, %4452, %4453, %4454) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11133 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.207) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10200 : int[] = prim::Constant[value=[1, 1]]()\n  %input.211 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11133, %10200) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10201 : int[] = prim::Constant[value=[1, 1]]()\n  %10202 : int[] = prim::Constant[value=[0, 0]]()\n  %10203 : int[] = prim::Constant[value=[1, 1]]()\n  %4482 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10204 : int[] = prim::Constant[value=[0, 0]]()\n  %4486 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4487 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4488 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4489 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4490 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.213 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.211, %223, %224, %10201, %10202, %10203, %4482, %10204, %4486, %4487, %4488, %4489, %4490) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11134 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.213) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10205 : int[] = prim::Constant[value=[1, 1]]()\n  %10206 : int[] = prim::Constant[value=[0, 0]]()\n  %10207 : int[] = prim::Constant[value=[1, 1]]()\n  %4502 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10208 : int[] = prim::Constant[value=[0, 0]]()\n  %4506 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4507 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4508 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4509 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4510 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4511 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11134, %225, %226, %10205, %10206, %10207, %4502, %10208, %4506, %4507, %4508, %4509, %4510) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4512 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4511) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.217 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4512, %11133) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4514 : NoneType = prim::Constant()\n  %10209 : int[] = prim::Constant[value=[1, 1]]()\n  %10210 : int[] = prim::Constant[value=[0, 0]]()\n  %10211 : int[] = prim::Constant[value=[1, 1]]()\n  %4524 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10212 : int[] = prim::Constant[value=[0, 0]]()\n  %4528 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4529 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4530 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4531 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4532 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.219 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.217, %227, %4514, %10209, %10210, %10211, %4524, %10212, %4528, %4529, %4530, %4531, %4532) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4534 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4535 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4536 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4537 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4538 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.219, %228, %229, %230, %231, %4534, %4535, %4536, %4537) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4539 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11071 : Tensor = aten::type_as(%11268, %4538)\n  %11269 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4538, %11071, %4539) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4541 : NoneType = prim::Constant()\n  %10213 : int[] = prim::Constant[value=[1, 1]]()\n  %10214 : int[] = prim::Constant[value=[0, 0]]()\n  %10215 : int[] = prim::Constant[value=[1, 1]]()\n  %4551 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10216 : int[] = prim::Constant[value=[0, 0]]()\n  %4555 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4556 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4557 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4558 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4559 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.223 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11269, %233, %4541, %10213, %10214, %10215, %4551, %10216, %4555, %4556, %4557, %4558, %4559) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4561 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4562 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4563 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4564 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.225 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.223, %234, %235, %236, %237, %4561, %4562, %4563, %4564) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11135 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.225) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4567 : NoneType = prim::Constant()\n  %10217 : int[] = prim::Constant[value=[1, 1]]()\n  %10218 : int[] = prim::Constant[value=[1, 1]]()\n  %10219 : int[] = prim::Constant[value=[1, 1]]()\n  %4577 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10220 : int[] = prim::Constant[value=[0, 0]]()\n  %4581 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4582 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4583 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4584 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4585 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.229 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11135, %239, %4567, %10217, %10218, %10219, %4577, %10220, %4581, %4582, %4583, %4584, %4585) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4587 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4588 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4589 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4590 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.231 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.229, %240, %241, %242, %243, %4587, %4588, %4589, %4590) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11136 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.231) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10221 : int[] = prim::Constant[value=[1, 1]]()\n  %input.235 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11136, %10221) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10222 : int[] = prim::Constant[value=[1, 1]]()\n  %10223 : int[] = prim::Constant[value=[0, 0]]()\n  %10224 : int[] = prim::Constant[value=[1, 1]]()\n  %4618 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10225 : int[] = prim::Constant[value=[0, 0]]()\n  %4622 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4623 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4624 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4625 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4626 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.237 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.235, %245, %246, %10222, %10223, %10224, %4618, %10225, %4622, %4623, %4624, %4625, %4626) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11137 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10226 : int[] = prim::Constant[value=[1, 1]]()\n  %10227 : int[] = prim::Constant[value=[0, 0]]()\n  %10228 : int[] = prim::Constant[value=[1, 1]]()\n  %4638 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10229 : int[] = prim::Constant[value=[0, 0]]()\n  %4642 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4643 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4644 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4645 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4646 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4647 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11137, %247, %248, %10226, %10227, %10228, %4638, %10229, %4642, %4643, %4644, %4645, %4646) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4648 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4647) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.241 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4648, %11136) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4650 : NoneType = prim::Constant()\n  %10230 : int[] = prim::Constant[value=[1, 1]]()\n  %10231 : int[] = prim::Constant[value=[0, 0]]()\n  %10232 : int[] = prim::Constant[value=[1, 1]]()\n  %4660 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10233 : int[] = prim::Constant[value=[0, 0]]()\n  %4664 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4665 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4666 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4667 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4668 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.243 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.241, %249, %4650, %10230, %10231, %10232, %4660, %10233, %4664, %4665, %4666, %4667, %4668) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4670 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4671 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4672 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4673 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4674 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.243, %250, %251, %252, %253, %4670, %4671, %4672, %4673) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4675 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11072 : Tensor = aten::type_as(%11269, %4674)\n  %11270 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4674, %11072, %4675) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4677 : NoneType = prim::Constant()\n  %10234 : int[] = prim::Constant[value=[1, 1]]()\n  %10235 : int[] = prim::Constant[value=[0, 0]]()\n  %10236 : int[] = prim::Constant[value=[1, 1]]()\n  %4687 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10237 : int[] = prim::Constant[value=[0, 0]]()\n  %4691 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4692 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4693 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4694 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4695 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.247 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11270, %255, %4677, %10234, %10235, %10236, %4687, %10237, %4691, %4692, %4693, %4694, %4695) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4697 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4698 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4699 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4700 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.249 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.247, %256, %257, %258, %259, %4697, %4698, %4699, %4700) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11138 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.249) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4703 : NoneType = prim::Constant()\n  %10238 : int[] = prim::Constant[value=[1, 1]]()\n  %10239 : int[] = prim::Constant[value=[1, 1]]()\n  %10240 : int[] = prim::Constant[value=[1, 1]]()\n  %4713 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10241 : int[] = prim::Constant[value=[0, 0]]()\n  %4717 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4718 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4719 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4720 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4721 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.253 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11138, %261, %4703, %10238, %10239, %10240, %4713, %10241, %4717, %4718, %4719, %4720, %4721) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4723 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4724 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4725 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4726 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.255 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.253, %262, %263, %264, %265, %4723, %4724, %4725, %4726) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11139 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.255) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10242 : int[] = prim::Constant[value=[1, 1]]()\n  %input.259 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11139, %10242) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10243 : int[] = prim::Constant[value=[1, 1]]()\n  %10244 : int[] = prim::Constant[value=[0, 0]]()\n  %10245 : int[] = prim::Constant[value=[1, 1]]()\n  %4754 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10246 : int[] = prim::Constant[value=[0, 0]]()\n  %4758 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4759 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4760 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4761 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4762 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.261 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.259, %267, %268, %10243, %10244, %10245, %4754, %10246, %4758, %4759, %4760, %4761, %4762) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11140 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.261) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10247 : int[] = prim::Constant[value=[1, 1]]()\n  %10248 : int[] = prim::Constant[value=[0, 0]]()\n  %10249 : int[] = prim::Constant[value=[1, 1]]()\n  %4774 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10250 : int[] = prim::Constant[value=[0, 0]]()\n  %4778 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4779 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4780 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4781 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4782 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4783 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11140, %269, %270, %10247, %10248, %10249, %4774, %10250, %4778, %4779, %4780, %4781, %4782) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4784 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4783) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.265 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4784, %11139) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4786 : NoneType = prim::Constant()\n  %10251 : int[] = prim::Constant[value=[1, 1]]()\n  %10252 : int[] = prim::Constant[value=[0, 0]]()\n  %10253 : int[] = prim::Constant[value=[1, 1]]()\n  %4796 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10254 : int[] = prim::Constant[value=[0, 0]]()\n  %4800 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4801 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4802 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4803 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4804 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.267 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.265, %271, %4786, %10251, %10252, %10253, %4796, %10254, %4800, %4801, %4802, %4803, %4804) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4806 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4807 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4808 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4809 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4810 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.267, %272, %273, %274, %275, %4806, %4807, %4808, %4809) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4811 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11073 : Tensor = aten::type_as(%11270, %4810)\n  %11271 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4810, %11073, %4811) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4813 : NoneType = prim::Constant()\n  %10255 : int[] = prim::Constant[value=[1, 1]]()\n  %10256 : int[] = prim::Constant[value=[0, 0]]()\n  %10257 : int[] = prim::Constant[value=[1, 1]]()\n  %4823 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10258 : int[] = prim::Constant[value=[0, 0]]()\n  %4827 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4828 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4829 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4830 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4831 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.271 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11271, %277, %4813, %10255, %10256, %10257, %4823, %10258, %4827, %4828, %4829, %4830, %4831) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4833 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4834 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4835 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4836 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.273 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.271, %278, %279, %280, %281, %4833, %4834, %4835, %4836) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11141 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.273) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4839 : NoneType = prim::Constant()\n  %10259 : int[] = prim::Constant[value=[1, 1]]()\n  %10260 : int[] = prim::Constant[value=[1, 1]]()\n  %10261 : int[] = prim::Constant[value=[1, 1]]()\n  %4849 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10262 : int[] = prim::Constant[value=[0, 0]]()\n  %4853 : int = prim::Constant[value=640]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4854 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4855 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4856 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4857 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.277 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11141, %283, %4839, %10259, %10260, %10261, %4849, %10262, %4853, %4854, %4855, %4856, %4857) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4859 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4860 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4861 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4862 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.279 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.277, %284, %285, %286, %287, %4859, %4860, %4861, %4862) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11142 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.279) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10263 : int[] = prim::Constant[value=[1, 1]]()\n  %input.283 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11142, %10263) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10264 : int[] = prim::Constant[value=[1, 1]]()\n  %10265 : int[] = prim::Constant[value=[0, 0]]()\n  %10266 : int[] = prim::Constant[value=[1, 1]]()\n  %4890 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10267 : int[] = prim::Constant[value=[0, 0]]()\n  %4894 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4895 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4896 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4897 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4898 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.285 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.283, %289, %290, %10264, %10265, %10266, %4890, %10267, %4894, %4895, %4896, %4897, %4898) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11143 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.285) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10268 : int[] = prim::Constant[value=[1, 1]]()\n  %10269 : int[] = prim::Constant[value=[0, 0]]()\n  %10270 : int[] = prim::Constant[value=[1, 1]]()\n  %4910 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10271 : int[] = prim::Constant[value=[0, 0]]()\n  %4914 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4915 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4916 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4917 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4918 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4919 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11143, %291, %292, %10268, %10269, %10270, %4910, %10271, %4914, %4915, %4916, %4917, %4918) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4920 : Float(32, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%4919) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.289 : Float(32, 640, 30, 30, strides=[576000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%4920, %11142) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %4922 : NoneType = prim::Constant()\n  %10272 : int[] = prim::Constant[value=[1, 1]]()\n  %10273 : int[] = prim::Constant[value=[0, 0]]()\n  %10274 : int[] = prim::Constant[value=[1, 1]]()\n  %4932 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10275 : int[] = prim::Constant[value=[0, 0]]()\n  %4936 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4937 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4938 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4939 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4940 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.291 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.289, %293, %4922, %10272, %10273, %10274, %4932, %10275, %4936, %4937, %4938, %4939, %4940) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4942 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4943 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4944 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4945 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4946 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.291, %294, %295, %296, %297, %4942, %4943, %4944, %4945) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4947 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11074 : Tensor = aten::type_as(%11271, %4946)\n  %11272 : Float(32, 160, 30, 30, strides=[144000, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%4946, %11074, %4947) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %4949 : NoneType = prim::Constant()\n  %10276 : int[] = prim::Constant[value=[1, 1]]()\n  %10277 : int[] = prim::Constant[value=[0, 0]]()\n  %10278 : int[] = prim::Constant[value=[1, 1]]()\n  %4959 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10279 : int[] = prim::Constant[value=[0, 0]]()\n  %4963 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4964 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4965 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4966 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4967 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.295 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11272, %299, %4949, %10276, %10277, %10278, %4959, %10279, %4963, %4964, %4965, %4966, %4967) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4969 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4970 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4971 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4972 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.297 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.295, %300, %301, %302, %303, %4969, %4970, %4971, %4972) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11144 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.297) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %4975 : NoneType = prim::Constant()\n  %10280 : int[] = prim::Constant[value=[1, 1]]()\n  %10281 : int[] = prim::Constant[value=[1, 1]]()\n  %10282 : int[] = prim::Constant[value=[1, 1]]()\n  %4985 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10283 : int[] = prim::Constant[value=[0, 0]]()\n  %4989 : int = prim::Constant[value=960]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4990 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4991 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4992 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4993 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.301 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11144, %305, %4975, %10280, %10281, %10282, %4985, %10283, %4989, %4990, %4991, %4992, %4993) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %4995 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4996 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4997 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %4998 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.303 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.301, %306, %307, %308, %309, %4995, %4996, %4997, %4998) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11145 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.303) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10284 : int[] = prim::Constant[value=[1, 1]]()\n  %input.307 : Float(32, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11145, %10284) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10285 : int[] = prim::Constant[value=[1, 1]]()\n  %10286 : int[] = prim::Constant[value=[0, 0]]()\n  %10287 : int[] = prim::Constant[value=[1, 1]]()\n  %5026 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10288 : int[] = prim::Constant[value=[0, 0]]()\n  %5030 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5031 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5032 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5033 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5034 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.309 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.307, %311, %312, %10285, %10286, %10287, %5026, %10288, %5030, %5031, %5032, %5033, %5034) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11146 : Float(32, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.309) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10289 : int[] = prim::Constant[value=[1, 1]]()\n  %10290 : int[] = prim::Constant[value=[0, 0]]()\n  %10291 : int[] = prim::Constant[value=[1, 1]]()\n  %5046 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10292 : int[] = prim::Constant[value=[0, 0]]()\n  %5050 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5051 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5052 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5053 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5054 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5055 : Float(32, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11146, %313, %314, %10289, %10290, %10291, %5046, %10292, %5050, %5051, %5052, %5053, %5054) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5056 : Float(32, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5055) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.313 : Float(32, 960, 30, 30, strides=[864000, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5056, %11145) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5058 : NoneType = prim::Constant()\n  %10293 : int[] = prim::Constant[value=[1, 1]]()\n  %10294 : int[] = prim::Constant[value=[0, 0]]()\n  %10295 : int[] = prim::Constant[value=[1, 1]]()\n  %5068 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10296 : int[] = prim::Constant[value=[0, 0]]()\n  %5072 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5073 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5074 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5075 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5076 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.315 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.313, %315, %5058, %10293, %10294, %10295, %5068, %10296, %5072, %5073, %5074, %5075, %5076) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5078 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5079 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5080 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5081 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.317 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.315, %316, %317, %318, %319, %5078, %5079, %5080, %5081) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5083 : NoneType = prim::Constant()\n  %10297 : int[] = prim::Constant[value=[1, 1]]()\n  %10298 : int[] = prim::Constant[value=[0, 0]]()\n  %10299 : int[] = prim::Constant[value=[1, 1]]()\n  %5093 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10300 : int[] = prim::Constant[value=[0, 0]]()\n  %5097 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5098 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5099 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5100 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5101 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.319 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.317, %321, %5083, %10297, %10298, %10299, %5093, %10300, %5097, %5098, %5099, %5100, %5101) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5103 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5104 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5105 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5106 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.321 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.319, %322, %323, %324, %325, %5103, %5104, %5105, %5106) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11147 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.321) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5109 : NoneType = prim::Constant()\n  %10301 : int[] = prim::Constant[value=[1, 1]]()\n  %10302 : int[] = prim::Constant[value=[1, 1]]()\n  %10303 : int[] = prim::Constant[value=[1, 1]]()\n  %5119 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10304 : int[] = prim::Constant[value=[0, 0]]()\n  %5123 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5124 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5125 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5126 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5127 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.325 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11147, %327, %5109, %10301, %10302, %10303, %5119, %10304, %5123, %5124, %5125, %5126, %5127) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5129 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5130 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5131 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5132 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.327 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.325, %328, %329, %330, %331, %5129, %5130, %5131, %5132) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11148 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.327) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10305 : int[] = prim::Constant[value=[1, 1]]()\n  %input.331 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11148, %10305) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10306 : int[] = prim::Constant[value=[1, 1]]()\n  %10307 : int[] = prim::Constant[value=[0, 0]]()\n  %10308 : int[] = prim::Constant[value=[1, 1]]()\n  %5160 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10309 : int[] = prim::Constant[value=[0, 0]]()\n  %5164 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5165 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5166 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5167 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5168 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.333 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.331, %333, %334, %10306, %10307, %10308, %5160, %10309, %5164, %5165, %5166, %5167, %5168) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11149 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.333) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10310 : int[] = prim::Constant[value=[1, 1]]()\n  %10311 : int[] = prim::Constant[value=[0, 0]]()\n  %10312 : int[] = prim::Constant[value=[1, 1]]()\n  %5180 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10313 : int[] = prim::Constant[value=[0, 0]]()\n  %5184 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5185 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5186 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5187 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5188 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5189 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11149, %335, %336, %10310, %10311, %10312, %5180, %10313, %5184, %5185, %5186, %5187, %5188) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5190 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5189) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.337 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5190, %11148) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5192 : NoneType = prim::Constant()\n  %10314 : int[] = prim::Constant[value=[1, 1]]()\n  %10315 : int[] = prim::Constant[value=[0, 0]]()\n  %10316 : int[] = prim::Constant[value=[1, 1]]()\n  %5202 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10317 : int[] = prim::Constant[value=[0, 0]]()\n  %5206 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5207 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5208 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5209 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5210 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.339 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.337, %337, %5192, %10314, %10315, %10316, %5202, %10317, %5206, %5207, %5208, %5209, %5210) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5212 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5213 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5214 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5215 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5216 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.339, %338, %339, %340, %341, %5212, %5213, %5214, %5215) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5217 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11075 : Tensor = aten::type_as(%input.317, %5216)\n  %11273 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5216, %11075, %5217) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5219 : NoneType = prim::Constant()\n  %10318 : int[] = prim::Constant[value=[1, 1]]()\n  %10319 : int[] = prim::Constant[value=[0, 0]]()\n  %10320 : int[] = prim::Constant[value=[1, 1]]()\n  %5229 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10321 : int[] = prim::Constant[value=[0, 0]]()\n  %5233 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5234 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5235 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5236 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5237 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.343 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11273, %343, %5219, %10318, %10319, %10320, %5229, %10321, %5233, %5234, %5235, %5236, %5237) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5239 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5240 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5241 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5242 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.345 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.343, %344, %345, %346, %347, %5239, %5240, %5241, %5242) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11150 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.345) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5245 : NoneType = prim::Constant()\n  %10322 : int[] = prim::Constant[value=[1, 1]]()\n  %10323 : int[] = prim::Constant[value=[1, 1]]()\n  %10324 : int[] = prim::Constant[value=[1, 1]]()\n  %5255 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10325 : int[] = prim::Constant[value=[0, 0]]()\n  %5259 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5260 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5261 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5262 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5263 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.349 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11150, %349, %5245, %10322, %10323, %10324, %5255, %10325, %5259, %5260, %5261, %5262, %5263) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5265 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5266 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5267 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5268 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.351 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.349, %350, %351, %352, %353, %5265, %5266, %5267, %5268) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11151 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.351) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10326 : int[] = prim::Constant[value=[1, 1]]()\n  %input.355 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11151, %10326) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10327 : int[] = prim::Constant[value=[1, 1]]()\n  %10328 : int[] = prim::Constant[value=[0, 0]]()\n  %10329 : int[] = prim::Constant[value=[1, 1]]()\n  %5296 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10330 : int[] = prim::Constant[value=[0, 0]]()\n  %5300 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5301 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5302 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5303 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5304 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.357 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.355, %355, %356, %10327, %10328, %10329, %5296, %10330, %5300, %5301, %5302, %5303, %5304) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11152 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.357) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10331 : int[] = prim::Constant[value=[1, 1]]()\n  %10332 : int[] = prim::Constant[value=[0, 0]]()\n  %10333 : int[] = prim::Constant[value=[1, 1]]()\n  %5316 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10334 : int[] = prim::Constant[value=[0, 0]]()\n  %5320 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5321 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5322 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5323 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5324 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5325 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11152, %357, %358, %10331, %10332, %10333, %5316, %10334, %5320, %5321, %5322, %5323, %5324) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5326 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5325) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.361 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5326, %11151) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5328 : NoneType = prim::Constant()\n  %10335 : int[] = prim::Constant[value=[1, 1]]()\n  %10336 : int[] = prim::Constant[value=[0, 0]]()\n  %10337 : int[] = prim::Constant[value=[1, 1]]()\n  %5338 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10338 : int[] = prim::Constant[value=[0, 0]]()\n  %5342 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5343 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5344 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5345 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5346 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.363 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.361, %359, %5328, %10335, %10336, %10337, %5338, %10338, %5342, %5343, %5344, %5345, %5346) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5348 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5349 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5350 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5351 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5352 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.363, %360, %361, %362, %363, %5348, %5349, %5350, %5351) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5353 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11076 : Tensor = aten::type_as(%11273, %5352)\n  %11274 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5352, %11076, %5353) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5355 : NoneType = prim::Constant()\n  %10339 : int[] = prim::Constant[value=[1, 1]]()\n  %10340 : int[] = prim::Constant[value=[0, 0]]()\n  %10341 : int[] = prim::Constant[value=[1, 1]]()\n  %5365 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10342 : int[] = prim::Constant[value=[0, 0]]()\n  %5369 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5370 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5371 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5372 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5373 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.367 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11274, %365, %5355, %10339, %10340, %10341, %5365, %10342, %5369, %5370, %5371, %5372, %5373) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5375 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5376 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5377 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5378 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.369 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.367, %366, %367, %368, %369, %5375, %5376, %5377, %5378) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11153 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.369) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5381 : NoneType = prim::Constant()\n  %10343 : int[] = prim::Constant[value=[1, 1]]()\n  %10344 : int[] = prim::Constant[value=[1, 1]]()\n  %10345 : int[] = prim::Constant[value=[1, 1]]()\n  %5391 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10346 : int[] = prim::Constant[value=[0, 0]]()\n  %5395 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5396 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5397 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5398 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5399 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.373 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11153, %371, %5381, %10343, %10344, %10345, %5391, %10346, %5395, %5396, %5397, %5398, %5399) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5401 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5402 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5403 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5404 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.375 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.373, %372, %373, %374, %375, %5401, %5402, %5403, %5404) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11154 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.375) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10347 : int[] = prim::Constant[value=[1, 1]]()\n  %input.379 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11154, %10347) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10348 : int[] = prim::Constant[value=[1, 1]]()\n  %10349 : int[] = prim::Constant[value=[0, 0]]()\n  %10350 : int[] = prim::Constant[value=[1, 1]]()\n  %5432 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10351 : int[] = prim::Constant[value=[0, 0]]()\n  %5436 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5437 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5438 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5439 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5440 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.381 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.379, %377, %378, %10348, %10349, %10350, %5432, %10351, %5436, %5437, %5438, %5439, %5440) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11155 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.381) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10352 : int[] = prim::Constant[value=[1, 1]]()\n  %10353 : int[] = prim::Constant[value=[0, 0]]()\n  %10354 : int[] = prim::Constant[value=[1, 1]]()\n  %5452 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10355 : int[] = prim::Constant[value=[0, 0]]()\n  %5456 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5457 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5458 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5459 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5460 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5461 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11155, %379, %380, %10352, %10353, %10354, %5452, %10355, %5456, %5457, %5458, %5459, %5460) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5462 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5461) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.385 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5462, %11154) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5464 : NoneType = prim::Constant()\n  %10356 : int[] = prim::Constant[value=[1, 1]]()\n  %10357 : int[] = prim::Constant[value=[0, 0]]()\n  %10358 : int[] = prim::Constant[value=[1, 1]]()\n  %5474 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10359 : int[] = prim::Constant[value=[0, 0]]()\n  %5478 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5479 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5480 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5481 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5482 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.387 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.385, %381, %5464, %10356, %10357, %10358, %5474, %10359, %5478, %5479, %5480, %5481, %5482) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5484 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5485 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5486 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5487 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5488 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.387, %382, %383, %384, %385, %5484, %5485, %5486, %5487) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5489 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11077 : Tensor = aten::type_as(%11274, %5488)\n  %11275 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5488, %11077, %5489) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5491 : NoneType = prim::Constant()\n  %10360 : int[] = prim::Constant[value=[1, 1]]()\n  %10361 : int[] = prim::Constant[value=[0, 0]]()\n  %10362 : int[] = prim::Constant[value=[1, 1]]()\n  %5501 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10363 : int[] = prim::Constant[value=[0, 0]]()\n  %5505 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5506 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5507 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5508 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5509 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.391 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11275, %387, %5491, %10360, %10361, %10362, %5501, %10363, %5505, %5506, %5507, %5508, %5509) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5511 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5512 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5513 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5514 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.393 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.391, %388, %389, %390, %391, %5511, %5512, %5513, %5514) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11156 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.393) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5517 : NoneType = prim::Constant()\n  %10364 : int[] = prim::Constant[value=[1, 1]]()\n  %10365 : int[] = prim::Constant[value=[1, 1]]()\n  %10366 : int[] = prim::Constant[value=[1, 1]]()\n  %5527 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10367 : int[] = prim::Constant[value=[0, 0]]()\n  %5531 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5532 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5533 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5534 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5535 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.397 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11156, %393, %5517, %10364, %10365, %10366, %5527, %10367, %5531, %5532, %5533, %5534, %5535) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5537 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5538 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5539 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5540 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.399 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.397, %394, %395, %396, %397, %5537, %5538, %5539, %5540) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11157 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.399) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10368 : int[] = prim::Constant[value=[1, 1]]()\n  %input.403 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11157, %10368) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10369 : int[] = prim::Constant[value=[1, 1]]()\n  %10370 : int[] = prim::Constant[value=[0, 0]]()\n  %10371 : int[] = prim::Constant[value=[1, 1]]()\n  %5568 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10372 : int[] = prim::Constant[value=[0, 0]]()\n  %5572 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5573 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5574 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5575 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5576 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.405 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.403, %399, %400, %10369, %10370, %10371, %5568, %10372, %5572, %5573, %5574, %5575, %5576) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11158 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.405) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10373 : int[] = prim::Constant[value=[1, 1]]()\n  %10374 : int[] = prim::Constant[value=[0, 0]]()\n  %10375 : int[] = prim::Constant[value=[1, 1]]()\n  %5588 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10376 : int[] = prim::Constant[value=[0, 0]]()\n  %5592 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5593 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5594 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5595 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5596 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5597 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11158, %401, %402, %10373, %10374, %10375, %5588, %10376, %5592, %5593, %5594, %5595, %5596) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5598 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5597) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.409 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5598, %11157) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5600 : NoneType = prim::Constant()\n  %10377 : int[] = prim::Constant[value=[1, 1]]()\n  %10378 : int[] = prim::Constant[value=[0, 0]]()\n  %10379 : int[] = prim::Constant[value=[1, 1]]()\n  %5610 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10380 : int[] = prim::Constant[value=[0, 0]]()\n  %5614 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5615 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5616 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5617 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5618 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.411 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.409, %403, %5600, %10377, %10378, %10379, %5610, %10380, %5614, %5615, %5616, %5617, %5618) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5620 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5621 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5622 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5623 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5624 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.411, %404, %405, %406, %407, %5620, %5621, %5622, %5623) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5625 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11078 : Tensor = aten::type_as(%11275, %5624)\n  %11276 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5624, %11078, %5625) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5627 : NoneType = prim::Constant()\n  %10381 : int[] = prim::Constant[value=[1, 1]]()\n  %10382 : int[] = prim::Constant[value=[0, 0]]()\n  %10383 : int[] = prim::Constant[value=[1, 1]]()\n  %5637 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10384 : int[] = prim::Constant[value=[0, 0]]()\n  %5641 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5642 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5643 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5644 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5645 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.415 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11276, %409, %5627, %10381, %10382, %10383, %5637, %10384, %5641, %5642, %5643, %5644, %5645) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5647 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5648 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5649 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5650 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.417 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.415, %410, %411, %412, %413, %5647, %5648, %5649, %5650) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11159 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.417) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5653 : NoneType = prim::Constant()\n  %10385 : int[] = prim::Constant[value=[1, 1]]()\n  %10386 : int[] = prim::Constant[value=[1, 1]]()\n  %10387 : int[] = prim::Constant[value=[1, 1]]()\n  %5663 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10388 : int[] = prim::Constant[value=[0, 0]]()\n  %5667 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5668 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5669 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5670 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5671 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.421 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11159, %415, %5653, %10385, %10386, %10387, %5663, %10388, %5667, %5668, %5669, %5670, %5671) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5673 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5674 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5675 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5676 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.423 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.421, %416, %417, %418, %419, %5673, %5674, %5675, %5676) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11160 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.423) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10389 : int[] = prim::Constant[value=[1, 1]]()\n  %input.427 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11160, %10389) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10390 : int[] = prim::Constant[value=[1, 1]]()\n  %10391 : int[] = prim::Constant[value=[0, 0]]()\n  %10392 : int[] = prim::Constant[value=[1, 1]]()\n  %5704 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10393 : int[] = prim::Constant[value=[0, 0]]()\n  %5708 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5709 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5710 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5711 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5712 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.429 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.427, %421, %422, %10390, %10391, %10392, %5704, %10393, %5708, %5709, %5710, %5711, %5712) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11161 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.429) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10394 : int[] = prim::Constant[value=[1, 1]]()\n  %10395 : int[] = prim::Constant[value=[0, 0]]()\n  %10396 : int[] = prim::Constant[value=[1, 1]]()\n  %5724 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10397 : int[] = prim::Constant[value=[0, 0]]()\n  %5728 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5729 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5730 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5731 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5732 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5733 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11161, %423, %424, %10394, %10395, %10396, %5724, %10397, %5728, %5729, %5730, %5731, %5732) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5734 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5733) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.433 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5734, %11160) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5736 : NoneType = prim::Constant()\n  %10398 : int[] = prim::Constant[value=[1, 1]]()\n  %10399 : int[] = prim::Constant[value=[0, 0]]()\n  %10400 : int[] = prim::Constant[value=[1, 1]]()\n  %5746 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10401 : int[] = prim::Constant[value=[0, 0]]()\n  %5750 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5751 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5752 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5753 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5754 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.435 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.433, %425, %5736, %10398, %10399, %10400, %5746, %10401, %5750, %5751, %5752, %5753, %5754) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5756 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5757 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5758 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5759 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5760 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.435, %426, %427, %428, %429, %5756, %5757, %5758, %5759) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5761 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11079 : Tensor = aten::type_as(%11276, %5760)\n  %11277 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5760, %11079, %5761) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5763 : NoneType = prim::Constant()\n  %10402 : int[] = prim::Constant[value=[1, 1]]()\n  %10403 : int[] = prim::Constant[value=[0, 0]]()\n  %10404 : int[] = prim::Constant[value=[1, 1]]()\n  %5773 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10405 : int[] = prim::Constant[value=[0, 0]]()\n  %5777 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5778 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5779 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5780 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5781 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.439 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11277, %431, %5763, %10402, %10403, %10404, %5773, %10405, %5777, %5778, %5779, %5780, %5781) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5783 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5784 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5785 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5786 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.441 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.439, %432, %433, %434, %435, %5783, %5784, %5785, %5786) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11162 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.441) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5789 : NoneType = prim::Constant()\n  %10406 : int[] = prim::Constant[value=[1, 1]]()\n  %10407 : int[] = prim::Constant[value=[1, 1]]()\n  %10408 : int[] = prim::Constant[value=[1, 1]]()\n  %5799 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10409 : int[] = prim::Constant[value=[0, 0]]()\n  %5803 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5804 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5805 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5806 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5807 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.445 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11162, %437, %5789, %10406, %10407, %10408, %5799, %10409, %5803, %5804, %5805, %5806, %5807) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5809 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5810 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5811 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5812 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.447 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.445, %438, %439, %440, %441, %5809, %5810, %5811, %5812) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11163 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.447) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10410 : int[] = prim::Constant[value=[1, 1]]()\n  %input.451 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11163, %10410) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10411 : int[] = prim::Constant[value=[1, 1]]()\n  %10412 : int[] = prim::Constant[value=[0, 0]]()\n  %10413 : int[] = prim::Constant[value=[1, 1]]()\n  %5840 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10414 : int[] = prim::Constant[value=[0, 0]]()\n  %5844 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5845 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5846 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5847 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5848 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.453 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.451, %443, %444, %10411, %10412, %10413, %5840, %10414, %5844, %5845, %5846, %5847, %5848) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11164 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.453) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10415 : int[] = prim::Constant[value=[1, 1]]()\n  %10416 : int[] = prim::Constant[value=[0, 0]]()\n  %10417 : int[] = prim::Constant[value=[1, 1]]()\n  %5860 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10418 : int[] = prim::Constant[value=[0, 0]]()\n  %5864 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5865 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5866 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5867 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5868 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5869 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11164, %445, %446, %10415, %10416, %10417, %5860, %10418, %5864, %5865, %5866, %5867, %5868) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5870 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%5869) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.457 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%5870, %11163) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %5872 : NoneType = prim::Constant()\n  %10419 : int[] = prim::Constant[value=[1, 1]]()\n  %10420 : int[] = prim::Constant[value=[0, 0]]()\n  %10421 : int[] = prim::Constant[value=[1, 1]]()\n  %5882 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10422 : int[] = prim::Constant[value=[0, 0]]()\n  %5886 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5887 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5888 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5889 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5890 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.459 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.457, %447, %5872, %10419, %10420, %10421, %5882, %10422, %5886, %5887, %5888, %5889, %5890) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5892 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5893 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5894 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5895 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5896 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.459, %448, %449, %450, %451, %5892, %5893, %5894, %5895) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5897 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11080 : Tensor = aten::type_as(%11277, %5896)\n  %11278 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%5896, %11080, %5897) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %5899 : NoneType = prim::Constant()\n  %10423 : int[] = prim::Constant[value=[1, 1]]()\n  %10424 : int[] = prim::Constant[value=[0, 0]]()\n  %10425 : int[] = prim::Constant[value=[1, 1]]()\n  %5909 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10426 : int[] = prim::Constant[value=[0, 0]]()\n  %5913 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5914 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5915 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5916 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5917 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.463 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11278, %453, %5899, %10423, %10424, %10425, %5909, %10426, %5913, %5914, %5915, %5916, %5917) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5919 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5920 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5921 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5922 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.465 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.463, %454, %455, %456, %457, %5919, %5920, %5921, %5922) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11165 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.465) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %5925 : NoneType = prim::Constant()\n  %10427 : int[] = prim::Constant[value=[1, 1]]()\n  %10428 : int[] = prim::Constant[value=[1, 1]]()\n  %10429 : int[] = prim::Constant[value=[1, 1]]()\n  %5935 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10430 : int[] = prim::Constant[value=[0, 0]]()\n  %5939 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5940 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5941 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5942 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5943 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.469 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11165, %459, %5925, %10427, %10428, %10429, %5935, %10430, %5939, %5940, %5941, %5942, %5943) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5945 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5946 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5947 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %5948 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.471 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.469, %460, %461, %462, %463, %5945, %5946, %5947, %5948) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11166 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.471) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10431 : int[] = prim::Constant[value=[1, 1]]()\n  %input.475 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11166, %10431) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10432 : int[] = prim::Constant[value=[1, 1]]()\n  %10433 : int[] = prim::Constant[value=[0, 0]]()\n  %10434 : int[] = prim::Constant[value=[1, 1]]()\n  %5976 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10435 : int[] = prim::Constant[value=[0, 0]]()\n  %5980 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5981 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5982 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5983 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %5984 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.477 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.475, %465, %466, %10432, %10433, %10434, %5976, %10435, %5980, %5981, %5982, %5983, %5984) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11167 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.477) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10436 : int[] = prim::Constant[value=[1, 1]]()\n  %10437 : int[] = prim::Constant[value=[0, 0]]()\n  %10438 : int[] = prim::Constant[value=[1, 1]]()\n  %5996 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10439 : int[] = prim::Constant[value=[0, 0]]()\n  %6000 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6001 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6002 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6003 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6004 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6005 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11167, %467, %468, %10436, %10437, %10438, %5996, %10439, %6000, %6001, %6002, %6003, %6004) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6006 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6005) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.481 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6006, %11166) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6008 : NoneType = prim::Constant()\n  %10440 : int[] = prim::Constant[value=[1, 1]]()\n  %10441 : int[] = prim::Constant[value=[0, 0]]()\n  %10442 : int[] = prim::Constant[value=[1, 1]]()\n  %6018 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10443 : int[] = prim::Constant[value=[0, 0]]()\n  %6022 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6023 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6024 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6025 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6026 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.483 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.481, %469, %6008, %10440, %10441, %10442, %6018, %10443, %6022, %6023, %6024, %6025, %6026) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6028 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6029 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6030 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6031 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6032 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.483, %470, %471, %472, %473, %6028, %6029, %6030, %6031) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6033 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11081 : Tensor = aten::type_as(%11278, %6032)\n  %11279 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6032, %11081, %6033) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6035 : NoneType = prim::Constant()\n  %10444 : int[] = prim::Constant[value=[1, 1]]()\n  %10445 : int[] = prim::Constant[value=[0, 0]]()\n  %10446 : int[] = prim::Constant[value=[1, 1]]()\n  %6045 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10447 : int[] = prim::Constant[value=[0, 0]]()\n  %6049 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6050 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6051 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6052 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6053 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.487 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11279, %475, %6035, %10444, %10445, %10446, %6045, %10447, %6049, %6050, %6051, %6052, %6053) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6055 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6056 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6057 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6058 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.489 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.487, %476, %477, %478, %479, %6055, %6056, %6057, %6058) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11168 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.489) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6061 : NoneType = prim::Constant()\n  %10448 : int[] = prim::Constant[value=[1, 1]]()\n  %10449 : int[] = prim::Constant[value=[1, 1]]()\n  %10450 : int[] = prim::Constant[value=[1, 1]]()\n  %6071 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10451 : int[] = prim::Constant[value=[0, 0]]()\n  %6075 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6076 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6077 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6078 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6079 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.493 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11168, %481, %6061, %10448, %10449, %10450, %6071, %10451, %6075, %6076, %6077, %6078, %6079) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6081 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6082 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6083 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6084 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.495 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.493, %482, %483, %484, %485, %6081, %6082, %6083, %6084) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11169 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.495) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10452 : int[] = prim::Constant[value=[1, 1]]()\n  %input.499 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11169, %10452) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10453 : int[] = prim::Constant[value=[1, 1]]()\n  %10454 : int[] = prim::Constant[value=[0, 0]]()\n  %10455 : int[] = prim::Constant[value=[1, 1]]()\n  %6112 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10456 : int[] = prim::Constant[value=[0, 0]]()\n  %6116 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6117 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6118 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6119 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6120 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.501 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.499, %487, %488, %10453, %10454, %10455, %6112, %10456, %6116, %6117, %6118, %6119, %6120) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11170 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.501) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10457 : int[] = prim::Constant[value=[1, 1]]()\n  %10458 : int[] = prim::Constant[value=[0, 0]]()\n  %10459 : int[] = prim::Constant[value=[1, 1]]()\n  %6132 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10460 : int[] = prim::Constant[value=[0, 0]]()\n  %6136 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6137 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6138 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6139 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6140 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6141 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11170, %489, %490, %10457, %10458, %10459, %6132, %10460, %6136, %6137, %6138, %6139, %6140) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6142 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6141) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.505 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6142, %11169) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6144 : NoneType = prim::Constant()\n  %10461 : int[] = prim::Constant[value=[1, 1]]()\n  %10462 : int[] = prim::Constant[value=[0, 0]]()\n  %10463 : int[] = prim::Constant[value=[1, 1]]()\n  %6154 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10464 : int[] = prim::Constant[value=[0, 0]]()\n  %6158 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6159 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6160 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6161 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6162 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.507 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.505, %491, %6144, %10461, %10462, %10463, %6154, %10464, %6158, %6159, %6160, %6161, %6162) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6164 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6165 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6166 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6167 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6168 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.507, %492, %493, %494, %495, %6164, %6165, %6166, %6167) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6169 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11082 : Tensor = aten::type_as(%11279, %6168)\n  %11280 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6168, %11082, %6169) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6171 : NoneType = prim::Constant()\n  %10465 : int[] = prim::Constant[value=[1, 1]]()\n  %10466 : int[] = prim::Constant[value=[0, 0]]()\n  %10467 : int[] = prim::Constant[value=[1, 1]]()\n  %6181 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10468 : int[] = prim::Constant[value=[0, 0]]()\n  %6185 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6186 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6187 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6188 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6189 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.511 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11280, %497, %6171, %10465, %10466, %10467, %6181, %10468, %6185, %6186, %6187, %6188, %6189) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6191 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6192 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6193 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6194 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.513 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.511, %498, %499, %500, %501, %6191, %6192, %6193, %6194) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11171 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.513) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6197 : NoneType = prim::Constant()\n  %10469 : int[] = prim::Constant[value=[1, 1]]()\n  %10470 : int[] = prim::Constant[value=[1, 1]]()\n  %10471 : int[] = prim::Constant[value=[1, 1]]()\n  %6207 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10472 : int[] = prim::Constant[value=[0, 0]]()\n  %6211 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6212 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6213 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6214 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6215 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.517 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11171, %503, %6197, %10469, %10470, %10471, %6207, %10472, %6211, %6212, %6213, %6214, %6215) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6217 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6218 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6219 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6220 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.519 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.517, %504, %505, %506, %507, %6217, %6218, %6219, %6220) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11172 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.519) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10473 : int[] = prim::Constant[value=[1, 1]]()\n  %input.523 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11172, %10473) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10474 : int[] = prim::Constant[value=[1, 1]]()\n  %10475 : int[] = prim::Constant[value=[0, 0]]()\n  %10476 : int[] = prim::Constant[value=[1, 1]]()\n  %6248 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10477 : int[] = prim::Constant[value=[0, 0]]()\n  %6252 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6253 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6254 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6255 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6256 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.525 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.523, %509, %510, %10474, %10475, %10476, %6248, %10477, %6252, %6253, %6254, %6255, %6256) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11173 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.525) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10478 : int[] = prim::Constant[value=[1, 1]]()\n  %10479 : int[] = prim::Constant[value=[0, 0]]()\n  %10480 : int[] = prim::Constant[value=[1, 1]]()\n  %6268 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10481 : int[] = prim::Constant[value=[0, 0]]()\n  %6272 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6273 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6274 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6275 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6276 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6277 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11173, %511, %512, %10478, %10479, %10480, %6268, %10481, %6272, %6273, %6274, %6275, %6276) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6278 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6277) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.529 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6278, %11172) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6280 : NoneType = prim::Constant()\n  %10482 : int[] = prim::Constant[value=[1, 1]]()\n  %10483 : int[] = prim::Constant[value=[0, 0]]()\n  %10484 : int[] = prim::Constant[value=[1, 1]]()\n  %6290 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10485 : int[] = prim::Constant[value=[0, 0]]()\n  %6294 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6295 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6296 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6297 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6298 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.531 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.529, %513, %6280, %10482, %10483, %10484, %6290, %10485, %6294, %6295, %6296, %6297, %6298) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6300 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6301 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6302 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6303 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6304 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.531, %514, %515, %516, %517, %6300, %6301, %6302, %6303) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6305 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11083 : Tensor = aten::type_as(%11280, %6304)\n  %11281 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6304, %11083, %6305) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6307 : NoneType = prim::Constant()\n  %10486 : int[] = prim::Constant[value=[1, 1]]()\n  %10487 : int[] = prim::Constant[value=[0, 0]]()\n  %10488 : int[] = prim::Constant[value=[1, 1]]()\n  %6317 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10489 : int[] = prim::Constant[value=[0, 0]]()\n  %6321 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6322 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6323 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6324 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6325 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.535 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11281, %519, %6307, %10486, %10487, %10488, %6317, %10489, %6321, %6322, %6323, %6324, %6325) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6327 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6328 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6329 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6330 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.537 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.535, %520, %521, %522, %523, %6327, %6328, %6329, %6330) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11174 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.537) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6333 : NoneType = prim::Constant()\n  %10490 : int[] = prim::Constant[value=[1, 1]]()\n  %10491 : int[] = prim::Constant[value=[1, 1]]()\n  %10492 : int[] = prim::Constant[value=[1, 1]]()\n  %6343 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10493 : int[] = prim::Constant[value=[0, 0]]()\n  %6347 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6348 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6349 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6350 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6351 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.541 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11174, %525, %6333, %10490, %10491, %10492, %6343, %10493, %6347, %6348, %6349, %6350, %6351) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6353 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6354 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6355 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6356 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.543 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.541, %526, %527, %528, %529, %6353, %6354, %6355, %6356) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11175 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.543) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10494 : int[] = prim::Constant[value=[1, 1]]()\n  %input.547 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11175, %10494) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10495 : int[] = prim::Constant[value=[1, 1]]()\n  %10496 : int[] = prim::Constant[value=[0, 0]]()\n  %10497 : int[] = prim::Constant[value=[1, 1]]()\n  %6384 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10498 : int[] = prim::Constant[value=[0, 0]]()\n  %6388 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6389 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6390 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6391 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6392 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.549 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.547, %531, %532, %10495, %10496, %10497, %6384, %10498, %6388, %6389, %6390, %6391, %6392) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11176 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10499 : int[] = prim::Constant[value=[1, 1]]()\n  %10500 : int[] = prim::Constant[value=[0, 0]]()\n  %10501 : int[] = prim::Constant[value=[1, 1]]()\n  %6404 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10502 : int[] = prim::Constant[value=[0, 0]]()\n  %6408 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6409 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6410 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6411 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6412 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6413 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11176, %533, %534, %10499, %10500, %10501, %6404, %10502, %6408, %6409, %6410, %6411, %6412) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6414 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6413) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.553 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6414, %11175) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6416 : NoneType = prim::Constant()\n  %10503 : int[] = prim::Constant[value=[1, 1]]()\n  %10504 : int[] = prim::Constant[value=[0, 0]]()\n  %10505 : int[] = prim::Constant[value=[1, 1]]()\n  %6426 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10506 : int[] = prim::Constant[value=[0, 0]]()\n  %6430 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6431 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6432 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6433 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6434 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.555 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.553, %535, %6416, %10503, %10504, %10505, %6426, %10506, %6430, %6431, %6432, %6433, %6434) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6436 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6437 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6438 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6439 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6440 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.555, %536, %537, %538, %539, %6436, %6437, %6438, %6439) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6441 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11084 : Tensor = aten::type_as(%11281, %6440)\n  %11282 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6440, %11084, %6441) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6443 : NoneType = prim::Constant()\n  %10507 : int[] = prim::Constant[value=[1, 1]]()\n  %10508 : int[] = prim::Constant[value=[0, 0]]()\n  %10509 : int[] = prim::Constant[value=[1, 1]]()\n  %6453 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10510 : int[] = prim::Constant[value=[0, 0]]()\n  %6457 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6458 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6459 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6460 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6461 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.559 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11282, %541, %6443, %10507, %10508, %10509, %6453, %10510, %6457, %6458, %6459, %6460, %6461) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6463 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6464 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6465 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6466 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.561 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.559, %542, %543, %544, %545, %6463, %6464, %6465, %6466) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11177 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.561) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6469 : NoneType = prim::Constant()\n  %10511 : int[] = prim::Constant[value=[1, 1]]()\n  %10512 : int[] = prim::Constant[value=[1, 1]]()\n  %10513 : int[] = prim::Constant[value=[1, 1]]()\n  %6479 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10514 : int[] = prim::Constant[value=[0, 0]]()\n  %6483 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6484 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6485 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6486 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6487 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.565 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11177, %547, %6469, %10511, %10512, %10513, %6479, %10514, %6483, %6484, %6485, %6486, %6487) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6489 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6490 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6491 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6492 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.567 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.565, %548, %549, %550, %551, %6489, %6490, %6491, %6492) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11178 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.567) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10515 : int[] = prim::Constant[value=[1, 1]]()\n  %input.571 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11178, %10515) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10516 : int[] = prim::Constant[value=[1, 1]]()\n  %10517 : int[] = prim::Constant[value=[0, 0]]()\n  %10518 : int[] = prim::Constant[value=[1, 1]]()\n  %6520 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10519 : int[] = prim::Constant[value=[0, 0]]()\n  %6524 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6525 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6526 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6527 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6528 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.573 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.571, %553, %554, %10516, %10517, %10518, %6520, %10519, %6524, %6525, %6526, %6527, %6528) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11179 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.573) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10520 : int[] = prim::Constant[value=[1, 1]]()\n  %10521 : int[] = prim::Constant[value=[0, 0]]()\n  %10522 : int[] = prim::Constant[value=[1, 1]]()\n  %6540 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10523 : int[] = prim::Constant[value=[0, 0]]()\n  %6544 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6545 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6546 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6547 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6548 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6549 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11179, %555, %556, %10520, %10521, %10522, %6540, %10523, %6544, %6545, %6546, %6547, %6548) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6550 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6549) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.577 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6550, %11178) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6552 : NoneType = prim::Constant()\n  %10524 : int[] = prim::Constant[value=[1, 1]]()\n  %10525 : int[] = prim::Constant[value=[0, 0]]()\n  %10526 : int[] = prim::Constant[value=[1, 1]]()\n  %6562 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10527 : int[] = prim::Constant[value=[0, 0]]()\n  %6566 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6567 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6568 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6569 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6570 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.579 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.577, %557, %6552, %10524, %10525, %10526, %6562, %10527, %6566, %6567, %6568, %6569, %6570) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6572 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6573 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6574 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6575 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6576 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.579, %558, %559, %560, %561, %6572, %6573, %6574, %6575) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6577 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11085 : Tensor = aten::type_as(%11282, %6576)\n  %11283 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6576, %11085, %6577) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6579 : NoneType = prim::Constant()\n  %10528 : int[] = prim::Constant[value=[1, 1]]()\n  %10529 : int[] = prim::Constant[value=[0, 0]]()\n  %10530 : int[] = prim::Constant[value=[1, 1]]()\n  %6589 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10531 : int[] = prim::Constant[value=[0, 0]]()\n  %6593 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6594 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6595 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6596 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6597 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.583 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11283, %563, %6579, %10528, %10529, %10530, %6589, %10531, %6593, %6594, %6595, %6596, %6597) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6599 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6600 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6601 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6602 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.585 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.583, %564, %565, %566, %567, %6599, %6600, %6601, %6602) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11180 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.585) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6605 : NoneType = prim::Constant()\n  %10532 : int[] = prim::Constant[value=[1, 1]]()\n  %10533 : int[] = prim::Constant[value=[1, 1]]()\n  %10534 : int[] = prim::Constant[value=[1, 1]]()\n  %6615 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10535 : int[] = prim::Constant[value=[0, 0]]()\n  %6619 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6620 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6621 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6622 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6623 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.589 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11180, %569, %6605, %10532, %10533, %10534, %6615, %10535, %6619, %6620, %6621, %6622, %6623) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6625 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6626 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6627 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6628 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.591 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.589, %570, %571, %572, %573, %6625, %6626, %6627, %6628) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11181 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.591) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10536 : int[] = prim::Constant[value=[1, 1]]()\n  %input.595 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11181, %10536) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10537 : int[] = prim::Constant[value=[1, 1]]()\n  %10538 : int[] = prim::Constant[value=[0, 0]]()\n  %10539 : int[] = prim::Constant[value=[1, 1]]()\n  %6656 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10540 : int[] = prim::Constant[value=[0, 0]]()\n  %6660 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6661 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6662 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6663 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6664 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.597 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.595, %575, %576, %10537, %10538, %10539, %6656, %10540, %6660, %6661, %6662, %6663, %6664) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11182 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.597) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10541 : int[] = prim::Constant[value=[1, 1]]()\n  %10542 : int[] = prim::Constant[value=[0, 0]]()\n  %10543 : int[] = prim::Constant[value=[1, 1]]()\n  %6676 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10544 : int[] = prim::Constant[value=[0, 0]]()\n  %6680 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6681 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6682 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6683 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6684 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6685 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11182, %577, %578, %10541, %10542, %10543, %6676, %10544, %6680, %6681, %6682, %6683, %6684) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6686 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6685) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.601 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6686, %11181) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6688 : NoneType = prim::Constant()\n  %10545 : int[] = prim::Constant[value=[1, 1]]()\n  %10546 : int[] = prim::Constant[value=[0, 0]]()\n  %10547 : int[] = prim::Constant[value=[1, 1]]()\n  %6698 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10548 : int[] = prim::Constant[value=[0, 0]]()\n  %6702 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6703 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6704 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6705 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6706 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.603 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.601, %579, %6688, %10545, %10546, %10547, %6698, %10548, %6702, %6703, %6704, %6705, %6706) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6708 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6709 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6710 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6711 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6712 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.603, %580, %581, %582, %583, %6708, %6709, %6710, %6711) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6713 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11086 : Tensor = aten::type_as(%11283, %6712)\n  %11284 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6712, %11086, %6713) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6715 : NoneType = prim::Constant()\n  %10549 : int[] = prim::Constant[value=[1, 1]]()\n  %10550 : int[] = prim::Constant[value=[0, 0]]()\n  %10551 : int[] = prim::Constant[value=[1, 1]]()\n  %6725 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10552 : int[] = prim::Constant[value=[0, 0]]()\n  %6729 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6730 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6731 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6732 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6733 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.607 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11284, %585, %6715, %10549, %10550, %10551, %6725, %10552, %6729, %6730, %6731, %6732, %6733) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6735 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6736 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6737 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6738 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.609 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.607, %586, %587, %588, %589, %6735, %6736, %6737, %6738) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11183 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.609) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6741 : NoneType = prim::Constant()\n  %10553 : int[] = prim::Constant[value=[1, 1]]()\n  %10554 : int[] = prim::Constant[value=[1, 1]]()\n  %10555 : int[] = prim::Constant[value=[1, 1]]()\n  %6751 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10556 : int[] = prim::Constant[value=[0, 0]]()\n  %6755 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6756 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6757 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6758 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6759 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.613 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11183, %591, %6741, %10553, %10554, %10555, %6751, %10556, %6755, %6756, %6757, %6758, %6759) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6761 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6762 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6763 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6764 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.615 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.613, %592, %593, %594, %595, %6761, %6762, %6763, %6764) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11184 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.615) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10557 : int[] = prim::Constant[value=[1, 1]]()\n  %input.619 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11184, %10557) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10558 : int[] = prim::Constant[value=[1, 1]]()\n  %10559 : int[] = prim::Constant[value=[0, 0]]()\n  %10560 : int[] = prim::Constant[value=[1, 1]]()\n  %6792 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10561 : int[] = prim::Constant[value=[0, 0]]()\n  %6796 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6797 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6798 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6799 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6800 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.621 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.619, %597, %598, %10558, %10559, %10560, %6792, %10561, %6796, %6797, %6798, %6799, %6800) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11185 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.621) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10562 : int[] = prim::Constant[value=[1, 1]]()\n  %10563 : int[] = prim::Constant[value=[0, 0]]()\n  %10564 : int[] = prim::Constant[value=[1, 1]]()\n  %6812 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10565 : int[] = prim::Constant[value=[0, 0]]()\n  %6816 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6817 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6818 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6819 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6820 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6821 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11185, %599, %600, %10562, %10563, %10564, %6812, %10565, %6816, %6817, %6818, %6819, %6820) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6822 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6821) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.625 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::mul(%6822, %11184) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6824 : NoneType = prim::Constant()\n  %10566 : int[] = prim::Constant[value=[1, 1]]()\n  %10567 : int[] = prim::Constant[value=[0, 0]]()\n  %10568 : int[] = prim::Constant[value=[1, 1]]()\n  %6834 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10569 : int[] = prim::Constant[value=[0, 0]]()\n  %6838 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6839 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6840 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6841 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6842 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.627 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.625, %601, %6824, %10566, %10567, %10568, %6834, %10569, %6838, %6839, %6840, %6841, %6842) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6844 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6845 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6846 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6847 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6848 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.627, %602, %603, %604, %605, %6844, %6845, %6846, %6847) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6849 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11087 : Tensor = aten::type_as(%11284, %6848)\n  %11285 : Float(32, 176, 30, 30, strides=[158400, 900, 30, 1], requires_grad=0, device=cpu) = aten::add(%6848, %11087, %6849) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %6851 : NoneType = prim::Constant()\n  %10570 : int[] = prim::Constant[value=[1, 1]]()\n  %10571 : int[] = prim::Constant[value=[0, 0]]()\n  %10572 : int[] = prim::Constant[value=[1, 1]]()\n  %6861 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10573 : int[] = prim::Constant[value=[0, 0]]()\n  %6865 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6866 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6867 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6868 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6869 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.631 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::_convolution(%11285, %607, %6851, %10570, %10571, %10572, %6861, %10573, %6865, %6866, %6867, %6868, %6869) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6871 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6872 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6873 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6874 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.633 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.631, %608, %609, %610, %611, %6871, %6872, %6873, %6874) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11186 : Float(32, 1056, 30, 30, strides=[950400, 900, 30, 1], requires_grad=0, device=cpu) = aten::silu(%input.633) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %6877 : NoneType = prim::Constant()\n  %10574 : int[] = prim::Constant[value=[2, 2]]()\n  %10575 : int[] = prim::Constant[value=[1, 1]]()\n  %10576 : int[] = prim::Constant[value=[1, 1]]()\n  %6887 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10577 : int[] = prim::Constant[value=[0, 0]]()\n  %6891 : int = prim::Constant[value=1056]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6892 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6893 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6894 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6895 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.637 : Float(32, 1056, 15, 15, strides=[237600, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11186, %613, %6877, %10574, %10575, %10576, %6887, %10577, %6891, %6892, %6893, %6894, %6895) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6897 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6898 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6899 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6900 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.639 : Float(32, 1056, 15, 15, strides=[237600, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.637, %614, %615, %616, %617, %6897, %6898, %6899, %6900) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11187 : Float(32, 1056, 15, 15, strides=[237600, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.639) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10578 : int[] = prim::Constant[value=[1, 1]]()\n  %input.643 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11187, %10578) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10579 : int[] = prim::Constant[value=[1, 1]]()\n  %10580 : int[] = prim::Constant[value=[0, 0]]()\n  %10581 : int[] = prim::Constant[value=[1, 1]]()\n  %6928 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10582 : int[] = prim::Constant[value=[0, 0]]()\n  %6932 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6933 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6934 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6935 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6936 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.645 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.643, %619, %620, %10579, %10580, %10581, %6928, %10582, %6932, %6933, %6934, %6935, %6936) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11188 : Float(32, 44, 1, 1, strides=[44, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.645) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10583 : int[] = prim::Constant[value=[1, 1]]()\n  %10584 : int[] = prim::Constant[value=[0, 0]]()\n  %10585 : int[] = prim::Constant[value=[1, 1]]()\n  %6948 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10586 : int[] = prim::Constant[value=[0, 0]]()\n  %6952 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6953 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6954 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6955 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6956 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6957 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11188, %621, %622, %10583, %10584, %10585, %6948, %10586, %6952, %6953, %6954, %6955, %6956) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6958 : Float(32, 1056, 1, 1, strides=[1056, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%6957) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.649 : Float(32, 1056, 15, 15, strides=[237600, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%6958, %11187) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %6960 : NoneType = prim::Constant()\n  %10587 : int[] = prim::Constant[value=[1, 1]]()\n  %10588 : int[] = prim::Constant[value=[0, 0]]()\n  %10589 : int[] = prim::Constant[value=[1, 1]]()\n  %6970 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10590 : int[] = prim::Constant[value=[0, 0]]()\n  %6974 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6975 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6976 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6977 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6978 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.651 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.649, %623, %6960, %10587, %10588, %10589, %6970, %10590, %6974, %6975, %6976, %6977, %6978) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %6980 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6981 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6982 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6983 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.653 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.651, %624, %625, %626, %627, %6980, %6981, %6982, %6983) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %6985 : NoneType = prim::Constant()\n  %10591 : int[] = prim::Constant[value=[1, 1]]()\n  %10592 : int[] = prim::Constant[value=[0, 0]]()\n  %10593 : int[] = prim::Constant[value=[1, 1]]()\n  %6995 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10594 : int[] = prim::Constant[value=[0, 0]]()\n  %6999 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7000 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7001 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7002 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7003 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.655 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.653, %629, %6985, %10591, %10592, %10593, %6995, %10594, %6999, %7000, %7001, %7002, %7003) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7005 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7006 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7007 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7008 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.657 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.655, %630, %631, %632, %633, %7005, %7006, %7007, %7008) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11189 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.657) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7011 : NoneType = prim::Constant()\n  %10595 : int[] = prim::Constant[value=[1, 1]]()\n  %10596 : int[] = prim::Constant[value=[1, 1]]()\n  %10597 : int[] = prim::Constant[value=[1, 1]]()\n  %7021 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10598 : int[] = prim::Constant[value=[0, 0]]()\n  %7025 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7026 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7027 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7028 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7029 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.661 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11189, %635, %7011, %10595, %10596, %10597, %7021, %10598, %7025, %7026, %7027, %7028, %7029) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7031 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7032 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7033 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7034 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.663 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.661, %636, %637, %638, %639, %7031, %7032, %7033, %7034) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11190 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.663) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10599 : int[] = prim::Constant[value=[1, 1]]()\n  %input.667 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11190, %10599) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10600 : int[] = prim::Constant[value=[1, 1]]()\n  %10601 : int[] = prim::Constant[value=[0, 0]]()\n  %10602 : int[] = prim::Constant[value=[1, 1]]()\n  %7062 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10603 : int[] = prim::Constant[value=[0, 0]]()\n  %7066 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7067 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7068 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7069 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7070 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.669 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.667, %641, %642, %10600, %10601, %10602, %7062, %10603, %7066, %7067, %7068, %7069, %7070) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11191 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.669) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10604 : int[] = prim::Constant[value=[1, 1]]()\n  %10605 : int[] = prim::Constant[value=[0, 0]]()\n  %10606 : int[] = prim::Constant[value=[1, 1]]()\n  %7082 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10607 : int[] = prim::Constant[value=[0, 0]]()\n  %7086 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7087 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7088 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7089 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7090 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7091 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11191, %643, %644, %10604, %10605, %10606, %7082, %10607, %7086, %7087, %7088, %7089, %7090) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7092 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7091) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.673 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7092, %11190) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7094 : NoneType = prim::Constant()\n  %10608 : int[] = prim::Constant[value=[1, 1]]()\n  %10609 : int[] = prim::Constant[value=[0, 0]]()\n  %10610 : int[] = prim::Constant[value=[1, 1]]()\n  %7104 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10611 : int[] = prim::Constant[value=[0, 0]]()\n  %7108 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7109 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7110 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7111 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7112 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.675 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.673, %645, %7094, %10608, %10609, %10610, %7104, %10611, %7108, %7109, %7110, %7111, %7112) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7114 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7115 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7116 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7117 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7118 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.675, %646, %647, %648, %649, %7114, %7115, %7116, %7117) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7119 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11088 : Tensor = aten::type_as(%input.653, %7118)\n  %11286 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7118, %11088, %7119) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7121 : NoneType = prim::Constant()\n  %10612 : int[] = prim::Constant[value=[1, 1]]()\n  %10613 : int[] = prim::Constant[value=[0, 0]]()\n  %10614 : int[] = prim::Constant[value=[1, 1]]()\n  %7131 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10615 : int[] = prim::Constant[value=[0, 0]]()\n  %7135 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7136 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7137 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7138 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7139 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.679 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11286, %651, %7121, %10612, %10613, %10614, %7131, %10615, %7135, %7136, %7137, %7138, %7139) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7141 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7142 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7143 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7144 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.681 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.679, %652, %653, %654, %655, %7141, %7142, %7143, %7144) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11192 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.681) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7147 : NoneType = prim::Constant()\n  %10616 : int[] = prim::Constant[value=[1, 1]]()\n  %10617 : int[] = prim::Constant[value=[1, 1]]()\n  %10618 : int[] = prim::Constant[value=[1, 1]]()\n  %7157 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10619 : int[] = prim::Constant[value=[0, 0]]()\n  %7161 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7162 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7163 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7164 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7165 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.685 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11192, %657, %7147, %10616, %10617, %10618, %7157, %10619, %7161, %7162, %7163, %7164, %7165) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7167 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7168 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7169 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7170 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.687 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.685, %658, %659, %660, %661, %7167, %7168, %7169, %7170) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11193 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.687) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10620 : int[] = prim::Constant[value=[1, 1]]()\n  %input.691 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11193, %10620) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10621 : int[] = prim::Constant[value=[1, 1]]()\n  %10622 : int[] = prim::Constant[value=[0, 0]]()\n  %10623 : int[] = prim::Constant[value=[1, 1]]()\n  %7198 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10624 : int[] = prim::Constant[value=[0, 0]]()\n  %7202 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7203 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7204 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7205 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7206 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.693 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.691, %663, %664, %10621, %10622, %10623, %7198, %10624, %7202, %7203, %7204, %7205, %7206) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11194 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.693) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10625 : int[] = prim::Constant[value=[1, 1]]()\n  %10626 : int[] = prim::Constant[value=[0, 0]]()\n  %10627 : int[] = prim::Constant[value=[1, 1]]()\n  %7218 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10628 : int[] = prim::Constant[value=[0, 0]]()\n  %7222 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7223 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7224 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7225 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7226 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7227 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11194, %665, %666, %10625, %10626, %10627, %7218, %10628, %7222, %7223, %7224, %7225, %7226) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7228 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7227) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.697 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7228, %11193) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7230 : NoneType = prim::Constant()\n  %10629 : int[] = prim::Constant[value=[1, 1]]()\n  %10630 : int[] = prim::Constant[value=[0, 0]]()\n  %10631 : int[] = prim::Constant[value=[1, 1]]()\n  %7240 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10632 : int[] = prim::Constant[value=[0, 0]]()\n  %7244 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7245 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7246 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7247 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7248 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.699 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.697, %667, %7230, %10629, %10630, %10631, %7240, %10632, %7244, %7245, %7246, %7247, %7248) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7250 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7251 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7252 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7253 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7254 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.699, %668, %669, %670, %671, %7250, %7251, %7252, %7253) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7255 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11089 : Tensor = aten::type_as(%11286, %7254)\n  %11287 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7254, %11089, %7255) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7257 : NoneType = prim::Constant()\n  %10633 : int[] = prim::Constant[value=[1, 1]]()\n  %10634 : int[] = prim::Constant[value=[0, 0]]()\n  %10635 : int[] = prim::Constant[value=[1, 1]]()\n  %7267 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10636 : int[] = prim::Constant[value=[0, 0]]()\n  %7271 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7272 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7273 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7274 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7275 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.703 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11287, %673, %7257, %10633, %10634, %10635, %7267, %10636, %7271, %7272, %7273, %7274, %7275) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7277 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7278 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7279 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7280 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.705 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.703, %674, %675, %676, %677, %7277, %7278, %7279, %7280) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11195 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.705) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7283 : NoneType = prim::Constant()\n  %10637 : int[] = prim::Constant[value=[1, 1]]()\n  %10638 : int[] = prim::Constant[value=[1, 1]]()\n  %10639 : int[] = prim::Constant[value=[1, 1]]()\n  %7293 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10640 : int[] = prim::Constant[value=[0, 0]]()\n  %7297 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7298 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7299 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7300 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7301 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.709 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11195, %679, %7283, %10637, %10638, %10639, %7293, %10640, %7297, %7298, %7299, %7300, %7301) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7303 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7304 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7305 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7306 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.711 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.709, %680, %681, %682, %683, %7303, %7304, %7305, %7306) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11196 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.711) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10641 : int[] = prim::Constant[value=[1, 1]]()\n  %input.715 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11196, %10641) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10642 : int[] = prim::Constant[value=[1, 1]]()\n  %10643 : int[] = prim::Constant[value=[0, 0]]()\n  %10644 : int[] = prim::Constant[value=[1, 1]]()\n  %7334 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10645 : int[] = prim::Constant[value=[0, 0]]()\n  %7338 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7339 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7340 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7341 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7342 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.717 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.715, %685, %686, %10642, %10643, %10644, %7334, %10645, %7338, %7339, %7340, %7341, %7342) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11197 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.717) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10646 : int[] = prim::Constant[value=[1, 1]]()\n  %10647 : int[] = prim::Constant[value=[0, 0]]()\n  %10648 : int[] = prim::Constant[value=[1, 1]]()\n  %7354 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10649 : int[] = prim::Constant[value=[0, 0]]()\n  %7358 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7359 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7360 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7361 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7362 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7363 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11197, %687, %688, %10646, %10647, %10648, %7354, %10649, %7358, %7359, %7360, %7361, %7362) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7364 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7363) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.721 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7364, %11196) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7366 : NoneType = prim::Constant()\n  %10650 : int[] = prim::Constant[value=[1, 1]]()\n  %10651 : int[] = prim::Constant[value=[0, 0]]()\n  %10652 : int[] = prim::Constant[value=[1, 1]]()\n  %7376 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10653 : int[] = prim::Constant[value=[0, 0]]()\n  %7380 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7381 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7382 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7383 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7384 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.723 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.721, %689, %7366, %10650, %10651, %10652, %7376, %10653, %7380, %7381, %7382, %7383, %7384) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7386 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7387 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7388 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7389 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7390 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.723, %690, %691, %692, %693, %7386, %7387, %7388, %7389) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7391 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11090 : Tensor = aten::type_as(%11287, %7390)\n  %11288 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7390, %11090, %7391) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7393 : NoneType = prim::Constant()\n  %10654 : int[] = prim::Constant[value=[1, 1]]()\n  %10655 : int[] = prim::Constant[value=[0, 0]]()\n  %10656 : int[] = prim::Constant[value=[1, 1]]()\n  %7403 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10657 : int[] = prim::Constant[value=[0, 0]]()\n  %7407 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7408 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7409 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7410 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7411 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.727 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11288, %695, %7393, %10654, %10655, %10656, %7403, %10657, %7407, %7408, %7409, %7410, %7411) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7413 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7414 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7415 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7416 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.729 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.727, %696, %697, %698, %699, %7413, %7414, %7415, %7416) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11198 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.729) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7419 : NoneType = prim::Constant()\n  %10658 : int[] = prim::Constant[value=[1, 1]]()\n  %10659 : int[] = prim::Constant[value=[1, 1]]()\n  %10660 : int[] = prim::Constant[value=[1, 1]]()\n  %7429 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10661 : int[] = prim::Constant[value=[0, 0]]()\n  %7433 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7434 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7435 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7436 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7437 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.733 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11198, %701, %7419, %10658, %10659, %10660, %7429, %10661, %7433, %7434, %7435, %7436, %7437) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7439 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7440 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7441 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7442 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.735 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.733, %702, %703, %704, %705, %7439, %7440, %7441, %7442) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11199 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.735) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10662 : int[] = prim::Constant[value=[1, 1]]()\n  %input.739 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11199, %10662) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10663 : int[] = prim::Constant[value=[1, 1]]()\n  %10664 : int[] = prim::Constant[value=[0, 0]]()\n  %10665 : int[] = prim::Constant[value=[1, 1]]()\n  %7470 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10666 : int[] = prim::Constant[value=[0, 0]]()\n  %7474 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7475 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7476 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7477 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7478 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.741 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.739, %707, %708, %10663, %10664, %10665, %7470, %10666, %7474, %7475, %7476, %7477, %7478) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11200 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.741) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10667 : int[] = prim::Constant[value=[1, 1]]()\n  %10668 : int[] = prim::Constant[value=[0, 0]]()\n  %10669 : int[] = prim::Constant[value=[1, 1]]()\n  %7490 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10670 : int[] = prim::Constant[value=[0, 0]]()\n  %7494 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7495 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7496 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7497 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7498 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7499 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11200, %709, %710, %10667, %10668, %10669, %7490, %10670, %7494, %7495, %7496, %7497, %7498) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7500 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7499) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.745 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7500, %11199) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7502 : NoneType = prim::Constant()\n  %10671 : int[] = prim::Constant[value=[1, 1]]()\n  %10672 : int[] = prim::Constant[value=[0, 0]]()\n  %10673 : int[] = prim::Constant[value=[1, 1]]()\n  %7512 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10674 : int[] = prim::Constant[value=[0, 0]]()\n  %7516 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7517 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7518 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7519 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7520 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.747 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.745, %711, %7502, %10671, %10672, %10673, %7512, %10674, %7516, %7517, %7518, %7519, %7520) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7522 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7523 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7524 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7525 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7526 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.747, %712, %713, %714, %715, %7522, %7523, %7524, %7525) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7527 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11091 : Tensor = aten::type_as(%11288, %7526)\n  %11289 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7526, %11091, %7527) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7529 : NoneType = prim::Constant()\n  %10675 : int[] = prim::Constant[value=[1, 1]]()\n  %10676 : int[] = prim::Constant[value=[0, 0]]()\n  %10677 : int[] = prim::Constant[value=[1, 1]]()\n  %7539 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10678 : int[] = prim::Constant[value=[0, 0]]()\n  %7543 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7544 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7545 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7546 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7547 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.751 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11289, %717, %7529, %10675, %10676, %10677, %7539, %10678, %7543, %7544, %7545, %7546, %7547) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7549 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7550 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7551 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7552 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.753 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.751, %718, %719, %720, %721, %7549, %7550, %7551, %7552) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11201 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.753) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7555 : NoneType = prim::Constant()\n  %10679 : int[] = prim::Constant[value=[1, 1]]()\n  %10680 : int[] = prim::Constant[value=[1, 1]]()\n  %10681 : int[] = prim::Constant[value=[1, 1]]()\n  %7565 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10682 : int[] = prim::Constant[value=[0, 0]]()\n  %7569 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7570 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7571 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7572 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7573 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.757 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11201, %723, %7555, %10679, %10680, %10681, %7565, %10682, %7569, %7570, %7571, %7572, %7573) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7575 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7576 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7577 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7578 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.759 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.757, %724, %725, %726, %727, %7575, %7576, %7577, %7578) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11202 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.759) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10683 : int[] = prim::Constant[value=[1, 1]]()\n  %input.763 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11202, %10683) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10684 : int[] = prim::Constant[value=[1, 1]]()\n  %10685 : int[] = prim::Constant[value=[0, 0]]()\n  %10686 : int[] = prim::Constant[value=[1, 1]]()\n  %7606 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10687 : int[] = prim::Constant[value=[0, 0]]()\n  %7610 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7611 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7612 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7613 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7614 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.765 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.763, %729, %730, %10684, %10685, %10686, %7606, %10687, %7610, %7611, %7612, %7613, %7614) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11203 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.765) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10688 : int[] = prim::Constant[value=[1, 1]]()\n  %10689 : int[] = prim::Constant[value=[0, 0]]()\n  %10690 : int[] = prim::Constant[value=[1, 1]]()\n  %7626 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10691 : int[] = prim::Constant[value=[0, 0]]()\n  %7630 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7631 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7632 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7633 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7634 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7635 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11203, %731, %732, %10688, %10689, %10690, %7626, %10691, %7630, %7631, %7632, %7633, %7634) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7636 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7635) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.769 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7636, %11202) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7638 : NoneType = prim::Constant()\n  %10692 : int[] = prim::Constant[value=[1, 1]]()\n  %10693 : int[] = prim::Constant[value=[0, 0]]()\n  %10694 : int[] = prim::Constant[value=[1, 1]]()\n  %7648 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10695 : int[] = prim::Constant[value=[0, 0]]()\n  %7652 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7653 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7654 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7655 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7656 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.771 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.769, %733, %7638, %10692, %10693, %10694, %7648, %10695, %7652, %7653, %7654, %7655, %7656) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7658 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7659 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7660 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7661 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7662 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.771, %734, %735, %736, %737, %7658, %7659, %7660, %7661) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7663 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11092 : Tensor = aten::type_as(%11289, %7662)\n  %11290 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7662, %11092, %7663) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7665 : NoneType = prim::Constant()\n  %10696 : int[] = prim::Constant[value=[1, 1]]()\n  %10697 : int[] = prim::Constant[value=[0, 0]]()\n  %10698 : int[] = prim::Constant[value=[1, 1]]()\n  %7675 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10699 : int[] = prim::Constant[value=[0, 0]]()\n  %7679 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7680 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7681 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7682 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7683 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.775 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11290, %739, %7665, %10696, %10697, %10698, %7675, %10699, %7679, %7680, %7681, %7682, %7683) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7685 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7686 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7687 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7688 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.777 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.775, %740, %741, %742, %743, %7685, %7686, %7687, %7688) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11204 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.777) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7691 : NoneType = prim::Constant()\n  %10700 : int[] = prim::Constant[value=[1, 1]]()\n  %10701 : int[] = prim::Constant[value=[1, 1]]()\n  %10702 : int[] = prim::Constant[value=[1, 1]]()\n  %7701 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10703 : int[] = prim::Constant[value=[0, 0]]()\n  %7705 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7706 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7707 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7708 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7709 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.781 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11204, %745, %7691, %10700, %10701, %10702, %7701, %10703, %7705, %7706, %7707, %7708, %7709) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7711 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7712 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7713 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7714 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.783 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.781, %746, %747, %748, %749, %7711, %7712, %7713, %7714) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11205 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.783) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10704 : int[] = prim::Constant[value=[1, 1]]()\n  %input.787 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11205, %10704) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10705 : int[] = prim::Constant[value=[1, 1]]()\n  %10706 : int[] = prim::Constant[value=[0, 0]]()\n  %10707 : int[] = prim::Constant[value=[1, 1]]()\n  %7742 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10708 : int[] = prim::Constant[value=[0, 0]]()\n  %7746 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7747 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7748 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7749 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7750 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.789 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.787, %751, %752, %10705, %10706, %10707, %7742, %10708, %7746, %7747, %7748, %7749, %7750) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11206 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.789) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10709 : int[] = prim::Constant[value=[1, 1]]()\n  %10710 : int[] = prim::Constant[value=[0, 0]]()\n  %10711 : int[] = prim::Constant[value=[1, 1]]()\n  %7762 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10712 : int[] = prim::Constant[value=[0, 0]]()\n  %7766 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7767 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7768 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7769 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7770 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7771 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11206, %753, %754, %10709, %10710, %10711, %7762, %10712, %7766, %7767, %7768, %7769, %7770) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7772 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7771) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.793 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7772, %11205) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7774 : NoneType = prim::Constant()\n  %10713 : int[] = prim::Constant[value=[1, 1]]()\n  %10714 : int[] = prim::Constant[value=[0, 0]]()\n  %10715 : int[] = prim::Constant[value=[1, 1]]()\n  %7784 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10716 : int[] = prim::Constant[value=[0, 0]]()\n  %7788 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7789 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7790 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7791 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7792 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.795 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.793, %755, %7774, %10713, %10714, %10715, %7784, %10716, %7788, %7789, %7790, %7791, %7792) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7794 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7795 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7796 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7797 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7798 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.795, %756, %757, %758, %759, %7794, %7795, %7796, %7797) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7799 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11093 : Tensor = aten::type_as(%11290, %7798)\n  %11291 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7798, %11093, %7799) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7801 : NoneType = prim::Constant()\n  %10717 : int[] = prim::Constant[value=[1, 1]]()\n  %10718 : int[] = prim::Constant[value=[0, 0]]()\n  %10719 : int[] = prim::Constant[value=[1, 1]]()\n  %7811 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10720 : int[] = prim::Constant[value=[0, 0]]()\n  %7815 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7816 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7817 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7818 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7819 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.799 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11291, %761, %7801, %10717, %10718, %10719, %7811, %10720, %7815, %7816, %7817, %7818, %7819) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7821 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7822 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7823 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7824 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.801 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.799, %762, %763, %764, %765, %7821, %7822, %7823, %7824) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11207 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.801) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7827 : NoneType = prim::Constant()\n  %10721 : int[] = prim::Constant[value=[1, 1]]()\n  %10722 : int[] = prim::Constant[value=[1, 1]]()\n  %10723 : int[] = prim::Constant[value=[1, 1]]()\n  %7837 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10724 : int[] = prim::Constant[value=[0, 0]]()\n  %7841 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7842 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7843 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7844 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7845 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.805 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11207, %767, %7827, %10721, %10722, %10723, %7837, %10724, %7841, %7842, %7843, %7844, %7845) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7847 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7848 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7849 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7850 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.807 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.805, %768, %769, %770, %771, %7847, %7848, %7849, %7850) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11208 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.807) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10725 : int[] = prim::Constant[value=[1, 1]]()\n  %input.811 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11208, %10725) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10726 : int[] = prim::Constant[value=[1, 1]]()\n  %10727 : int[] = prim::Constant[value=[0, 0]]()\n  %10728 : int[] = prim::Constant[value=[1, 1]]()\n  %7878 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10729 : int[] = prim::Constant[value=[0, 0]]()\n  %7882 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7883 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7884 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7885 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7886 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.813 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.811, %773, %774, %10726, %10727, %10728, %7878, %10729, %7882, %7883, %7884, %7885, %7886) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11209 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.813) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10730 : int[] = prim::Constant[value=[1, 1]]()\n  %10731 : int[] = prim::Constant[value=[0, 0]]()\n  %10732 : int[] = prim::Constant[value=[1, 1]]()\n  %7898 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10733 : int[] = prim::Constant[value=[0, 0]]()\n  %7902 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7903 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7904 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7905 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7906 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7907 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11209, %775, %776, %10730, %10731, %10732, %7898, %10733, %7902, %7903, %7904, %7905, %7906) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7908 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%7907) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.817 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%7908, %11208) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %7910 : NoneType = prim::Constant()\n  %10734 : int[] = prim::Constant[value=[1, 1]]()\n  %10735 : int[] = prim::Constant[value=[0, 0]]()\n  %10736 : int[] = prim::Constant[value=[1, 1]]()\n  %7920 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10737 : int[] = prim::Constant[value=[0, 0]]()\n  %7924 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7925 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7926 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7927 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7928 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.819 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.817, %777, %7910, %10734, %10735, %10736, %7920, %10737, %7924, %7925, %7926, %7927, %7928) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7930 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7931 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7932 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7933 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7934 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.819, %778, %779, %780, %781, %7930, %7931, %7932, %7933) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7935 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11094 : Tensor = aten::type_as(%11291, %7934)\n  %11292 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%7934, %11094, %7935) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %7937 : NoneType = prim::Constant()\n  %10738 : int[] = prim::Constant[value=[1, 1]]()\n  %10739 : int[] = prim::Constant[value=[0, 0]]()\n  %10740 : int[] = prim::Constant[value=[1, 1]]()\n  %7947 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10741 : int[] = prim::Constant[value=[0, 0]]()\n  %7951 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7952 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7953 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7954 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7955 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.823 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11292, %783, %7937, %10738, %10739, %10740, %7947, %10741, %7951, %7952, %7953, %7954, %7955) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7957 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7958 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7959 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7960 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.825 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.823, %784, %785, %786, %787, %7957, %7958, %7959, %7960) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11210 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.825) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %7963 : NoneType = prim::Constant()\n  %10742 : int[] = prim::Constant[value=[1, 1]]()\n  %10743 : int[] = prim::Constant[value=[1, 1]]()\n  %10744 : int[] = prim::Constant[value=[1, 1]]()\n  %7973 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10745 : int[] = prim::Constant[value=[0, 0]]()\n  %7977 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7978 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7979 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7980 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7981 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.829 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11210, %789, %7963, %10742, %10743, %10744, %7973, %10745, %7977, %7978, %7979, %7980, %7981) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %7983 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7984 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7985 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %7986 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.831 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.829, %790, %791, %792, %793, %7983, %7984, %7985, %7986) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11211 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.831) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10746 : int[] = prim::Constant[value=[1, 1]]()\n  %input.835 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11211, %10746) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10747 : int[] = prim::Constant[value=[1, 1]]()\n  %10748 : int[] = prim::Constant[value=[0, 0]]()\n  %10749 : int[] = prim::Constant[value=[1, 1]]()\n  %8014 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10750 : int[] = prim::Constant[value=[0, 0]]()\n  %8018 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8019 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8020 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8021 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8022 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.837 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.835, %795, %796, %10747, %10748, %10749, %8014, %10750, %8018, %8019, %8020, %8021, %8022) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11212 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.837) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10751 : int[] = prim::Constant[value=[1, 1]]()\n  %10752 : int[] = prim::Constant[value=[0, 0]]()\n  %10753 : int[] = prim::Constant[value=[1, 1]]()\n  %8034 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10754 : int[] = prim::Constant[value=[0, 0]]()\n  %8038 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8039 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8040 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8041 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8042 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8043 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11212, %797, %798, %10751, %10752, %10753, %8034, %10754, %8038, %8039, %8040, %8041, %8042) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8044 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8043) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.841 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8044, %11211) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8046 : NoneType = prim::Constant()\n  %10755 : int[] = prim::Constant[value=[1, 1]]()\n  %10756 : int[] = prim::Constant[value=[0, 0]]()\n  %10757 : int[] = prim::Constant[value=[1, 1]]()\n  %8056 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10758 : int[] = prim::Constant[value=[0, 0]]()\n  %8060 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8061 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8062 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8063 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8064 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.843 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.841, %799, %8046, %10755, %10756, %10757, %8056, %10758, %8060, %8061, %8062, %8063, %8064) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8066 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8067 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8068 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8069 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8070 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.843, %800, %801, %802, %803, %8066, %8067, %8068, %8069) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8071 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11095 : Tensor = aten::type_as(%11292, %8070)\n  %11293 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8070, %11095, %8071) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8073 : NoneType = prim::Constant()\n  %10759 : int[] = prim::Constant[value=[1, 1]]()\n  %10760 : int[] = prim::Constant[value=[0, 0]]()\n  %10761 : int[] = prim::Constant[value=[1, 1]]()\n  %8083 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10762 : int[] = prim::Constant[value=[0, 0]]()\n  %8087 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8088 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8089 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8090 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8091 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.847 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11293, %805, %8073, %10759, %10760, %10761, %8083, %10762, %8087, %8088, %8089, %8090, %8091) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8093 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8094 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8095 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8096 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.849 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.847, %806, %807, %808, %809, %8093, %8094, %8095, %8096) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11213 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.849) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8099 : NoneType = prim::Constant()\n  %10763 : int[] = prim::Constant[value=[1, 1]]()\n  %10764 : int[] = prim::Constant[value=[1, 1]]()\n  %10765 : int[] = prim::Constant[value=[1, 1]]()\n  %8109 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10766 : int[] = prim::Constant[value=[0, 0]]()\n  %8113 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8114 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8115 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8116 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8117 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.853 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11213, %811, %8099, %10763, %10764, %10765, %8109, %10766, %8113, %8114, %8115, %8116, %8117) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8119 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8120 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8121 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8122 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.855 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.853, %812, %813, %814, %815, %8119, %8120, %8121, %8122) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11214 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.855) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10767 : int[] = prim::Constant[value=[1, 1]]()\n  %input.859 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11214, %10767) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10768 : int[] = prim::Constant[value=[1, 1]]()\n  %10769 : int[] = prim::Constant[value=[0, 0]]()\n  %10770 : int[] = prim::Constant[value=[1, 1]]()\n  %8150 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10771 : int[] = prim::Constant[value=[0, 0]]()\n  %8154 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8155 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8156 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8157 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8158 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.861 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.859, %817, %818, %10768, %10769, %10770, %8150, %10771, %8154, %8155, %8156, %8157, %8158) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11215 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.861) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10772 : int[] = prim::Constant[value=[1, 1]]()\n  %10773 : int[] = prim::Constant[value=[0, 0]]()\n  %10774 : int[] = prim::Constant[value=[1, 1]]()\n  %8170 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10775 : int[] = prim::Constant[value=[0, 0]]()\n  %8174 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8175 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8176 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8177 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8178 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8179 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11215, %819, %820, %10772, %10773, %10774, %8170, %10775, %8174, %8175, %8176, %8177, %8178) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8180 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8179) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.865 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8180, %11214) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8182 : NoneType = prim::Constant()\n  %10776 : int[] = prim::Constant[value=[1, 1]]()\n  %10777 : int[] = prim::Constant[value=[0, 0]]()\n  %10778 : int[] = prim::Constant[value=[1, 1]]()\n  %8192 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10779 : int[] = prim::Constant[value=[0, 0]]()\n  %8196 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8197 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8198 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8199 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8200 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.867 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.865, %821, %8182, %10776, %10777, %10778, %8192, %10779, %8196, %8197, %8198, %8199, %8200) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8202 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8203 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8204 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8205 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8206 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.867, %822, %823, %824, %825, %8202, %8203, %8204, %8205) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8207 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11096 : Tensor = aten::type_as(%11293, %8206)\n  %11294 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8206, %11096, %8207) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8209 : NoneType = prim::Constant()\n  %10780 : int[] = prim::Constant[value=[1, 1]]()\n  %10781 : int[] = prim::Constant[value=[0, 0]]()\n  %10782 : int[] = prim::Constant[value=[1, 1]]()\n  %8219 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10783 : int[] = prim::Constant[value=[0, 0]]()\n  %8223 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8224 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8225 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8226 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8227 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.871 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11294, %827, %8209, %10780, %10781, %10782, %8219, %10783, %8223, %8224, %8225, %8226, %8227) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8229 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8230 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8231 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8232 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.873 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.871, %828, %829, %830, %831, %8229, %8230, %8231, %8232) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11216 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.873) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8235 : NoneType = prim::Constant()\n  %10784 : int[] = prim::Constant[value=[1, 1]]()\n  %10785 : int[] = prim::Constant[value=[1, 1]]()\n  %10786 : int[] = prim::Constant[value=[1, 1]]()\n  %8245 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10787 : int[] = prim::Constant[value=[0, 0]]()\n  %8249 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8250 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8251 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8252 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8253 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.877 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11216, %833, %8235, %10784, %10785, %10786, %8245, %10787, %8249, %8250, %8251, %8252, %8253) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8255 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8256 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8257 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8258 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.879 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.877, %834, %835, %836, %837, %8255, %8256, %8257, %8258) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11217 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.879) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10788 : int[] = prim::Constant[value=[1, 1]]()\n  %input.883 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11217, %10788) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10789 : int[] = prim::Constant[value=[1, 1]]()\n  %10790 : int[] = prim::Constant[value=[0, 0]]()\n  %10791 : int[] = prim::Constant[value=[1, 1]]()\n  %8286 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10792 : int[] = prim::Constant[value=[0, 0]]()\n  %8290 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8291 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8292 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8293 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8294 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.885 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.883, %839, %840, %10789, %10790, %10791, %8286, %10792, %8290, %8291, %8292, %8293, %8294) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11218 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.885) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10793 : int[] = prim::Constant[value=[1, 1]]()\n  %10794 : int[] = prim::Constant[value=[0, 0]]()\n  %10795 : int[] = prim::Constant[value=[1, 1]]()\n  %8306 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10796 : int[] = prim::Constant[value=[0, 0]]()\n  %8310 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8311 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8312 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8313 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8314 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8315 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11218, %841, %842, %10793, %10794, %10795, %8306, %10796, %8310, %8311, %8312, %8313, %8314) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8316 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8315) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.889 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8316, %11217) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8318 : NoneType = prim::Constant()\n  %10797 : int[] = prim::Constant[value=[1, 1]]()\n  %10798 : int[] = prim::Constant[value=[0, 0]]()\n  %10799 : int[] = prim::Constant[value=[1, 1]]()\n  %8328 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10800 : int[] = prim::Constant[value=[0, 0]]()\n  %8332 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8333 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8334 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8335 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8336 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.891 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.889, %843, %8318, %10797, %10798, %10799, %8328, %10800, %8332, %8333, %8334, %8335, %8336) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8338 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8339 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8340 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8341 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8342 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.891, %844, %845, %846, %847, %8338, %8339, %8340, %8341) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8343 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11097 : Tensor = aten::type_as(%11294, %8342)\n  %11295 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8342, %11097, %8343) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8345 : NoneType = prim::Constant()\n  %10801 : int[] = prim::Constant[value=[1, 1]]()\n  %10802 : int[] = prim::Constant[value=[0, 0]]()\n  %10803 : int[] = prim::Constant[value=[1, 1]]()\n  %8355 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10804 : int[] = prim::Constant[value=[0, 0]]()\n  %8359 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8360 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8361 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8362 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8363 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.895 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11295, %849, %8345, %10801, %10802, %10803, %8355, %10804, %8359, %8360, %8361, %8362, %8363) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8365 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8366 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8367 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8368 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.897 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.895, %850, %851, %852, %853, %8365, %8366, %8367, %8368) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11219 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.897) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8371 : NoneType = prim::Constant()\n  %10805 : int[] = prim::Constant[value=[1, 1]]()\n  %10806 : int[] = prim::Constant[value=[1, 1]]()\n  %10807 : int[] = prim::Constant[value=[1, 1]]()\n  %8381 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10808 : int[] = prim::Constant[value=[0, 0]]()\n  %8385 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8386 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8387 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8388 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8389 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.901 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11219, %855, %8371, %10805, %10806, %10807, %8381, %10808, %8385, %8386, %8387, %8388, %8389) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8391 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8392 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8393 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8394 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.903 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.901, %856, %857, %858, %859, %8391, %8392, %8393, %8394) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11220 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.903) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10809 : int[] = prim::Constant[value=[1, 1]]()\n  %input.907 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11220, %10809) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10810 : int[] = prim::Constant[value=[1, 1]]()\n  %10811 : int[] = prim::Constant[value=[0, 0]]()\n  %10812 : int[] = prim::Constant[value=[1, 1]]()\n  %8422 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10813 : int[] = prim::Constant[value=[0, 0]]()\n  %8426 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8427 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8428 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8429 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8430 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.909 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.907, %861, %862, %10810, %10811, %10812, %8422, %10813, %8426, %8427, %8428, %8429, %8430) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11221 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.909) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10814 : int[] = prim::Constant[value=[1, 1]]()\n  %10815 : int[] = prim::Constant[value=[0, 0]]()\n  %10816 : int[] = prim::Constant[value=[1, 1]]()\n  %8442 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10817 : int[] = prim::Constant[value=[0, 0]]()\n  %8446 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8447 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8448 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8449 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8450 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8451 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11221, %863, %864, %10814, %10815, %10816, %8442, %10817, %8446, %8447, %8448, %8449, %8450) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8452 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8451) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.913 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8452, %11220) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8454 : NoneType = prim::Constant()\n  %10818 : int[] = prim::Constant[value=[1, 1]]()\n  %10819 : int[] = prim::Constant[value=[0, 0]]()\n  %10820 : int[] = prim::Constant[value=[1, 1]]()\n  %8464 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10821 : int[] = prim::Constant[value=[0, 0]]()\n  %8468 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8469 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8470 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8471 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8472 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.915 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.913, %865, %8454, %10818, %10819, %10820, %8464, %10821, %8468, %8469, %8470, %8471, %8472) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8474 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8475 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8476 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8477 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8478 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.915, %866, %867, %868, %869, %8474, %8475, %8476, %8477) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8479 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11098 : Tensor = aten::type_as(%11295, %8478)\n  %11296 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8478, %11098, %8479) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8481 : NoneType = prim::Constant()\n  %10822 : int[] = prim::Constant[value=[1, 1]]()\n  %10823 : int[] = prim::Constant[value=[0, 0]]()\n  %10824 : int[] = prim::Constant[value=[1, 1]]()\n  %8491 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10825 : int[] = prim::Constant[value=[0, 0]]()\n  %8495 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8496 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8497 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8498 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8499 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.919 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11296, %871, %8481, %10822, %10823, %10824, %8491, %10825, %8495, %8496, %8497, %8498, %8499) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8501 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8502 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8503 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8504 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.921 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.919, %872, %873, %874, %875, %8501, %8502, %8503, %8504) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11222 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.921) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8507 : NoneType = prim::Constant()\n  %10826 : int[] = prim::Constant[value=[1, 1]]()\n  %10827 : int[] = prim::Constant[value=[1, 1]]()\n  %10828 : int[] = prim::Constant[value=[1, 1]]()\n  %8517 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10829 : int[] = prim::Constant[value=[0, 0]]()\n  %8521 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8522 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8523 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8524 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8525 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.925 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11222, %877, %8507, %10826, %10827, %10828, %8517, %10829, %8521, %8522, %8523, %8524, %8525) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8527 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8528 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8529 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8530 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.927 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.925, %878, %879, %880, %881, %8527, %8528, %8529, %8530) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11223 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.927) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10830 : int[] = prim::Constant[value=[1, 1]]()\n  %input.931 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11223, %10830) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10831 : int[] = prim::Constant[value=[1, 1]]()\n  %10832 : int[] = prim::Constant[value=[0, 0]]()\n  %10833 : int[] = prim::Constant[value=[1, 1]]()\n  %8558 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10834 : int[] = prim::Constant[value=[0, 0]]()\n  %8562 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8563 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8564 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8565 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8566 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.933 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.931, %883, %884, %10831, %10832, %10833, %8558, %10834, %8562, %8563, %8564, %8565, %8566) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11224 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.933) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10835 : int[] = prim::Constant[value=[1, 1]]()\n  %10836 : int[] = prim::Constant[value=[0, 0]]()\n  %10837 : int[] = prim::Constant[value=[1, 1]]()\n  %8578 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10838 : int[] = prim::Constant[value=[0, 0]]()\n  %8582 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8583 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8584 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8585 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8586 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8587 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11224, %885, %886, %10835, %10836, %10837, %8578, %10838, %8582, %8583, %8584, %8585, %8586) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8588 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8587) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.937 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8588, %11223) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8590 : NoneType = prim::Constant()\n  %10839 : int[] = prim::Constant[value=[1, 1]]()\n  %10840 : int[] = prim::Constant[value=[0, 0]]()\n  %10841 : int[] = prim::Constant[value=[1, 1]]()\n  %8600 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10842 : int[] = prim::Constant[value=[0, 0]]()\n  %8604 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8605 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8606 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8607 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8608 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.939 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.937, %887, %8590, %10839, %10840, %10841, %8600, %10842, %8604, %8605, %8606, %8607, %8608) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8610 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8611 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8612 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8613 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8614 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.939, %888, %889, %890, %891, %8610, %8611, %8612, %8613) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8615 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11099 : Tensor = aten::type_as(%11296, %8614)\n  %11297 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8614, %11099, %8615) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8617 : NoneType = prim::Constant()\n  %10843 : int[] = prim::Constant[value=[1, 1]]()\n  %10844 : int[] = prim::Constant[value=[0, 0]]()\n  %10845 : int[] = prim::Constant[value=[1, 1]]()\n  %8627 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10846 : int[] = prim::Constant[value=[0, 0]]()\n  %8631 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8632 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8633 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8634 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8635 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.943 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11297, %893, %8617, %10843, %10844, %10845, %8627, %10846, %8631, %8632, %8633, %8634, %8635) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8637 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8638 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8639 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8640 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.945 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.943, %894, %895, %896, %897, %8637, %8638, %8639, %8640) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11225 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.945) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8643 : NoneType = prim::Constant()\n  %10847 : int[] = prim::Constant[value=[1, 1]]()\n  %10848 : int[] = prim::Constant[value=[1, 1]]()\n  %10849 : int[] = prim::Constant[value=[1, 1]]()\n  %8653 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10850 : int[] = prim::Constant[value=[0, 0]]()\n  %8657 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8658 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8659 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8660 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8661 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.949 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11225, %899, %8643, %10847, %10848, %10849, %8653, %10850, %8657, %8658, %8659, %8660, %8661) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8663 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8664 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8665 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8666 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.951 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.949, %900, %901, %902, %903, %8663, %8664, %8665, %8666) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11226 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.951) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10851 : int[] = prim::Constant[value=[1, 1]]()\n  %input.955 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11226, %10851) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10852 : int[] = prim::Constant[value=[1, 1]]()\n  %10853 : int[] = prim::Constant[value=[0, 0]]()\n  %10854 : int[] = prim::Constant[value=[1, 1]]()\n  %8694 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10855 : int[] = prim::Constant[value=[0, 0]]()\n  %8698 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8699 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8700 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8701 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8702 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.957 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.955, %905, %906, %10852, %10853, %10854, %8694, %10855, %8698, %8699, %8700, %8701, %8702) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11227 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.957) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10856 : int[] = prim::Constant[value=[1, 1]]()\n  %10857 : int[] = prim::Constant[value=[0, 0]]()\n  %10858 : int[] = prim::Constant[value=[1, 1]]()\n  %8714 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10859 : int[] = prim::Constant[value=[0, 0]]()\n  %8718 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8719 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8720 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8721 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8722 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8723 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11227, %907, %908, %10856, %10857, %10858, %8714, %10859, %8718, %8719, %8720, %8721, %8722) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8724 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8723) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.961 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8724, %11226) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8726 : NoneType = prim::Constant()\n  %10860 : int[] = prim::Constant[value=[1, 1]]()\n  %10861 : int[] = prim::Constant[value=[0, 0]]()\n  %10862 : int[] = prim::Constant[value=[1, 1]]()\n  %8736 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10863 : int[] = prim::Constant[value=[0, 0]]()\n  %8740 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8741 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8742 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8743 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8744 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.963 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.961, %909, %8726, %10860, %10861, %10862, %8736, %10863, %8740, %8741, %8742, %8743, %8744) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8746 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8747 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8748 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8749 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8750 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.963, %910, %911, %912, %913, %8746, %8747, %8748, %8749) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8751 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11100 : Tensor = aten::type_as(%11297, %8750)\n  %11298 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8750, %11100, %8751) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8753 : NoneType = prim::Constant()\n  %10864 : int[] = prim::Constant[value=[1, 1]]()\n  %10865 : int[] = prim::Constant[value=[0, 0]]()\n  %10866 : int[] = prim::Constant[value=[1, 1]]()\n  %8763 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10867 : int[] = prim::Constant[value=[0, 0]]()\n  %8767 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8768 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8769 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8770 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8771 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.967 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11298, %915, %8753, %10864, %10865, %10866, %8763, %10867, %8767, %8768, %8769, %8770, %8771) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8773 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8774 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8775 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8776 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.969 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.967, %916, %917, %918, %919, %8773, %8774, %8775, %8776) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11228 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.969) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8779 : NoneType = prim::Constant()\n  %10868 : int[] = prim::Constant[value=[1, 1]]()\n  %10869 : int[] = prim::Constant[value=[1, 1]]()\n  %10870 : int[] = prim::Constant[value=[1, 1]]()\n  %8789 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10871 : int[] = prim::Constant[value=[0, 0]]()\n  %8793 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8794 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8795 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8796 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8797 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.973 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11228, %921, %8779, %10868, %10869, %10870, %8789, %10871, %8793, %8794, %8795, %8796, %8797) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8799 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8800 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8801 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8802 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.975 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.973, %922, %923, %924, %925, %8799, %8800, %8801, %8802) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11229 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.975) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10872 : int[] = prim::Constant[value=[1, 1]]()\n  %input.979 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11229, %10872) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10873 : int[] = prim::Constant[value=[1, 1]]()\n  %10874 : int[] = prim::Constant[value=[0, 0]]()\n  %10875 : int[] = prim::Constant[value=[1, 1]]()\n  %8830 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10876 : int[] = prim::Constant[value=[0, 0]]()\n  %8834 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8835 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8836 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8837 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8838 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.981 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.979, %927, %928, %10873, %10874, %10875, %8830, %10876, %8834, %8835, %8836, %8837, %8838) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11230 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.981) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10877 : int[] = prim::Constant[value=[1, 1]]()\n  %10878 : int[] = prim::Constant[value=[0, 0]]()\n  %10879 : int[] = prim::Constant[value=[1, 1]]()\n  %8850 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10880 : int[] = prim::Constant[value=[0, 0]]()\n  %8854 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8855 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8856 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8857 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8858 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8859 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11230, %929, %930, %10877, %10878, %10879, %8850, %10880, %8854, %8855, %8856, %8857, %8858) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8860 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8859) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.985 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8860, %11229) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8862 : NoneType = prim::Constant()\n  %10881 : int[] = prim::Constant[value=[1, 1]]()\n  %10882 : int[] = prim::Constant[value=[0, 0]]()\n  %10883 : int[] = prim::Constant[value=[1, 1]]()\n  %8872 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10884 : int[] = prim::Constant[value=[0, 0]]()\n  %8876 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8877 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8878 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8879 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8880 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.987 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.985, %931, %8862, %10881, %10882, %10883, %8872, %10884, %8876, %8877, %8878, %8879, %8880) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8882 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8883 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8884 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8885 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8886 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.987, %932, %933, %934, %935, %8882, %8883, %8884, %8885) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8887 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11101 : Tensor = aten::type_as(%11298, %8886)\n  %11299 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%8886, %11101, %8887) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %8889 : NoneType = prim::Constant()\n  %10885 : int[] = prim::Constant[value=[1, 1]]()\n  %10886 : int[] = prim::Constant[value=[0, 0]]()\n  %10887 : int[] = prim::Constant[value=[1, 1]]()\n  %8899 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10888 : int[] = prim::Constant[value=[0, 0]]()\n  %8903 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8904 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8905 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8906 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8907 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.991 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11299, %937, %8889, %10885, %10886, %10887, %8899, %10888, %8903, %8904, %8905, %8906, %8907) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8909 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8910 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8911 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8912 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.993 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.991, %938, %939, %940, %941, %8909, %8910, %8911, %8912) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11231 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.993) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %8915 : NoneType = prim::Constant()\n  %10889 : int[] = prim::Constant[value=[1, 1]]()\n  %10890 : int[] = prim::Constant[value=[1, 1]]()\n  %10891 : int[] = prim::Constant[value=[1, 1]]()\n  %8925 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10892 : int[] = prim::Constant[value=[0, 0]]()\n  %8929 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8930 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8931 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8932 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8933 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.997 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11231, %943, %8915, %10889, %10890, %10891, %8925, %10892, %8929, %8930, %8931, %8932, %8933) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8935 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8936 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8937 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %8938 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.999 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.997, %944, %945, %946, %947, %8935, %8936, %8937, %8938) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11232 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.999) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10893 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1003 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11232, %10893) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10894 : int[] = prim::Constant[value=[1, 1]]()\n  %10895 : int[] = prim::Constant[value=[0, 0]]()\n  %10896 : int[] = prim::Constant[value=[1, 1]]()\n  %8966 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10897 : int[] = prim::Constant[value=[0, 0]]()\n  %8970 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8971 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8972 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8973 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8974 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1005 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1003, %949, %950, %10894, %10895, %10896, %8966, %10897, %8970, %8971, %8972, %8973, %8974) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11233 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1005) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10898 : int[] = prim::Constant[value=[1, 1]]()\n  %10899 : int[] = prim::Constant[value=[0, 0]]()\n  %10900 : int[] = prim::Constant[value=[1, 1]]()\n  %8986 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10901 : int[] = prim::Constant[value=[0, 0]]()\n  %8990 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8991 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8992 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8993 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8994 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8995 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11233, %951, %952, %10898, %10899, %10900, %8986, %10901, %8990, %8991, %8992, %8993, %8994) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %8996 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%8995) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1009 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%8996, %11232) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %8998 : NoneType = prim::Constant()\n  %10902 : int[] = prim::Constant[value=[1, 1]]()\n  %10903 : int[] = prim::Constant[value=[0, 0]]()\n  %10904 : int[] = prim::Constant[value=[1, 1]]()\n  %9008 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10905 : int[] = prim::Constant[value=[0, 0]]()\n  %9012 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9013 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9014 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9015 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9016 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1011 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1009, %953, %8998, %10902, %10903, %10904, %9008, %10905, %9012, %9013, %9014, %9015, %9016) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9018 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9019 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9020 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9021 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9022 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1011, %954, %955, %956, %957, %9018, %9019, %9020, %9021) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9023 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11102 : Tensor = aten::type_as(%11299, %9022)\n  %11300 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9022, %11102, %9023) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9025 : NoneType = prim::Constant()\n  %10906 : int[] = prim::Constant[value=[1, 1]]()\n  %10907 : int[] = prim::Constant[value=[0, 0]]()\n  %10908 : int[] = prim::Constant[value=[1, 1]]()\n  %9035 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10909 : int[] = prim::Constant[value=[0, 0]]()\n  %9039 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9040 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9041 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9042 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9043 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1015 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11300, %959, %9025, %10906, %10907, %10908, %9035, %10909, %9039, %9040, %9041, %9042, %9043) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9045 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9046 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9047 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9048 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1017 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1015, %960, %961, %962, %963, %9045, %9046, %9047, %9048) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11234 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1017) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9051 : NoneType = prim::Constant()\n  %10910 : int[] = prim::Constant[value=[1, 1]]()\n  %10911 : int[] = prim::Constant[value=[1, 1]]()\n  %10912 : int[] = prim::Constant[value=[1, 1]]()\n  %9061 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10913 : int[] = prim::Constant[value=[0, 0]]()\n  %9065 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9066 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9067 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9068 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9069 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1021 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11234, %965, %9051, %10910, %10911, %10912, %9061, %10913, %9065, %9066, %9067, %9068, %9069) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9071 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9072 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9073 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9074 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1023 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1021, %966, %967, %968, %969, %9071, %9072, %9073, %9074) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11235 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1023) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10914 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1027 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11235, %10914) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10915 : int[] = prim::Constant[value=[1, 1]]()\n  %10916 : int[] = prim::Constant[value=[0, 0]]()\n  %10917 : int[] = prim::Constant[value=[1, 1]]()\n  %9102 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10918 : int[] = prim::Constant[value=[0, 0]]()\n  %9106 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9107 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9108 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9109 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9110 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1029 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1027, %971, %972, %10915, %10916, %10917, %9102, %10918, %9106, %9107, %9108, %9109, %9110) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11236 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1029) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10919 : int[] = prim::Constant[value=[1, 1]]()\n  %10920 : int[] = prim::Constant[value=[0, 0]]()\n  %10921 : int[] = prim::Constant[value=[1, 1]]()\n  %9122 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10922 : int[] = prim::Constant[value=[0, 0]]()\n  %9126 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9127 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9128 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9129 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9130 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9131 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11236, %973, %974, %10919, %10920, %10921, %9122, %10922, %9126, %9127, %9128, %9129, %9130) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9132 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9131) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1033 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9132, %11235) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9134 : NoneType = prim::Constant()\n  %10923 : int[] = prim::Constant[value=[1, 1]]()\n  %10924 : int[] = prim::Constant[value=[0, 0]]()\n  %10925 : int[] = prim::Constant[value=[1, 1]]()\n  %9144 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10926 : int[] = prim::Constant[value=[0, 0]]()\n  %9148 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9149 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9150 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9151 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9152 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1035 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1033, %975, %9134, %10923, %10924, %10925, %9144, %10926, %9148, %9149, %9150, %9151, %9152) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9154 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9155 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9156 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9157 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9158 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1035, %976, %977, %978, %979, %9154, %9155, %9156, %9157) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9159 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11103 : Tensor = aten::type_as(%11300, %9158)\n  %11301 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9158, %11103, %9159) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9161 : NoneType = prim::Constant()\n  %10927 : int[] = prim::Constant[value=[1, 1]]()\n  %10928 : int[] = prim::Constant[value=[0, 0]]()\n  %10929 : int[] = prim::Constant[value=[1, 1]]()\n  %9171 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10930 : int[] = prim::Constant[value=[0, 0]]()\n  %9175 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9176 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9177 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9178 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9179 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1039 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11301, %981, %9161, %10927, %10928, %10929, %9171, %10930, %9175, %9176, %9177, %9178, %9179) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9181 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9182 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9183 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9184 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1041 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1039, %982, %983, %984, %985, %9181, %9182, %9183, %9184) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11237 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1041) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9187 : NoneType = prim::Constant()\n  %10931 : int[] = prim::Constant[value=[1, 1]]()\n  %10932 : int[] = prim::Constant[value=[1, 1]]()\n  %10933 : int[] = prim::Constant[value=[1, 1]]()\n  %9197 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10934 : int[] = prim::Constant[value=[0, 0]]()\n  %9201 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9202 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9203 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9204 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9205 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1045 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11237, %987, %9187, %10931, %10932, %10933, %9197, %10934, %9201, %9202, %9203, %9204, %9205) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9207 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9208 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9209 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9210 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1047 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1045, %988, %989, %990, %991, %9207, %9208, %9209, %9210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11238 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1047) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10935 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1051 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11238, %10935) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10936 : int[] = prim::Constant[value=[1, 1]]()\n  %10937 : int[] = prim::Constant[value=[0, 0]]()\n  %10938 : int[] = prim::Constant[value=[1, 1]]()\n  %9238 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10939 : int[] = prim::Constant[value=[0, 0]]()\n  %9242 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9243 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9244 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9245 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9246 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1053 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1051, %993, %994, %10936, %10937, %10938, %9238, %10939, %9242, %9243, %9244, %9245, %9246) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11239 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1053) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10940 : int[] = prim::Constant[value=[1, 1]]()\n  %10941 : int[] = prim::Constant[value=[0, 0]]()\n  %10942 : int[] = prim::Constant[value=[1, 1]]()\n  %9258 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10943 : int[] = prim::Constant[value=[0, 0]]()\n  %9262 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9263 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9264 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9265 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9266 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9267 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11239, %995, %996, %10940, %10941, %10942, %9258, %10943, %9262, %9263, %9264, %9265, %9266) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9268 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9267) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1057 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9268, %11238) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9270 : NoneType = prim::Constant()\n  %10944 : int[] = prim::Constant[value=[1, 1]]()\n  %10945 : int[] = prim::Constant[value=[0, 0]]()\n  %10946 : int[] = prim::Constant[value=[1, 1]]()\n  %9280 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10947 : int[] = prim::Constant[value=[0, 0]]()\n  %9284 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9285 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9286 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9287 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9288 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1059 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1057, %997, %9270, %10944, %10945, %10946, %9280, %10947, %9284, %9285, %9286, %9287, %9288) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9290 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9291 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9292 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9293 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9294 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1059, %998, %999, %1000, %1001, %9290, %9291, %9292, %9293) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9295 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11104 : Tensor = aten::type_as(%11301, %9294)\n  %11302 : Float(32, 304, 15, 15, strides=[68400, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9294, %11104, %9295) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9297 : NoneType = prim::Constant()\n  %10948 : int[] = prim::Constant[value=[1, 1]]()\n  %10949 : int[] = prim::Constant[value=[0, 0]]()\n  %10950 : int[] = prim::Constant[value=[1, 1]]()\n  %9307 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10951 : int[] = prim::Constant[value=[0, 0]]()\n  %9311 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9312 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9313 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9314 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9315 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1063 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11302, %1003, %9297, %10948, %10949, %10950, %9307, %10951, %9311, %9312, %9313, %9314, %9315) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9317 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9318 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9319 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9320 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1065 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1063, %1004, %1005, %1006, %1007, %9317, %9318, %9319, %9320) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11240 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1065) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9323 : NoneType = prim::Constant()\n  %10952 : int[] = prim::Constant[value=[1, 1]]()\n  %10953 : int[] = prim::Constant[value=[1, 1]]()\n  %10954 : int[] = prim::Constant[value=[1, 1]]()\n  %9333 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10955 : int[] = prim::Constant[value=[0, 0]]()\n  %9337 : int = prim::Constant[value=1824]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9338 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9339 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9340 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9341 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1069 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11240, %1009, %9323, %10952, %10953, %10954, %9333, %10955, %9337, %9338, %9339, %9340, %9341) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9343 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9344 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9345 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9346 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1071 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1069, %1010, %1011, %1012, %1013, %9343, %9344, %9345, %9346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11241 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1071) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10956 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1075 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11241, %10956) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10957 : int[] = prim::Constant[value=[1, 1]]()\n  %10958 : int[] = prim::Constant[value=[0, 0]]()\n  %10959 : int[] = prim::Constant[value=[1, 1]]()\n  %9374 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10960 : int[] = prim::Constant[value=[0, 0]]()\n  %9378 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9379 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9380 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9381 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9382 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1077 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1075, %1015, %1016, %10957, %10958, %10959, %9374, %10960, %9378, %9379, %9380, %9381, %9382) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11242 : Float(32, 76, 1, 1, strides=[76, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1077) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10961 : int[] = prim::Constant[value=[1, 1]]()\n  %10962 : int[] = prim::Constant[value=[0, 0]]()\n  %10963 : int[] = prim::Constant[value=[1, 1]]()\n  %9394 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10964 : int[] = prim::Constant[value=[0, 0]]()\n  %9398 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9399 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9400 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9401 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9402 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9403 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11242, %1017, %1018, %10961, %10962, %10963, %9394, %10964, %9398, %9399, %9400, %9401, %9402) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9404 : Float(32, 1824, 1, 1, strides=[1824, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9403) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1081 : Float(32, 1824, 15, 15, strides=[410400, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9404, %11241) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9406 : NoneType = prim::Constant()\n  %10965 : int[] = prim::Constant[value=[1, 1]]()\n  %10966 : int[] = prim::Constant[value=[0, 0]]()\n  %10967 : int[] = prim::Constant[value=[1, 1]]()\n  %9416 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10968 : int[] = prim::Constant[value=[0, 0]]()\n  %9420 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9421 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9422 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9423 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9424 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1083 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1081, %1019, %9406, %10965, %10966, %10967, %9416, %10968, %9420, %9421, %9422, %9423, %9424) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9426 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9427 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9428 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9429 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1085 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1083, %1020, %1021, %1022, %1023, %9426, %9427, %9428, %9429) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9431 : NoneType = prim::Constant()\n  %10969 : int[] = prim::Constant[value=[1, 1]]()\n  %10970 : int[] = prim::Constant[value=[0, 0]]()\n  %10971 : int[] = prim::Constant[value=[1, 1]]()\n  %9441 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10972 : int[] = prim::Constant[value=[0, 0]]()\n  %9445 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9446 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9447 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9448 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9449 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1087 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1085, %1025, %9431, %10969, %10970, %10971, %9441, %10972, %9445, %9446, %9447, %9448, %9449) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9451 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9452 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9453 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9454 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1089 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1087, %1026, %1027, %1028, %1029, %9451, %9452, %9453, %9454) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11243 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1089) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9457 : NoneType = prim::Constant()\n  %10973 : int[] = prim::Constant[value=[1, 1]]()\n  %10974 : int[] = prim::Constant[value=[1, 1]]()\n  %10975 : int[] = prim::Constant[value=[1, 1]]()\n  %9467 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10976 : int[] = prim::Constant[value=[0, 0]]()\n  %9471 : int = prim::Constant[value=3072]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9472 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9473 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9474 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9475 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1093 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11243, %1031, %9457, %10973, %10974, %10975, %9467, %10976, %9471, %9472, %9473, %9474, %9475) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9477 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9478 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9479 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9480 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1095 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1093, %1032, %1033, %1034, %1035, %9477, %9478, %9479, %9480) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11244 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1095) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10977 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1099 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11244, %10977) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10978 : int[] = prim::Constant[value=[1, 1]]()\n  %10979 : int[] = prim::Constant[value=[0, 0]]()\n  %10980 : int[] = prim::Constant[value=[1, 1]]()\n  %9508 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10981 : int[] = prim::Constant[value=[0, 0]]()\n  %9512 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9513 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9514 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9515 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9516 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1101 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1099, %1037, %1038, %10978, %10979, %10980, %9508, %10981, %9512, %9513, %9514, %9515, %9516) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11245 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1101) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10982 : int[] = prim::Constant[value=[1, 1]]()\n  %10983 : int[] = prim::Constant[value=[0, 0]]()\n  %10984 : int[] = prim::Constant[value=[1, 1]]()\n  %9528 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10985 : int[] = prim::Constant[value=[0, 0]]()\n  %9532 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9533 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9534 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9535 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9536 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9537 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11245, %1039, %1040, %10982, %10983, %10984, %9528, %10985, %9532, %9533, %9534, %9535, %9536) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9538 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9537) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1105 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9538, %11244) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9540 : NoneType = prim::Constant()\n  %10986 : int[] = prim::Constant[value=[1, 1]]()\n  %10987 : int[] = prim::Constant[value=[0, 0]]()\n  %10988 : int[] = prim::Constant[value=[1, 1]]()\n  %9550 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10989 : int[] = prim::Constant[value=[0, 0]]()\n  %9554 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9555 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9556 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9557 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9558 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1107 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1105, %1041, %9540, %10986, %10987, %10988, %9550, %10989, %9554, %9555, %9556, %9557, %9558) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9560 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9561 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9562 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9563 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9564 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1107, %1042, %1043, %1044, %1045, %9560, %9561, %9562, %9563) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9565 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11105 : Tensor = aten::type_as(%input.1085, %9564)\n  %11303 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9564, %11105, %9565) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9567 : NoneType = prim::Constant()\n  %10990 : int[] = prim::Constant[value=[1, 1]]()\n  %10991 : int[] = prim::Constant[value=[0, 0]]()\n  %10992 : int[] = prim::Constant[value=[1, 1]]()\n  %9577 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10993 : int[] = prim::Constant[value=[0, 0]]()\n  %9581 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9582 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9583 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9584 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9585 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1111 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11303, %1047, %9567, %10990, %10991, %10992, %9577, %10993, %9581, %9582, %9583, %9584, %9585) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9587 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9588 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9589 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9590 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1113 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1111, %1048, %1049, %1050, %1051, %9587, %9588, %9589, %9590) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11246 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1113) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9593 : NoneType = prim::Constant()\n  %10994 : int[] = prim::Constant[value=[1, 1]]()\n  %10995 : int[] = prim::Constant[value=[1, 1]]()\n  %10996 : int[] = prim::Constant[value=[1, 1]]()\n  %9603 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %10997 : int[] = prim::Constant[value=[0, 0]]()\n  %9607 : int = prim::Constant[value=3072]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9608 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9609 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9610 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9611 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1117 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11246, %1053, %9593, %10994, %10995, %10996, %9603, %10997, %9607, %9608, %9609, %9610, %9611) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9613 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9614 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9615 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9616 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1119 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1117, %1054, %1055, %1056, %1057, %9613, %9614, %9615, %9616) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11247 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1119) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %10998 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1123 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11247, %10998) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10999 : int[] = prim::Constant[value=[1, 1]]()\n  %11000 : int[] = prim::Constant[value=[0, 0]]()\n  %11001 : int[] = prim::Constant[value=[1, 1]]()\n  %9644 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11002 : int[] = prim::Constant[value=[0, 0]]()\n  %9648 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9649 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9650 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9651 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9652 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1125 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1123, %1059, %1060, %10999, %11000, %11001, %9644, %11002, %9648, %9649, %9650, %9651, %9652) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11248 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1125) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11003 : int[] = prim::Constant[value=[1, 1]]()\n  %11004 : int[] = prim::Constant[value=[0, 0]]()\n  %11005 : int[] = prim::Constant[value=[1, 1]]()\n  %9664 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11006 : int[] = prim::Constant[value=[0, 0]]()\n  %9668 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9669 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9670 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9671 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9672 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9673 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11248, %1061, %1062, %11003, %11004, %11005, %9664, %11006, %9668, %9669, %9670, %9671, %9672) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9674 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9673) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1129 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9674, %11247) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9676 : NoneType = prim::Constant()\n  %11007 : int[] = prim::Constant[value=[1, 1]]()\n  %11008 : int[] = prim::Constant[value=[0, 0]]()\n  %11009 : int[] = prim::Constant[value=[1, 1]]()\n  %9686 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11010 : int[] = prim::Constant[value=[0, 0]]()\n  %9690 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9691 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9692 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9693 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9694 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1131 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1129, %1063, %9676, %11007, %11008, %11009, %9686, %11010, %9690, %9691, %9692, %9693, %9694) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9696 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9697 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9698 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9699 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9700 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1131, %1064, %1065, %1066, %1067, %9696, %9697, %9698, %9699) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9701 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11106 : Tensor = aten::type_as(%11303, %9700)\n  %11304 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9700, %11106, %9701) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9703 : NoneType = prim::Constant()\n  %11011 : int[] = prim::Constant[value=[1, 1]]()\n  %11012 : int[] = prim::Constant[value=[0, 0]]()\n  %11013 : int[] = prim::Constant[value=[1, 1]]()\n  %9713 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11014 : int[] = prim::Constant[value=[0, 0]]()\n  %9717 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9718 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9719 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9720 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9721 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1135 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11304, %1069, %9703, %11011, %11012, %11013, %9713, %11014, %9717, %9718, %9719, %9720, %9721) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9723 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9724 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9725 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9726 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1137 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1135, %1070, %1071, %1072, %1073, %9723, %9724, %9725, %9726) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11249 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1137) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9729 : NoneType = prim::Constant()\n  %11015 : int[] = prim::Constant[value=[1, 1]]()\n  %11016 : int[] = prim::Constant[value=[1, 1]]()\n  %11017 : int[] = prim::Constant[value=[1, 1]]()\n  %9739 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11018 : int[] = prim::Constant[value=[0, 0]]()\n  %9743 : int = prim::Constant[value=3072]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9744 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9745 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9746 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9747 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1141 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11249, %1075, %9729, %11015, %11016, %11017, %9739, %11018, %9743, %9744, %9745, %9746, %9747) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9749 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9750 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9751 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9752 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1143 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1141, %1076, %1077, %1078, %1079, %9749, %9750, %9751, %9752) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11250 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1143) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11019 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1147 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11250, %11019) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %11020 : int[] = prim::Constant[value=[1, 1]]()\n  %11021 : int[] = prim::Constant[value=[0, 0]]()\n  %11022 : int[] = prim::Constant[value=[1, 1]]()\n  %9780 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11023 : int[] = prim::Constant[value=[0, 0]]()\n  %9784 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9785 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9786 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9787 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9788 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1149 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1147, %1081, %1082, %11020, %11021, %11022, %9780, %11023, %9784, %9785, %9786, %9787, %9788) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11251 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1149) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11024 : int[] = prim::Constant[value=[1, 1]]()\n  %11025 : int[] = prim::Constant[value=[0, 0]]()\n  %11026 : int[] = prim::Constant[value=[1, 1]]()\n  %9800 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11027 : int[] = prim::Constant[value=[0, 0]]()\n  %9804 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9805 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9806 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9807 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9808 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9809 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11251, %1083, %1084, %11024, %11025, %11026, %9800, %11027, %9804, %9805, %9806, %9807, %9808) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9810 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9809) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1153 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9810, %11250) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9812 : NoneType = prim::Constant()\n  %11028 : int[] = prim::Constant[value=[1, 1]]()\n  %11029 : int[] = prim::Constant[value=[0, 0]]()\n  %11030 : int[] = prim::Constant[value=[1, 1]]()\n  %9822 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11031 : int[] = prim::Constant[value=[0, 0]]()\n  %9826 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9827 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9828 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9829 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9830 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1155 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1153, %1085, %9812, %11028, %11029, %11030, %9822, %11031, %9826, %9827, %9828, %9829, %9830) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9832 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9833 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9834 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9835 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9836 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1155, %1086, %1087, %1088, %1089, %9832, %9833, %9834, %9835) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9837 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11107 : Tensor = aten::type_as(%11304, %9836)\n  %11305 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9836, %11107, %9837) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9839 : NoneType = prim::Constant()\n  %11032 : int[] = prim::Constant[value=[1, 1]]()\n  %11033 : int[] = prim::Constant[value=[0, 0]]()\n  %11034 : int[] = prim::Constant[value=[1, 1]]()\n  %9849 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11035 : int[] = prim::Constant[value=[0, 0]]()\n  %9853 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9854 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9855 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9856 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9857 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1159 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11305, %1091, %9839, %11032, %11033, %11034, %9849, %11035, %9853, %9854, %9855, %9856, %9857) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9859 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9860 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9861 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9862 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1161 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1159, %1092, %1093, %1094, %1095, %9859, %9860, %9861, %9862) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11252 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1161) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %9865 : NoneType = prim::Constant()\n  %11036 : int[] = prim::Constant[value=[1, 1]]()\n  %11037 : int[] = prim::Constant[value=[1, 1]]()\n  %11038 : int[] = prim::Constant[value=[1, 1]]()\n  %9875 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11039 : int[] = prim::Constant[value=[0, 0]]()\n  %9879 : int = prim::Constant[value=3072]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9880 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9881 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9882 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9883 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1165 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11252, %1097, %9865, %11036, %11037, %11038, %9875, %11039, %9879, %9880, %9881, %9882, %9883) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9885 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9886 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9887 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9888 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1167 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1165, %1098, %1099, %1100, %1101, %9885, %9886, %9887, %9888) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11253 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1167) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11040 : int[] = prim::Constant[value=[1, 1]]()\n  %input.1171 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11253, %11040) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %11041 : int[] = prim::Constant[value=[1, 1]]()\n  %11042 : int[] = prim::Constant[value=[0, 0]]()\n  %11043 : int[] = prim::Constant[value=[1, 1]]()\n  %9916 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11044 : int[] = prim::Constant[value=[0, 0]]()\n  %9920 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9921 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9922 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9923 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9924 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1173 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1171, %1103, %1104, %11041, %11042, %11043, %9916, %11044, %9920, %9921, %9922, %9923, %9924) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11254 : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::silu(%input.1173) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11045 : int[] = prim::Constant[value=[1, 1]]()\n  %11046 : int[] = prim::Constant[value=[0, 0]]()\n  %11047 : int[] = prim::Constant[value=[1, 1]]()\n  %9936 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11048 : int[] = prim::Constant[value=[0, 0]]()\n  %9940 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9941 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9942 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9943 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9944 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9945 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%11254, %1105, %1106, %11045, %11046, %11047, %9936, %11048, %9940, %9941, %9942, %9943, %9944) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9946 : Float(32, 3072, 1, 1, strides=[3072, 1, 1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%9945) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:290:0\n  %input.1177 : Float(32, 3072, 15, 15, strides=[691200, 225, 15, 1], requires_grad=0, device=cpu) = aten::mul(%9946, %11253) # /usr/local/lib/python3.7/dist-packages/torchvision/ops/misc.py:254:0\n  %9948 : NoneType = prim::Constant()\n  %11049 : int[] = prim::Constant[value=[1, 1]]()\n  %11050 : int[] = prim::Constant[value=[0, 0]]()\n  %11051 : int[] = prim::Constant[value=[1, 1]]()\n  %9958 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11052 : int[] = prim::Constant[value=[0, 0]]()\n  %9962 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9963 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9964 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9965 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9966 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1179 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1177, %1107, %9948, %11049, %11050, %11051, %9958, %11052, %9962, %9963, %9964, %9965, %9966) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9968 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9969 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9970 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9971 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9972 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1179, %1108, %1109, %1110, %1111, %9968, %9969, %9970, %9971) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9973 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %11108 : Tensor = aten::type_as(%11305, %9972)\n  %11306 : Float(32, 512, 15, 15, strides=[115200, 225, 15, 1], requires_grad=0, device=cpu) = aten::add(%9972, %11108, %9973) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:168:0\n  %9975 : NoneType = prim::Constant()\n  %11053 : int[] = prim::Constant[value=[1, 1]]()\n  %11054 : int[] = prim::Constant[value=[0, 0]]()\n  %11055 : int[] = prim::Constant[value=[1, 1]]()\n  %9985 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %11056 : int[] = prim::Constant[value=[0, 0]]()\n  %9989 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9990 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9991 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9992 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9993 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %input.1183 : Float(32, 1280, 15, 15, strides=[288000, 225, 15, 1], requires_grad=0, device=cpu) = aten::_convolution(%11306, %1113, %9975, %11053, %11054, %11055, %9985, %11056, %9989, %9990, %9991, %9992, %9993) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:454:0\n  %9995 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9996 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9997 : float = prim::Constant[value=0.001]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %9998 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %input.1185 : Float(32, 1280, 15, 15, strides=[288000, 225, 15, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.1183, %1114, %1115, %1116, %1117, %9995, %9996, %9997, %9998) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2439:0\n  %11255 : Float(32, 1280, 15, 15, strides=[288000, 225, 15, 1], requires_grad=0, device=cpu) = aten::silu(%input.1185) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2047:0\n  %11057 : int[] = prim::Constant[value=[1, 1]]()\n  %10025 : Float(32, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%11255, %11057) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1214:0\n  %10026 : int = prim::Constant[value=1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:348:0\n  %10027 : int = prim::Constant[value=-1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:348:0\n  %input : Float(32, 1280, strides=[1280, 1], requires_grad=0, device=cpu) = aten::flatten(%10025, %10026, %10027) # /usr/local/lib/python3.7/dist-packages/torchvision/models/efficientnet.py:348:0\n  %10029 : float = prim::Constant[value=0.29999999999999999]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1252:0\n  %10030 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1252:0\n  %11307 : Float(32, 1280, strides=[1280, 1], requires_grad=0, device=cpu) = aten::dropout(%input, %10029, %10030) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1252:0\n  %10032 : Float(32, 5, strides=[5, 1], requires_grad=1, device=cpu) = aten::linear(%11307, %1119, %1120) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py:114:0\n  return (%10032)\n, None, False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.save('efficientNetV2m_hiddenlayer',format='png')"
      ],
      "metadata": {
        "id": "-nurcYk_NMBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Netron"
      ],
      "metadata": {
        "id": "jcCrT7ZWPBRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netron"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkG5APRcPSRf",
        "outputId": "d078b2ec-2cad-44a1-b698-11ee87a82c48"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting netron\n",
            "  Downloading netron-6.1.9-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     || 1.5 MB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: netron\n",
            "Successfully installed netron-6.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "netron -b model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "YGJwEf9lPWKH",
        "outputId": "a42f6d4d-7f8f-4ad8-d268-91c2b479cf96"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-5ea74cc302c1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    netron -b model\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import "
      ],
      "metadata": {
        "id": "yZzXU53yPDJ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}